+ echo 'Beginning trial 10 of 10'
Beginning trial 10 of 10
+ echo ':::DLPAL /mnt/data/bert_20221004.sif 2524 8 node[031-038]'
:::DLPAL /mnt/data/bert_20221004.sif 2524 8 node[031-038]
++ scontrol show hostname
++ tr '\n' ' '
+ hosts='node031 node032 node033 node034 node035 node036 node037 node038 '
+ echo 'hosts=node031 node032 node033 node034 node035 node036 node037 node038 '
hosts=node031 node032 node033 node034 node035 node036 node037 node038 
+ for node in $hosts
+ '[' 1 -eq 1 ']'
+ srun -N 1 -n 1 -w node031 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on node031
vm.drop_caches = 3
+ srun -N 1 -n 1 -w node031 mpirun --allow-run-as-root -np 1 singularity exec -B /home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert --pwd /workspace/bert /mnt/data/bert_20221004.sif python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1665725645202, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ for node in $hosts
+ '[' 1 -eq 1 ']'
+ srun -N 1 -n 1 -w node032 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on node032
vm.drop_caches = 3
+ srun -N 1 -n 1 -w node032 mpirun --allow-run-as-root -np 1 singularity exec -B /home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert --pwd /workspace/bert /mnt/data/bert_20221004.sif python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1665725650096, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ for node in $hosts
+ '[' 1 -eq 1 ']'
+ srun -N 1 -n 1 -w node033 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on node033
vm.drop_caches = 3
+ srun -N 1 -n 1 -w node033 mpirun --allow-run-as-root -np 1 singularity exec -B /home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert --pwd /workspace/bert /mnt/data/bert_20221004.sif python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1665725654909, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ for node in $hosts
+ '[' 1 -eq 1 ']'
+ srun -N 1 -n 1 -w node034 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on node034
vm.drop_caches = 3
+ srun -N 1 -n 1 -w node034 mpirun --allow-run-as-root -np 1 singularity exec -B /home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert --pwd /workspace/bert /mnt/data/bert_20221004.sif python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1665725659736, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ for node in $hosts
+ '[' 1 -eq 1 ']'
+ srun -N 1 -n 1 -w node035 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on node035
vm.drop_caches = 3
+ srun -N 1 -n 1 -w node035 mpirun --allow-run-as-root -np 1 singularity exec -B /home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert --pwd /workspace/bert /mnt/data/bert_20221004.sif python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1665725664571, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ for node in $hosts
+ '[' 1 -eq 1 ']'
+ srun -N 1 -n 1 -w node036 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on node036
vm.drop_caches = 3
+ srun -N 1 -n 1 -w node036 mpirun --allow-run-as-root -np 1 singularity exec -B /home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert --pwd /workspace/bert /mnt/data/bert_20221004.sif python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1665725669424, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ for node in $hosts
+ '[' 1 -eq 1 ']'
+ srun -N 1 -n 1 -w node037 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on node037
vm.drop_caches = 3
+ srun -N 1 -n 1 -w node037 mpirun --allow-run-as-root -np 1 singularity exec -B /home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert --pwd /workspace/bert /mnt/data/bert_20221004.sif python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1665725674255, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ for node in $hosts
+ '[' 1 -eq 1 ']'
+ srun -N 1 -n 1 -w node038 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on node038
vm.drop_caches = 3
+ srun -N 1 -n 1 -w node038 mpirun --allow-run-as-root -np 1 singularity exec -B /home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert --pwd /workspace/bert /mnt/data/bert_20221004.sif python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1665725679064, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ MPIRUN='mpirun --allow-run-as-root --bind-to none --report-bindings -np 32'
+ srun -l --ntasks=32 --ntasks-per-node=4 singularity exec --nv -B /mnt/data/mlperf/bert/hdf5_4320_shards_varlength:/workspace/data,/mnt/data/mlperf/bert/hdf5_4320_shards_varlength:/workspace/data_phase2,/mnt/data/mlperf/bert/phase1:/workspace/phase1,/mnt/data/mlperf/bert/eval_varlength/:/workspace/evaldata,/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert,/home/frank/results/bert-2.1/8XE8545-4xA100-SXM4-40GB:/results -B /home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert --pwd /workspace/bert /mnt/data/bert_20221004.sif ./run_and_time_multi.sh
 3: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
 0: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
 2: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
 1: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
28: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
20: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
 5: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
25: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
16: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
 9: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
29: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
30: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
21: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
31: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
22: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
23: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
24: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
 7: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
17: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
26: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
 4: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
18: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
27: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
 6: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
19: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
10: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
11: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
 8: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
12: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
13: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
14: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
15: WARNING: While bind mounting '/home/mlperf/mlperf-training-v2.1/bert/scripts:/workspace/bert': destination is already in the mount point list
 0: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
 0: ++ export BATCHSIZE=48
 0: ++ BATCHSIZE=48
 0: ++ export GRADIENT_STEPS=1
 0: ++ GRADIENT_STEPS=1
 0: ++ export LR=0.002
 0: ++ LR=0.002
 0: ++ export MAX_SAMPLES_TERMINATION=4500000
 0: ++ MAX_SAMPLES_TERMINATION=4500000
 0: ++ export MAX_STEPS=2254
 0: ++ MAX_STEPS=2254
 0: ++ export OPT_LAMB_BETA_1=0.66
 0: ++ OPT_LAMB_BETA_1=0.66
 0: ++ export OPT_LAMB_BETA_2=0.996
 0: ++ OPT_LAMB_BETA_2=0.996
 0: ++ export START_WARMUP_STEP=0
 0: ++ START_WARMUP_STEP=0
 0: ++ export WARMUP_PROPORTION=0.0
 0: ++ WARMUP_PROPORTION=0.0
 0: ++ export WEIGHT_DECAY_RATE=0.01
 0: ++ WEIGHT_DECAY_RATE=0.01
 0: ++ export INIT_LOSS_SCALE=4096.0
 0: ++ INIT_LOSS_SCALE=4096.0
 0: ++ export SBATCH_NETWORK=sharp
 0: ++ SBATCH_NETWORK=sharp
 0: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 0: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 0: ++ export PHASE=2
 0: ++ PHASE=2
 0: ++ export EVAL_ITER_START_SAMPLES=175000
 0: ++ EVAL_ITER_START_SAMPLES=175000
 0: ++ export EVAL_ITER_SAMPLES=175000
 0: ++ EVAL_ITER_SAMPLES=175000
 0: ++ export DGXNNODES=8
 0: ++ DGXNNODES=8
 0: +++ sed 's/^config_//'
 0: +++ sed 's/\.sh$//'
 0: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
 0: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
 0: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
 0: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
 0: ++ export WALLTIME_MINUTES=15
 0: ++ WALLTIME_MINUTES=15
 0: ++ export WALLTIME=20
 0: ++ WALLTIME=20
 0: ++ export DGXNGPU=4
 0: ++ DGXNGPU=4
 0: ++ export DGXSOCKETCORES=64
 0: ++ DGXSOCKETCORES=64
 0: ++ export DGXNSOCKET=2
 0: ++ DGXNSOCKET=2
 0: ++ export DGXHT=1
 0: ++ DGXHT=1
 0: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
 0: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
 0: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
 0: ++ export MLPERF_SUBMISSION_ORG=Dell
 0: ++ MLPERF_SUBMISSION_ORG=Dell
 0: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
 0: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
 0: ++ export OMP_NUM_THREADS=8
 0: ++ OMP_NUM_THREADS=8
 0: + ulimit -Sn 100000
 0: + '[' '' = 1 ']'
 0: + : 48
 0: + : 1
 0: + : 0.002
 0: + : 2254
 0: + : 2
 0: + : 0
 0: + : ''
 0: + : ''\'''\'''
 0: + : 6521
 0: + : 2524
 0: + : 0
 0: + : 4
 0: + : ''
 0: + : 0
 0: + : 175000
 0: + : 175000
 0: + : 4500000
 0: + : 0.66
 0: + : 0.996
 0: + : 0
 0: + : 0.720
 0: + : 0
 0: + : 0.0
 0: + : 0.0
 0: + : 0.01
 0: + : 0
 0: + : 0
 0: + : 0
 0: + : 0
 0: + : 0
 0: + : 0
 0: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
 0: Run vars: id 2524 gpus 4 mparams ''
 0: ++ date +%s
 0: + START=1665725682
 0: ++ date '+%Y-%m-%d %r'
 0: + START_FMT='2022-10-14 12:34:42 AM'
 0: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
 0: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
 0: + '[' '!' -z '' ']'
 0: + '[' 0 -gt 0 ']'
 0: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
 0: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
 0: + PHASES=("$PHASE1" "$PHASE2")
 0: + export RANK=0
 0: + RANK=0
 0: + export WORLD_SIZE=32
 0: + WORLD_SIZE=32
 0: WORLD_SIZE=32
 0: + echo WORLD_SIZE=32
 0: ++ cut -d - -f1
 0: ++ cut -d - -f2 -
 0: ++ echo 'node[031-038]'
 0: ++ tr -d '['
 0: + export MASTER_ADDR=node031
 0: + MASTER_ADDR=node031
 0: MASTER_ADDR=node031
 0: + echo MASTER_ADDR=node031
 0: + export MASTER_PORT=19002
 0: + MASTER_PORT=19002
 0: + echo HOSTNAME=node031
 0: HOSTNAME=node031
 0: + declare -a CMD
 0: + [[ -n 0 ]]
 0: + [[ 32 -gt 8 ]]
 0: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
 0: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 0: -bert_config_path=/workspace/phase1/bert_config.json '
 0: + '[' -n 0 ']'
 0: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 0: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
 0: + [[ 0 != 1 ]]
 0: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 0: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
 0: + [[ '' -ge 1 ]]
 0: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 0: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
 0: + [[ 0 != 0 ]]
 0: + '[' '' = apiLog.sh ']'
 0: + '[' '' = 1 ']'
 0: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
 0: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=6521'
 0: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
 0: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=6521
 2: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
 2: ++ export BATCHSIZE=48
 2: ++ BATCHSIZE=48
 2: ++ export GRADIENT_STEPS=1
 2: ++ GRADIENT_STEPS=1
 2: ++ export LR=0.002
 2: ++ LR=0.002
 2: ++ export MAX_SAMPLES_TERMINATION=4500000
 2: ++ MAX_SAMPLES_TERMINATION=4500000
 2: ++ export MAX_STEPS=2254
 2: ++ MAX_STEPS=2254
 2: ++ export OPT_LAMB_BETA_1=0.66
 2: ++ OPT_LAMB_BETA_1=0.66
 2: ++ export OPT_LAMB_BETA_2=0.996
 2: ++ OPT_LAMB_BETA_2=0.996
 2: ++ export START_WARMUP_STEP=0
 2: ++ START_WARMUP_STEP=0
 2: ++ export WARMUP_PROPORTION=0.0
 2: ++ WARMUP_PROPORTION=0.0
 2: ++ export WEIGHT_DECAY_RATE=0.01
 2: ++ WEIGHT_DECAY_RATE=0.01
 2: ++ export INIT_LOSS_SCALE=4096.0
 2: ++ INIT_LOSS_SCALE=4096.0
 2: ++ export SBATCH_NETWORK=sharp
 2: ++ SBATCH_NETWORK=sharp
 2: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 2: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 2: ++ export PHASE=2
 2: ++ PHASE=2
 2: ++ export EVAL_ITER_START_SAMPLES=175000
 2: ++ EVAL_ITER_START_SAMPLES=175000
 2: ++ export EVAL_ITER_SAMPLES=175000
 2: ++ EVAL_ITER_SAMPLES=175000
 2: ++ export DGXNNODES=8
 2: ++ DGXNNODES=8
 2: +++ sed 's/^config_//'
 2: +++ sed 's/\.sh$//'
 2: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
 2: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
 2: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
 2: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
 2: ++ export WALLTIME_MINUTES=15
 2: ++ WALLTIME_MINUTES=15
 2: ++ export WALLTIME=20
 2: ++ WALLTIME=20
 2: ++ export DGXNGPU=4
 2: ++ DGXNGPU=4
 2: ++ export DGXSOCKETCORES=64
 2: ++ DGXSOCKETCORES=64
 2: ++ export DGXNSOCKET=2
 2: ++ DGXNSOCKET=2
 2: ++ export DGXHT=1
 2: ++ DGXHT=1
 2: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
 2: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
 2: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
 2: ++ export MLPERF_SUBMISSION_ORG=Dell
 2: ++ MLPERF_SUBMISSION_ORG=Dell
 2: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
 2: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
 2: ++ export OMP_NUM_THREADS=8
 2: ++ OMP_NUM_THREADS=8
 2: + ulimit -Sn 100000
 2: + '[' '' = 1 ']'
 2: + : 48
 2: + : 1
 2: + : 0.002
 2: + : 2254
 2: + : 2
 2: + : 2
 2: + : ''
 2: + : ''\'''\'''
 2: + : 8650
 2: + : 2524
 2: + : 0
 2: + : 4
 2: + : ''
 2: + : 0
 2: + : 175000
 2: + : 175000
 2: + : 4500000
 2: + : 0.66
 2: + : 0.996
 2: + : 0
 2: + : 0.720
 2: + : 0
 2: + : 0.0
 2: + : 0.0
 2: + : 0.01
 2: + : 0
 2: + : 0
 2: + : 0
 2: + : 0
 2: + : 0
 2: + : 0
 2: Run vars: id 2524 gpus 4 mparams ''
 2: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
 2: ++ date +%s
 2: + START=1665725682
 2: ++ date '+%Y-%m-%d %r'
 2: + START_FMT='2022-10-14 12:34:42 AM'
 2: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
 2: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
 2: + '[' '!' -z '' ']'
 2: + '[' 0 -gt 0 ']'
 2: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
 2: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
 2: + PHASES=("$PHASE1" "$PHASE2")
 2: + export RANK=2
 2: + RANK=2
 2: + export WORLD_SIZE=32
 2: + WORLD_SIZE=32
 2: + echo WORLD_SIZE=32
 2: WORLD_SIZE=32
 2: ++ cut -d - -f1
 2: ++ cut -d - -f2 -
 2: ++ echo 'node[031-038]'
 2: ++ tr -d '['
 2: + export MASTER_ADDR=node031
 2: + MASTER_ADDR=node031
 2: MASTER_ADDR=node031
 2: + echo MASTER_ADDR=node031
 2: + export MASTER_PORT=19002
 2: + MASTER_PORT=19002
 2: HOSTNAME=node031
 2: + echo HOSTNAME=node031
 2: + declare -a CMD
 2: + [[ -n 2 ]]
 2: + [[ 32 -gt 8 ]]
 2: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
 2: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 2: -bert_config_path=/workspace/phase1/bert_config.json '
 2: + '[' -n 2 ']'
 2: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 2: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
 2: + [[ 0 != 1 ]]
 2: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 2: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
 2: + [[ '' -ge 1 ]]
 2: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 2: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
 2: + [[ 0 != 0 ]]
 2: + '[' '' = apiLog.sh ']'
 2: + '[' '' = 1 ']'
 2: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
 2: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=8650'
 2: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
 2: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=8650
 3: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
 3: ++ export BATCHSIZE=48
 3: ++ BATCHSIZE=48
 3: ++ export GRADIENT_STEPS=1
 3: ++ GRADIENT_STEPS=1
 3: ++ export LR=0.002
 3: ++ LR=0.002
 3: ++ export MAX_SAMPLES_TERMINATION=4500000
 3: ++ MAX_SAMPLES_TERMINATION=4500000
 3: ++ export MAX_STEPS=2254
 3: ++ MAX_STEPS=2254
 3: ++ export OPT_LAMB_BETA_1=0.66
 3: ++ OPT_LAMB_BETA_1=0.66
 3: ++ export OPT_LAMB_BETA_2=0.996
 3: ++ OPT_LAMB_BETA_2=0.996
 3: ++ export START_WARMUP_STEP=0
 3: ++ START_WARMUP_STEP=0
 3: ++ export WARMUP_PROPORTION=0.0
 3: ++ WARMUP_PROPORTION=0.0
 3: ++ export WEIGHT_DECAY_RATE=0.01
 3: ++ WEIGHT_DECAY_RATE=0.01
 3: ++ export INIT_LOSS_SCALE=4096.0
 3: ++ INIT_LOSS_SCALE=4096.0
 3: ++ export SBATCH_NETWORK=sharp
 3: ++ SBATCH_NETWORK=sharp
 3: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 3: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 3: ++ export PHASE=2
 3: ++ PHASE=2
 3: ++ export EVAL_ITER_START_SAMPLES=175000
 3: ++ EVAL_ITER_START_SAMPLES=175000
 3: ++ export EVAL_ITER_SAMPLES=175000
 3: ++ EVAL_ITER_SAMPLES=175000
 3: ++ export DGXNNODES=8
 3: ++ DGXNNODES=8
 3: +++ sed 's/^config_//'
 3: +++ sed 's/\.sh$//'
 3: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
 3: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
 3: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
 3: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
 3: ++ export WALLTIME_MINUTES=15
 3: ++ WALLTIME_MINUTES=15
 3: ++ export WALLTIME=20
 3: ++ WALLTIME=20
 3: ++ export DGXNGPU=4
 3: ++ DGXNGPU=4
 3: ++ export DGXSOCKETCORES=64
 3: ++ DGXSOCKETCORES=64
 3: ++ export DGXNSOCKET=2
 3: ++ DGXNSOCKET=2
 3: ++ export DGXHT=1
 3: ++ DGXHT=1
 3: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
 3: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
 3: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
 3: ++ export MLPERF_SUBMISSION_ORG=Dell
 3: ++ MLPERF_SUBMISSION_ORG=Dell
 3: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
 3: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
 3: ++ export OMP_NUM_THREADS=8
 3: ++ OMP_NUM_THREADS=8
 3: + ulimit -Sn 100000
 3: + '[' '' = 1 ']'
 3: + : 48
 3: + : 1
 3: + : 0.002
 3: + : 2254
 3: + : 2
 3: + : 3
 3: + : ''
 3: + : ''\'''\'''
 3: + : 17081
 3: + : 2524
 3: + : 0
 3: + : 4
 3: + : ''
 3: + : 0
 3: + : 175000
 3: + : 175000
 3: + : 4500000
 3: + : 0.66
 3: + : 0.996
 3: + : 0
 3: + : 0.720
 3: + : 0
 3: + : 0.0
 3: + : 0.0
 3: + : 0.01
 3: + : 0
 3: + : 0
 3: + : 0
 3: + : 0
 3: + : 0
 3: + : 0
 3: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
 3: Run vars: id 2524 gpus 4 mparams ''
 3: ++ date +%s
 3: + START=1665725682
 3: ++ date '+%Y-%m-%d %r'
 3: + START_FMT='2022-10-14 12:34:42 AM'
 3: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
 3: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
 3: + '[' '!' -z '' ']'
 3: + '[' 0 -gt 0 ']'
 3: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
 3: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
 3: + PHASES=("$PHASE1" "$PHASE2")
 3: + export RANK=3
 3: + RANK=3
 3: + export WORLD_SIZE=32
 3: + WORLD_SIZE=32
 3: WORLD_SIZE=32
 3: + echo WORLD_SIZE=32
 3: ++ cut -d - -f1
 3: ++ cut -d - -f2 -
 3: ++ tr -d '['
 3: ++ echo 'node[031-038]'
 3: + export MASTER_ADDR=node031
 3: + MASTER_ADDR=node031
 3: MASTER_ADDR=node031
 3: + echo MASTER_ADDR=node031
 3: + export MASTER_PORT=19002
 3: + MASTER_PORT=19002
 3: HOSTNAME=node031
 3: + echo HOSTNAME=node031
 3: + declare -a CMD
 3: + [[ -n 3 ]]
 3: + [[ 32 -gt 8 ]]
 3: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
 3: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 3: -bert_config_path=/workspace/phase1/bert_config.json '
 3: + '[' -n 3 ']'
 3: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 3: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
 3: + [[ 0 != 1 ]]
 3: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 3: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
 3: + [[ '' -ge 1 ]]
 3: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 3: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
 3: + [[ 0 != 0 ]]
 3: + '[' '' = apiLog.sh ']'
 3: + '[' '' = 1 ']'
 3: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
 3: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=17081'
 3: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
 3: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=17081
 1: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
 1: ++ export BATCHSIZE=48
 1: ++ BATCHSIZE=48
 1: ++ export GRADIENT_STEPS=1
 1: ++ GRADIENT_STEPS=1
 1: ++ export LR=0.002
 1: ++ LR=0.002
 1: ++ export MAX_SAMPLES_TERMINATION=4500000
 1: ++ MAX_SAMPLES_TERMINATION=4500000
 1: ++ export MAX_STEPS=2254
 1: ++ MAX_STEPS=2254
 1: ++ export OPT_LAMB_BETA_1=0.66
 1: ++ OPT_LAMB_BETA_1=0.66
 1: ++ export OPT_LAMB_BETA_2=0.996
 1: ++ OPT_LAMB_BETA_2=0.996
 1: ++ export START_WARMUP_STEP=0
 1: ++ START_WARMUP_STEP=0
 1: ++ export WARMUP_PROPORTION=0.0
 1: ++ WARMUP_PROPORTION=0.0
 1: ++ export WEIGHT_DECAY_RATE=0.01
 1: ++ WEIGHT_DECAY_RATE=0.01
 1: ++ export INIT_LOSS_SCALE=4096.0
 1: ++ INIT_LOSS_SCALE=4096.0
 1: ++ export SBATCH_NETWORK=sharp
 1: ++ SBATCH_NETWORK=sharp
 1: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 1: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 1: ++ export PHASE=2
 1: ++ PHASE=2
 1: ++ export EVAL_ITER_START_SAMPLES=175000
 1: ++ EVAL_ITER_START_SAMPLES=175000
 1: ++ export EVAL_ITER_SAMPLES=175000
 1: ++ EVAL_ITER_SAMPLES=175000
 1: ++ export DGXNNODES=8
 1: ++ DGXNNODES=8
 1: +++ sed 's/^config_//'
 1: +++ sed 's/\.sh$//'
 1: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
 1: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
 1: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
 1: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
 1: ++ export WALLTIME_MINUTES=15
 1: ++ WALLTIME_MINUTES=15
 1: ++ export WALLTIME=20
 1: ++ WALLTIME=20
 1: ++ export DGXNGPU=4
 1: ++ DGXNGPU=4
 1: ++ export DGXSOCKETCORES=64
 1: ++ DGXSOCKETCORES=64
 1: ++ export DGXNSOCKET=2
 1: ++ DGXNSOCKET=2
 1: ++ export DGXHT=1
 1: ++ DGXHT=1
 1: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
 1: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
 1: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
 1: ++ export MLPERF_SUBMISSION_ORG=Dell
 1: ++ MLPERF_SUBMISSION_ORG=Dell
 1: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
 1: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
 1: ++ export OMP_NUM_THREADS=8
 1: ++ OMP_NUM_THREADS=8
 1: + ulimit -Sn 100000
 1: + '[' '' = 1 ']'
 1: + : 48
 1: + : 1
 1: + : 0.002
 1: + : 2254
 1: + : 2
 1: + : 1
 1: + : ''
 1: + : ''\'''\'''
 1: + : 20326
 1: + : 2524
 1: + : 0
 1: + : 4
 1: + : ''
 1: + : 0
 1: + : 175000
 1: + : 175000
 1: + : 4500000
 1: + : 0.66
 1: + : 0.996
 1: + : 0
 1: + : 0.720
 1: + : 0
 1: + : 0.0
 1: + : 0.0
 1: + : 0.01
 1: + : 0
 1: + : 0
 1: + : 0
 1: + : 0
 1: + : 0
 1: + : 0
 1: Run vars: id 2524 gpus 4 mparams ''
 1: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
 1: ++ date +%s
28: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
28: ++ export BATCHSIZE=48
28: ++ BATCHSIZE=48
28: ++ export GRADIENT_STEPS=1
28: ++ GRADIENT_STEPS=1
28: ++ export LR=0.002
28: ++ LR=0.002
28: ++ export MAX_SAMPLES_TERMINATION=4500000
28: ++ MAX_SAMPLES_TERMINATION=4500000
28: ++ export MAX_STEPS=2254
28: ++ MAX_STEPS=2254
28: ++ export OPT_LAMB_BETA_1=0.66
28: ++ OPT_LAMB_BETA_1=0.66
28: ++ export OPT_LAMB_BETA_2=0.996
28: ++ OPT_LAMB_BETA_2=0.996
28: ++ export START_WARMUP_STEP=0
28: ++ START_WARMUP_STEP=0
28: ++ export WARMUP_PROPORTION=0.0
28: ++ WARMUP_PROPORTION=0.0
28: ++ export WEIGHT_DECAY_RATE=0.01
28: ++ WEIGHT_DECAY_RATE=0.01
28: ++ export INIT_LOSS_SCALE=4096.0
28: ++ INIT_LOSS_SCALE=4096.0
28: ++ export SBATCH_NETWORK=sharp
28: ++ SBATCH_NETWORK=sharp
28: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
28: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
28: ++ export PHASE=2
28: ++ PHASE=2
28: ++ export EVAL_ITER_START_SAMPLES=175000
28: ++ EVAL_ITER_START_SAMPLES=175000
 1: + START=1665725682
28: ++ export EVAL_ITER_SAMPLES=175000
28: ++ EVAL_ITER_SAMPLES=175000
28: ++ export DGXNNODES=8
28: ++ DGXNNODES=8
 1: ++ date '+%Y-%m-%d %r'
28: +++ sed 's/^config_//'
28: +++ sed 's/\.sh$//'
28: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
 1: + START_FMT='2022-10-14 12:34:42 AM'
 1: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
 1: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
 1: + '[' '!' -z '' ']'
 1: + '[' 0 -gt 0 ']'
 1: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
 1: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
 1: + PHASES=("$PHASE1" "$PHASE2")
 1: + export RANK=1
 1: + RANK=1
 1: + export WORLD_SIZE=32
 1: + WORLD_SIZE=32
 1: WORLD_SIZE=32
 1: + echo WORLD_SIZE=32
 1: ++ cut -d - -f1
 1: ++ cut -d - -f2 -
 1: ++ tr -d '['
 1: ++ echo 'node[031-038]'
28: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
 1: + export MASTER_ADDR=node031
 1: + MASTER_ADDR=node031
 1: MASTER_ADDR=node031
 1: + echo MASTER_ADDR=node031
 1: + export MASTER_PORT=19002
 1: + MASTER_PORT=19002
 1: HOSTNAME=node031
 1: + echo HOSTNAME=node031
 1: + declare -a CMD
 1: + [[ -n 1 ]]
 1: + [[ 32 -gt 8 ]]
 1: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
 1: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 1: -bert_config_path=/workspace/phase1/bert_config.json '
 1: + '[' -n 1 ']'
 1: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 1: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
 1: + [[ 0 != 1 ]]
 1: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 1: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
 1: + [[ '' -ge 1 ]]
 1: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 1: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
 1: + [[ 0 != 0 ]]
 1: + '[' '' = apiLog.sh ']'
 1: + '[' '' = 1 ']'
 1: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
 1: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=20326'
 1: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
 1: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=20326
28: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
28: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
28: ++ export WALLTIME_MINUTES=15
28: ++ WALLTIME_MINUTES=15
28: ++ export WALLTIME=20
28: ++ WALLTIME=20
28: ++ export DGXNGPU=4
28: ++ DGXNGPU=4
28: ++ export DGXSOCKETCORES=64
28: ++ DGXSOCKETCORES=64
28: ++ export DGXNSOCKET=2
28: ++ DGXNSOCKET=2
28: ++ export DGXHT=1
28: ++ DGXHT=1
28: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
28: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
28: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
28: ++ export MLPERF_SUBMISSION_ORG=Dell
28: ++ MLPERF_SUBMISSION_ORG=Dell
28: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
28: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
28: ++ export OMP_NUM_THREADS=8
28: ++ OMP_NUM_THREADS=8
28: + ulimit -Sn 100000
28: + '[' '' = 1 ']'
28: + : 48
28: + : 1
28: + : 0.002
28: + : 2254
28: + : 2
28: + : 0
28: + : ''
28: + : ''\'''\'''
28: + : 10136
28: + : 2524
28: + : 7
28: + : 4
28: + : ''
28: + : 0
28: + : 175000
28: + : 175000
28: + : 4500000
28: + : 0.66
28: + : 0.996
28: + : 0
28: + : 0.720
28: + : 0
28: + : 0.0
28: + : 0.0
28: + : 0.01
28: + : 0
28: + : 0
28: + : 0
28: + : 0
28: + : 0
28: + : 0
28: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
28: Run vars: id 2524 gpus 4 mparams ''
28: ++ date +%s
28: + START=1665725682
28: ++ date '+%Y-%m-%d %r'
28: + START_FMT='2022-10-14 12:34:42 AM'
28: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
28: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
28: + '[' '!' -z '' ']'
28: + '[' 0 -gt 0 ']'
28: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
28: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
28: + PHASES=("$PHASE1" "$PHASE2")
28: + export RANK=28
28: + RANK=28
28: + export WORLD_SIZE=32
28: + WORLD_SIZE=32
28: + echo WORLD_SIZE=32
28: WORLD_SIZE=32
28: ++ cut -d - -f1
28: ++ cut -d - -f2 -
28: ++ tr -d '['
28: ++ echo 'node[031-038]'
28: + export MASTER_ADDR=node031
28: + MASTER_ADDR=node031
28: + echo MASTER_ADDR=node031
28: MASTER_ADDR=node031
28: + export MASTER_PORT=19002
28: + MASTER_PORT=19002
28: HOSTNAME=node031
28: + echo HOSTNAME=node031
28: + declare -a CMD
28: + [[ -n 0 ]]
28: + [[ 32 -gt 8 ]]
28: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
28: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
28: -bert_config_path=/workspace/phase1/bert_config.json '
28: + '[' -n 0 ']'
28: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
28: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
28: + [[ 0 != 1 ]]
28: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
28: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
28: + [[ '' -ge 1 ]]
28: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
28: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
28: + [[ 0 != 0 ]]
28: + '[' '' = apiLog.sh ']'
28: + '[' '' = 1 ']'
28: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
28: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=10136'
28: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
28: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=10136
29: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
29: ++ export BATCHSIZE=48
29: ++ BATCHSIZE=48
29: ++ export GRADIENT_STEPS=1
29: ++ GRADIENT_STEPS=1
29: ++ export LR=0.002
29: ++ LR=0.002
29: ++ export MAX_SAMPLES_TERMINATION=4500000
29: ++ MAX_SAMPLES_TERMINATION=4500000
29: ++ export MAX_STEPS=2254
29: ++ MAX_STEPS=2254
29: ++ export OPT_LAMB_BETA_1=0.66
29: ++ OPT_LAMB_BETA_1=0.66
29: ++ export OPT_LAMB_BETA_2=0.996
29: ++ OPT_LAMB_BETA_2=0.996
29: ++ export START_WARMUP_STEP=0
29: ++ START_WARMUP_STEP=0
29: ++ export WARMUP_PROPORTION=0.0
29: ++ WARMUP_PROPORTION=0.0
29: ++ export WEIGHT_DECAY_RATE=0.01
29: ++ WEIGHT_DECAY_RATE=0.01
29: ++ export INIT_LOSS_SCALE=4096.0
29: ++ INIT_LOSS_SCALE=4096.0
29: ++ export SBATCH_NETWORK=sharp
29: ++ SBATCH_NETWORK=sharp
29: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
29: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
29: ++ export PHASE=2
29: ++ PHASE=2
29: ++ export EVAL_ITER_START_SAMPLES=175000
29: ++ EVAL_ITER_START_SAMPLES=175000
29: ++ export EVAL_ITER_SAMPLES=175000
29: ++ EVAL_ITER_SAMPLES=175000
29: ++ export DGXNNODES=8
29: ++ DGXNNODES=8
29: +++ sed 's/^config_//'
29: +++ sed 's/\.sh$//'
29: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
29: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
27: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
29: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
29: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
29: ++ export WALLTIME_MINUTES=15
29: ++ WALLTIME_MINUTES=15
29: ++ export WALLTIME=20
29: ++ WALLTIME=20
29: ++ export DGXNGPU=4
29: ++ DGXNGPU=4
29: ++ export DGXSOCKETCORES=64
29: ++ DGXSOCKETCORES=64
29: ++ export DGXNSOCKET=2
29: ++ DGXNSOCKET=2
29: ++ export DGXHT=1
29: ++ DGXHT=1
29: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
29: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
29: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
29: ++ export MLPERF_SUBMISSION_ORG=Dell
29: ++ MLPERF_SUBMISSION_ORG=Dell
29: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
29: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
29: ++ export OMP_NUM_THREADS=8
29: ++ OMP_NUM_THREADS=8
29: + ulimit -Sn 100000
29: + '[' '' = 1 ']'
29: + : 48
29: + : 1
29: + : 0.002
29: + : 2254
29: + : 2
29: + : 1
29: + : ''
29: + : ''\'''\'''
29: + : 21606
27: ++ export BATCHSIZE=48
27: ++ BATCHSIZE=48
29: + : 2524
29: + : 7
29: + : 4
29: + : ''
29: + : 0
29: + : 175000
29: + : 175000
29: + : 4500000
29: + : 0.66
29: + : 0.996
29: + : 0
29: + : 0.720
29: + : 0
29: + : 0.0
27: ++ export GRADIENT_STEPS=1
27: ++ GRADIENT_STEPS=1
29: + : 0.0
27: ++ export LR=0.002
27: ++ LR=0.002
29: + : 0.01
27: ++ export MAX_SAMPLES_TERMINATION=4500000
27: ++ MAX_SAMPLES_TERMINATION=4500000
29: + : 0
27: ++ export MAX_STEPS=2254
27: ++ MAX_STEPS=2254
29: + : 0
27: ++ export OPT_LAMB_BETA_1=0.66
27: ++ OPT_LAMB_BETA_1=0.66
29: Run vars: id 2524 gpus 4 mparams ''
29: + : 0
27: ++ export OPT_LAMB_BETA_2=0.996
27: ++ OPT_LAMB_BETA_2=0.996
29: + : 0
27: ++ export START_WARMUP_STEP=0
27: ++ START_WARMUP_STEP=0
29: + : 0
27: ++ export WARMUP_PROPORTION=0.0
27: ++ WARMUP_PROPORTION=0.0
29: + : 0
27: ++ export WEIGHT_DECAY_RATE=0.01
29: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
27: ++ WEIGHT_DECAY_RATE=0.01
27: ++ export INIT_LOSS_SCALE=4096.0
27: ++ INIT_LOSS_SCALE=4096.0
27: ++ export SBATCH_NETWORK=sharp
27: ++ SBATCH_NETWORK=sharp
27: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
27: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
27: ++ export PHASE=2
27: ++ PHASE=2
27: ++ export EVAL_ITER_START_SAMPLES=175000
27: ++ EVAL_ITER_START_SAMPLES=175000
27: ++ export EVAL_ITER_SAMPLES=175000
27: ++ EVAL_ITER_SAMPLES=175000
27: ++ export DGXNNODES=8
27: ++ DGXNNODES=8
29: ++ date +%s
27: +++ sed 's/^config_//'
27: +++ sed 's/\.sh$//'
27: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
29: + START=1665725682
29: ++ date '+%Y-%m-%d %r'
29: + START_FMT='2022-10-14 12:34:42 AM'
29: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
29: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
29: + '[' '!' -z '' ']'
29: + '[' 0 -gt 0 ']'
27: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
29: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
29: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
29: + PHASES=("$PHASE1" "$PHASE2")
29: + export RANK=29
29: + RANK=29
29: + export WORLD_SIZE=32
29: + WORLD_SIZE=32
29: WORLD_SIZE=32
29: + echo WORLD_SIZE=32
29: ++ cut -d - -f1
29: ++ cut -d - -f2 -
29: ++ echo 'node[031-038]'
29: ++ tr -d '['
27: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
27: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
27: ++ export WALLTIME_MINUTES=15
27: ++ WALLTIME_MINUTES=15
27: ++ export WALLTIME=20
27: ++ WALLTIME=20
27: ++ export DGXNGPU=4
27: ++ DGXNGPU=4
27: ++ export DGXSOCKETCORES=64
27: ++ DGXSOCKETCORES=64
27: ++ export DGXNSOCKET=2
27: ++ DGXNSOCKET=2
27: ++ export DGXHT=1
27: ++ DGXHT=1
27: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
27: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
27: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
27: ++ export MLPERF_SUBMISSION_ORG=Dell
27: ++ MLPERF_SUBMISSION_ORG=Dell
27: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
27: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
27: ++ export OMP_NUM_THREADS=8
27: ++ OMP_NUM_THREADS=8
27: + ulimit -Sn 100000
27: + '[' '' = 1 ']'
27: + : 48
27: + : 1
27: + : 0.002
27: + : 2254
27: + : 2
27: + : 3
27: + : ''
27: + : ''\'''\'''
27: + : 5671
27: + : 2524
27: + : 6
27: + : 4
27: + : ''
27: + : 0
27: + : 175000
27: + : 175000
27: + : 4500000
27: + : 0.66
27: + : 0.996
27: + : 0
29: + export MASTER_ADDR=node031
29: + MASTER_ADDR=node031
27: + : 0.720
27: + : 0
27: + : 0.0
27: + : 0.0
27: + : 0.01
27: + : 0
27: + : 0
27: + : 0
27: + : 0
27: + : 0
27: + : 0
27: Run vars: id 2524 gpus 4 mparams ''
27: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
29: + echo MASTER_ADDR=node031
29: MASTER_ADDR=node031
29: + export MASTER_PORT=19002
29: + MASTER_PORT=19002
29: HOSTNAME=node031
29: + echo HOSTNAME=node031
29: + declare -a CMD
29: + [[ -n 1 ]]
29: + [[ 32 -gt 8 ]]
29: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
27: ++ date +%s
29: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
29: -bert_config_path=/workspace/phase1/bert_config.json '
29: + '[' -n 1 ']'
29: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
29: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
29: + [[ 0 != 1 ]]
29: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
29: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
29: + [[ '' -ge 1 ]]
29: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
29: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
29: + [[ 0 != 0 ]]
29: + '[' '' = apiLog.sh ']'
29: + '[' '' = 1 ']'
29: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
29: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=21606'
29: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
29: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=21606
27: + START=1665725682
27: ++ date '+%Y-%m-%d %r'
27: + START_FMT='2022-10-14 12:34:42 AM'
20: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
27: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
27: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
27: + '[' '!' -z '' ']'
27: + '[' 0 -gt 0 ']'
27: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
30: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
27: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
27: + PHASES=("$PHASE1" "$PHASE2")
27: + export RANK=27
27: + RANK=27
27: + export WORLD_SIZE=32
27: + WORLD_SIZE=32
27: WORLD_SIZE=32
27: + echo WORLD_SIZE=32
30: ++ export BATCHSIZE=48
30: ++ BATCHSIZE=48
30: ++ export GRADIENT_STEPS=1
30: ++ GRADIENT_STEPS=1
30: ++ export LR=0.002
30: ++ LR=0.002
30: ++ export MAX_SAMPLES_TERMINATION=4500000
30: ++ MAX_SAMPLES_TERMINATION=4500000
30: ++ export MAX_STEPS=2254
30: ++ MAX_STEPS=2254
30: ++ export OPT_LAMB_BETA_1=0.66
30: ++ OPT_LAMB_BETA_1=0.66
20: ++ export BATCHSIZE=48
20: ++ BATCHSIZE=48
30: ++ export OPT_LAMB_BETA_2=0.996
30: ++ OPT_LAMB_BETA_2=0.996
30: ++ export START_WARMUP_STEP=0
30: ++ START_WARMUP_STEP=0
30: ++ export WARMUP_PROPORTION=0.0
30: ++ WARMUP_PROPORTION=0.0
30: ++ export WEIGHT_DECAY_RATE=0.01
30: ++ WEIGHT_DECAY_RATE=0.01
30: ++ export INIT_LOSS_SCALE=4096.0
30: ++ INIT_LOSS_SCALE=4096.0
30: ++ export SBATCH_NETWORK=sharp
30: ++ SBATCH_NETWORK=sharp
20: ++ export GRADIENT_STEPS=1
20: ++ GRADIENT_STEPS=1
30: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
30: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
20: ++ export LR=0.002
20: ++ LR=0.002
30: ++ export PHASE=2
30: ++ PHASE=2
20: ++ export MAX_SAMPLES_TERMINATION=4500000
20: ++ MAX_SAMPLES_TERMINATION=4500000
30: ++ export EVAL_ITER_START_SAMPLES=175000
30: ++ EVAL_ITER_START_SAMPLES=175000
20: ++ export MAX_STEPS=2254
20: ++ MAX_STEPS=2254
30: ++ export EVAL_ITER_SAMPLES=175000
30: ++ EVAL_ITER_SAMPLES=175000
20: ++ export OPT_LAMB_BETA_1=0.66
30: ++ export DGXNNODES=8
20: ++ OPT_LAMB_BETA_1=0.66
30: ++ DGXNNODES=8
20: ++ export OPT_LAMB_BETA_2=0.996
20: ++ OPT_LAMB_BETA_2=0.996
20: ++ export START_WARMUP_STEP=0
20: ++ START_WARMUP_STEP=0
20: ++ export WARMUP_PROPORTION=0.0
20: ++ WARMUP_PROPORTION=0.0
20: ++ export WEIGHT_DECAY_RATE=0.01
20: ++ WEIGHT_DECAY_RATE=0.01
20: ++ export INIT_LOSS_SCALE=4096.0
20: ++ INIT_LOSS_SCALE=4096.0
20: ++ export SBATCH_NETWORK=sharp
20: ++ SBATCH_NETWORK=sharp
20: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
20: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
20: ++ export PHASE=2
20: ++ PHASE=2
20: ++ export EVAL_ITER_START_SAMPLES=175000
20: ++ EVAL_ITER_START_SAMPLES=175000
20: ++ export EVAL_ITER_SAMPLES=175000
20: ++ EVAL_ITER_SAMPLES=175000
20: ++ export DGXNNODES=8
20: ++ DGXNNODES=8
27: ++ cut -d - -f1
27: ++ cut -d - -f2 -
27: ++ tr -d '['
20: +++ sed 's/^config_//'
20: +++ sed 's/\.sh$//'
20: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
30: +++ sed 's/^config_//'
30: +++ sed 's/\.sh$//'
30: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
27: ++ echo 'node[031-038]'
27: + export MASTER_ADDR=node031
27: + MASTER_ADDR=node031
27: MASTER_ADDR=node031
27: + echo MASTER_ADDR=node031
27: + export MASTER_PORT=19002
27: + MASTER_PORT=19002
27: + echo HOSTNAME=node031
27: HOSTNAME=node031
27: + declare -a CMD
27: + [[ -n 3 ]]
27: + [[ 32 -gt 8 ]]
27: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
27: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
27: -bert_config_path=/workspace/phase1/bert_config.json '
30: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
27: + '[' -n 3 ']'
27: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
27: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
27: + [[ 0 != 1 ]]
27: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
27: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
27: + [[ '' -ge 1 ]]
27: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
20: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
27: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
27: + [[ 0 != 0 ]]
27: + '[' '' = apiLog.sh ']'
27: + '[' '' = 1 ']'
27: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
27: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=5671'
27: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
27: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=5671
30: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
30: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
30: ++ export WALLTIME_MINUTES=15
30: ++ WALLTIME_MINUTES=15
30: ++ export WALLTIME=20
30: ++ WALLTIME=20
30: ++ export DGXNGPU=4
30: ++ DGXNGPU=4
30: ++ export DGXSOCKETCORES=64
30: ++ DGXSOCKETCORES=64
30: ++ export DGXNSOCKET=2
30: ++ DGXNSOCKET=2
30: ++ export DGXHT=1
30: ++ DGXHT=1
30: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
30: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
30: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
30: ++ export MLPERF_SUBMISSION_ORG=Dell
30: ++ MLPERF_SUBMISSION_ORG=Dell
30: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
30: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
30: ++ export OMP_NUM_THREADS=8
30: ++ OMP_NUM_THREADS=8
30: + ulimit -Sn 100000
30: + '[' '' = 1 ']'
30: + : 48
30: + : 1
30: + : 0.002
30: + : 2254
30: + : 2
30: + : 2
30: + : ''
30: + : ''\'''\'''
30: + : 30065
30: + : 2524
30: + : 7
30: + : 4
30: + : ''
30: + : 0
30: + : 175000
30: + : 175000
30: + : 4500000
30: + : 0.66
30: + : 0.996
30: + : 0
30: + : 0.720
30: + : 0
30: + : 0.0
30: + : 0.0
30: + : 0.01
30: + : 0
30: + : 0
30: + : 0
30: + : 0
20: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
30: + : 0
30: + : 0
30: Run vars: id 2524 gpus 4 mparams ''
30: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
20: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
20: ++ export WALLTIME_MINUTES=15
20: ++ WALLTIME_MINUTES=15
20: ++ export WALLTIME=20
20: ++ WALLTIME=20
20: ++ export DGXNGPU=4
20: ++ DGXNGPU=4
20: ++ export DGXSOCKETCORES=64
20: ++ DGXSOCKETCORES=64
20: ++ export DGXNSOCKET=2
20: ++ DGXNSOCKET=2
20: ++ export DGXHT=1
20: ++ DGXHT=1
20: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
20: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
20: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
20: ++ export MLPERF_SUBMISSION_ORG=Dell
20: ++ MLPERF_SUBMISSION_ORG=Dell
20: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
20: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
20: ++ export OMP_NUM_THREADS=8
20: ++ OMP_NUM_THREADS=8
20: + ulimit -Sn 100000
20: + '[' '' = 1 ']'
30: ++ date +%s
20: + : 48
20: + : 1
20: + : 0.002
20: + : 2254
20: + : 2
20: + : 0
20: + : ''
20: + : ''\'''\'''
20: + : 30995
20: + : 2524
20: + : 5
20: + : 4
20: + : ''
20: + : 0
20: + : 175000
20: + : 175000
20: + : 4500000
20: + : 0.66
20: + : 0.996
20: + : 0
20: + : 0.720
20: + : 0
20: + : 0.0
20: + : 0.0
20: + : 0.01
20: + : 0
20: + : 0
20: + : 0
20: + : 0
20: + : 0
20: + : 0
20: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
20: Run vars: id 2524 gpus 4 mparams ''
20: ++ date +%s
30: + START=1665725682
30: ++ date '+%Y-%m-%d %r'
25: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
25: ++ export BATCHSIZE=48
25: ++ BATCHSIZE=48
25: ++ export GRADIENT_STEPS=1
25: ++ GRADIENT_STEPS=1
25: ++ export LR=0.002
25: ++ LR=0.002
25: ++ export MAX_SAMPLES_TERMINATION=4500000
25: ++ MAX_SAMPLES_TERMINATION=4500000
25: ++ export MAX_STEPS=2254
25: ++ MAX_STEPS=2254
25: ++ export OPT_LAMB_BETA_1=0.66
25: ++ OPT_LAMB_BETA_1=0.66
25: ++ export OPT_LAMB_BETA_2=0.996
25: ++ OPT_LAMB_BETA_2=0.996
25: ++ export START_WARMUP_STEP=0
25: ++ START_WARMUP_STEP=0
25: ++ export WARMUP_PROPORTION=0.0
25: ++ WARMUP_PROPORTION=0.0
25: ++ export WEIGHT_DECAY_RATE=0.01
25: ++ WEIGHT_DECAY_RATE=0.01
25: ++ export INIT_LOSS_SCALE=4096.0
25: ++ INIT_LOSS_SCALE=4096.0
25: ++ export SBATCH_NETWORK=sharp
25: ++ SBATCH_NETWORK=sharp
25: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
25: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
25: ++ export PHASE=2
25: ++ PHASE=2
25: ++ export EVAL_ITER_START_SAMPLES=175000
25: ++ EVAL_ITER_START_SAMPLES=175000
25: ++ export EVAL_ITER_SAMPLES=175000
25: ++ EVAL_ITER_SAMPLES=175000
25: ++ export DGXNNODES=8
25: ++ DGXNNODES=8
30: + START_FMT='2022-10-14 12:34:42 AM'
20: + START=1665725682
25: +++ sed 's/^config_//'
30: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
30: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
30: + '[' '!' -z '' ']'
30: + '[' 0 -gt 0 ']'
25: +++ sed 's/\.sh$//'
25: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
30: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
30: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
30: + PHASES=("$PHASE1" "$PHASE2")
30: + export RANK=30
30: + RANK=30
30: + export WORLD_SIZE=32
30: + WORLD_SIZE=32
30: WORLD_SIZE=32
30: + echo WORLD_SIZE=32
20: ++ date '+%Y-%m-%d %r'
30: ++ cut -d - -f1
30: ++ cut -d - -f2 -
30: ++ tr -d '['
30: ++ echo 'node[031-038]'
20: + START_FMT='2022-10-14 12:34:42 AM'
20: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
20: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
20: + '[' '!' -z '' ']'
20: + '[' 0 -gt 0 ']'
20: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
20: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
20: + PHASES=("$PHASE1" "$PHASE2")
20: + export RANK=20
20: + RANK=20
20: + export WORLD_SIZE=32
20: + WORLD_SIZE=32
20: WORLD_SIZE=32
20: + echo WORLD_SIZE=32
25: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
20: ++ cut -d - -f1
20: ++ cut -d - -f2 -
20: ++ tr -d '['
30: + export MASTER_ADDR=node031
30: + MASTER_ADDR=node031
20: ++ echo 'node[031-038]'
30: MASTER_ADDR=node031
30: + echo MASTER_ADDR=node031
30: + export MASTER_PORT=19002
30: + MASTER_PORT=19002
30: HOSTNAME=node031
30: + echo HOSTNAME=node031
30: + declare -a CMD
30: + [[ -n 2 ]]
30: + [[ 32 -gt 8 ]]
30: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
30: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
30: -bert_config_path=/workspace/phase1/bert_config.json '
30: + '[' -n 2 ']'
30: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
30: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
30: + [[ 0 != 1 ]]
30: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
30: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
30: + [[ '' -ge 1 ]]
30: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
30: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
30: + [[ 0 != 0 ]]
30: + '[' '' = apiLog.sh ']'
30: + '[' '' = 1 ']'
30: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
30: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=30065'
30: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
30: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=30065
25: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
25: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
25: ++ export WALLTIME_MINUTES=15
25: ++ WALLTIME_MINUTES=15
25: ++ export WALLTIME=20
25: ++ WALLTIME=20
25: ++ export DGXNGPU=4
25: ++ DGXNGPU=4
25: ++ export DGXSOCKETCORES=64
25: ++ DGXSOCKETCORES=64
25: ++ export DGXNSOCKET=2
25: ++ DGXNSOCKET=2
25: ++ export DGXHT=1
25: ++ DGXHT=1
25: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
25: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
25: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
25: ++ export MLPERF_SUBMISSION_ORG=Dell
25: ++ MLPERF_SUBMISSION_ORG=Dell
25: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
25: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
25: ++ export OMP_NUM_THREADS=8
25: ++ OMP_NUM_THREADS=8
25: + ulimit -Sn 100000
25: + '[' '' = 1 ']'
25: + : 48
25: + : 1
25: + : 0.002
25: + : 2254
25: + : 2
25: + : 1
25: + : ''
25: + : ''\'''\'''
25: + : 3267
25: + : 2524
25: + : 6
25: + : 4
25: + : ''
25: + : 0
25: + : 175000
25: + : 175000
25: + : 4500000
25: + : 0.66
25: + : 0.996
25: + : 0
25: + : 0.720
25: + : 0
25: + : 0.0
25: + : 0.0
25: + : 0.01
25: + : 0
25: + : 0
25: + : 0
25: + : 0
25: + : 0
25: + : 0
25: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
25: Run vars: id 2524 gpus 4 mparams ''
20: + export MASTER_ADDR=node031
20: + MASTER_ADDR=node031
25: ++ date +%s
20: + echo MASTER_ADDR=node031
20: MASTER_ADDR=node031
20: + export MASTER_PORT=19002
20: + MASTER_PORT=19002
20: HOSTNAME=node031
20: + echo HOSTNAME=node031
20: + declare -a CMD
20: + [[ -n 0 ]]
20: + [[ 32 -gt 8 ]]
20: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
20: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
20: -bert_config_path=/workspace/phase1/bert_config.json '
20: + '[' -n 0 ']'
20: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
20: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
20: + [[ 0 != 1 ]]
20: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
20: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
20: + [[ '' -ge 1 ]]
20: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
20: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
20: + [[ 0 != 0 ]]
20: + '[' '' = apiLog.sh ']'
20: + '[' '' = 1 ']'
20: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
20: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=30995'
20: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
20: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=30995
25: + START=1665725682
25: ++ date '+%Y-%m-%d %r'
25: + START_FMT='2022-10-14 12:34:42 AM'
25: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
25: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
25: + '[' '!' -z '' ']'
25: + '[' 0 -gt 0 ']'
25: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
25: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
25: + PHASES=("$PHASE1" "$PHASE2")
25: + export RANK=25
25: + RANK=25
25: + export WORLD_SIZE=32
25: + WORLD_SIZE=32
25: WORLD_SIZE=32
25: + echo WORLD_SIZE=32
25: ++ cut -d - -f1
25: ++ cut -d - -f2 -
25: ++ echo 'node[031-038]'
25: ++ tr -d '['
22: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
22: ++ export BATCHSIZE=48
22: ++ BATCHSIZE=48
22: ++ export GRADIENT_STEPS=1
22: ++ GRADIENT_STEPS=1
22: ++ export LR=0.002
22: ++ LR=0.002
22: ++ export MAX_SAMPLES_TERMINATION=4500000
22: ++ MAX_SAMPLES_TERMINATION=4500000
22: ++ export MAX_STEPS=2254
22: ++ MAX_STEPS=2254
22: ++ export OPT_LAMB_BETA_1=0.66
22: ++ OPT_LAMB_BETA_1=0.66
22: ++ export OPT_LAMB_BETA_2=0.996
22: ++ OPT_LAMB_BETA_2=0.996
22: ++ export START_WARMUP_STEP=0
22: ++ START_WARMUP_STEP=0
22: ++ export WARMUP_PROPORTION=0.0
22: ++ WARMUP_PROPORTION=0.0
22: ++ export WEIGHT_DECAY_RATE=0.01
22: ++ WEIGHT_DECAY_RATE=0.01
22: ++ export INIT_LOSS_SCALE=4096.0
22: ++ INIT_LOSS_SCALE=4096.0
22: ++ export SBATCH_NETWORK=sharp
22: ++ SBATCH_NETWORK=sharp
22: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
22: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
22: ++ export PHASE=2
22: ++ PHASE=2
22: ++ export EVAL_ITER_START_SAMPLES=175000
22: ++ EVAL_ITER_START_SAMPLES=175000
22: ++ export EVAL_ITER_SAMPLES=175000
22: ++ EVAL_ITER_SAMPLES=175000
22: ++ export DGXNNODES=8
22: ++ DGXNNODES=8
22: +++ sed 's/^config_//'
22: +++ sed 's/\.sh$//'
22: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
25: + export MASTER_ADDR=node031
25: + MASTER_ADDR=node031
25: + echo MASTER_ADDR=node031
25: MASTER_ADDR=node031
25: + export MASTER_PORT=19002
25: + MASTER_PORT=19002
25: HOSTNAME=node031
25: + echo HOSTNAME=node031
25: + declare -a CMD
25: + [[ -n 1 ]]
25: + [[ 32 -gt 8 ]]
25: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
25: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
25: -bert_config_path=/workspace/phase1/bert_config.json '
25: + '[' -n 1 ']'
25: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
25: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
25: + [[ 0 != 1 ]]
25: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
25: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
25: + [[ '' -ge 1 ]]
25: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
25: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
25: + [[ 0 != 0 ]]
25: + '[' '' = apiLog.sh ']'
25: + '[' '' = 1 ']'
25: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
25: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=3267'
22: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
25: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
25: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=3267
22: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
22: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
22: ++ export WALLTIME_MINUTES=15
22: ++ WALLTIME_MINUTES=15
22: ++ export WALLTIME=20
22: ++ WALLTIME=20
22: ++ export DGXNGPU=4
22: ++ DGXNGPU=4
22: ++ export DGXSOCKETCORES=64
22: ++ DGXSOCKETCORES=64
22: ++ export DGXNSOCKET=2
22: ++ DGXNSOCKET=2
22: ++ export DGXHT=1
22: ++ DGXHT=1
22: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
22: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
22: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
22: ++ export MLPERF_SUBMISSION_ORG=Dell
22: ++ MLPERF_SUBMISSION_ORG=Dell
22: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
22: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
22: ++ export OMP_NUM_THREADS=8
22: ++ OMP_NUM_THREADS=8
22: + ulimit -Sn 100000
22: + '[' '' = 1 ']'
22: + : 48
22: + : 1
22: + : 0.002
22: + : 2254
22: + : 2
22: + : 2
22: + : ''
22: + : ''\'''\'''
22: + : 124
22: + : 2524
22: + : 5
22: + : 4
22: + : ''
22: + : 0
22: + : 175000
22: + : 175000
22: + : 4500000
22: + : 0.66
22: + : 0.996
22: + : 0
22: + : 0.720
22: + : 0
22: + : 0.0
22: + : 0.0
22: + : 0.01
22: + : 0
22: + : 0
22: + : 0
22: + : 0
22: + : 0
22: + : 0
22: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
22: Run vars: id 2524 gpus 4 mparams ''
22: ++ date +%s
22: + START=1665725682
22: ++ date '+%Y-%m-%d %r'
22: + START_FMT='2022-10-14 12:34:42 AM'
22: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
22: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
22: + '[' '!' -z '' ']'
22: + '[' 0 -gt 0 ']'
22: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
22: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
22: + PHASES=("$PHASE1" "$PHASE2")
22: + export RANK=22
22: + RANK=22
22: + export WORLD_SIZE=32
22: + WORLD_SIZE=32
22: WORLD_SIZE=32
22: + echo WORLD_SIZE=32
22: ++ cut -d - -f1
22: ++ cut -d - -f2 -
22: ++ echo 'node[031-038]'
22: ++ tr -d '['
22: + export MASTER_ADDR=node031
22: + MASTER_ADDR=node031
22: + echo MASTER_ADDR=node031
22: MASTER_ADDR=node031
22: + export MASTER_PORT=19002
22: + MASTER_PORT=19002
22: HOSTNAME=node031
22: + echo HOSTNAME=node031
22: + declare -a CMD
22: + [[ -n 2 ]]
22: + [[ 32 -gt 8 ]]
22: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
22: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
22: -bert_config_path=/workspace/phase1/bert_config.json '
22: + '[' -n 2 ']'
22: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
22: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
22: + [[ 0 != 1 ]]
22: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
22: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
22: + [[ '' -ge 1 ]]
22: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
22: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
22: + [[ 0 != 0 ]]
22: + '[' '' = apiLog.sh ']'
22: + '[' '' = 1 ']'
22: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
22: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=124'
22: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
22: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=124
 4: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
 4: ++ export BATCHSIZE=48
 4: ++ BATCHSIZE=48
 4: ++ export GRADIENT_STEPS=1
 4: ++ GRADIENT_STEPS=1
 4: ++ export LR=0.002
 4: ++ LR=0.002
 4: ++ export MAX_SAMPLES_TERMINATION=4500000
 4: ++ MAX_SAMPLES_TERMINATION=4500000
 4: ++ export MAX_STEPS=2254
 4: ++ MAX_STEPS=2254
 4: ++ export OPT_LAMB_BETA_1=0.66
 4: ++ OPT_LAMB_BETA_1=0.66
 4: ++ export OPT_LAMB_BETA_2=0.996
 4: ++ OPT_LAMB_BETA_2=0.996
 4: ++ export START_WARMUP_STEP=0
 4: ++ START_WARMUP_STEP=0
 4: ++ export WARMUP_PROPORTION=0.0
 4: ++ WARMUP_PROPORTION=0.0
 4: ++ export WEIGHT_DECAY_RATE=0.01
 4: ++ WEIGHT_DECAY_RATE=0.01
 4: ++ export INIT_LOSS_SCALE=4096.0
 4: ++ INIT_LOSS_SCALE=4096.0
 4: ++ export SBATCH_NETWORK=sharp
 4: ++ SBATCH_NETWORK=sharp
 4: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 4: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 4: ++ export PHASE=2
 4: ++ PHASE=2
 4: ++ export EVAL_ITER_START_SAMPLES=175000
 4: ++ EVAL_ITER_START_SAMPLES=175000
 4: ++ export EVAL_ITER_SAMPLES=175000
 4: ++ EVAL_ITER_SAMPLES=175000
 4: ++ export DGXNNODES=8
 4: ++ DGXNNODES=8
 4: +++ sed 's/^config_//'
 4: +++ sed 's/\.sh$//'
 4: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
 4: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
 4: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
 4: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
 4: ++ export WALLTIME_MINUTES=15
 4: ++ WALLTIME_MINUTES=15
 4: ++ export WALLTIME=20
 4: ++ WALLTIME=20
 4: ++ export DGXNGPU=4
 4: ++ DGXNGPU=4
 4: ++ export DGXSOCKETCORES=64
 4: ++ DGXSOCKETCORES=64
 4: ++ export DGXNSOCKET=2
 4: ++ DGXNSOCKET=2
 4: ++ export DGXHT=1
 4: ++ DGXHT=1
 4: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
 4: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
 4: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
 4: ++ export MLPERF_SUBMISSION_ORG=Dell
 4: ++ MLPERF_SUBMISSION_ORG=Dell
 4: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
 4: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
 4: ++ export OMP_NUM_THREADS=8
 4: ++ OMP_NUM_THREADS=8
 4: + ulimit -Sn 100000
 4: + '[' '' = 1 ']'
 4: + : 48
 4: + : 1
 4: + : 0.002
 4: + : 2254
 4: + : 2
16: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
 4: + : 0
 4: + : ''
 4: + : ''\'''\'''
 4: + : 9791
 4: + : 2524
 4: + : 1
 4: + : 4
 4: + : ''
 4: + : 0
 4: + : 175000
 4: + : 175000
 4: + : 4500000
 4: + : 0.66
 4: + : 0.996
 4: + : 0
 4: + : 0.720
 4: + : 0
 4: + : 0.0
 4: + : 0.0
 4: + : 0.01
 4: + : 0
 4: + : 0
 4: + : 0
 4: + : 0
 4: + : 0
 4: + : 0
 4: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
 4: Run vars: id 2524 gpus 4 mparams ''
 4: ++ date +%s
16: ++ export BATCHSIZE=48
16: ++ BATCHSIZE=48
16: ++ export GRADIENT_STEPS=1
16: ++ GRADIENT_STEPS=1
16: ++ export LR=0.002
16: ++ LR=0.002
16: ++ export MAX_SAMPLES_TERMINATION=4500000
16: ++ MAX_SAMPLES_TERMINATION=4500000
16: ++ export MAX_STEPS=2254
16: ++ MAX_STEPS=2254
16: ++ export OPT_LAMB_BETA_1=0.66
16: ++ OPT_LAMB_BETA_1=0.66
16: ++ export OPT_LAMB_BETA_2=0.996
16: ++ OPT_LAMB_BETA_2=0.996
16: ++ export START_WARMUP_STEP=0
16: ++ START_WARMUP_STEP=0
16: ++ export WARMUP_PROPORTION=0.0
16: ++ WARMUP_PROPORTION=0.0
16: ++ export WEIGHT_DECAY_RATE=0.01
16: ++ WEIGHT_DECAY_RATE=0.01
16: ++ export INIT_LOSS_SCALE=4096.0
16: ++ INIT_LOSS_SCALE=4096.0
16: ++ export SBATCH_NETWORK=sharp
16: ++ SBATCH_NETWORK=sharp
16: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
16: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
16: ++ export PHASE=2
16: ++ PHASE=2
16: ++ export EVAL_ITER_START_SAMPLES=175000
16: ++ EVAL_ITER_START_SAMPLES=175000
16: ++ export EVAL_ITER_SAMPLES=175000
16: ++ EVAL_ITER_SAMPLES=175000
16: ++ export DGXNNODES=8
16: ++ DGXNNODES=8
14: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
16: +++ sed 's/^config_//'
16: +++ sed 's/\.sh$//'
14: ++ export BATCHSIZE=48
14: ++ BATCHSIZE=48
16: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
14: ++ export GRADIENT_STEPS=1
14: ++ GRADIENT_STEPS=1
14: ++ export LR=0.002
14: ++ LR=0.002
14: ++ export MAX_SAMPLES_TERMINATION=4500000
14: ++ MAX_SAMPLES_TERMINATION=4500000
14: ++ export MAX_STEPS=2254
14: ++ MAX_STEPS=2254
14: ++ export OPT_LAMB_BETA_1=0.66
14: ++ OPT_LAMB_BETA_1=0.66
14: ++ export OPT_LAMB_BETA_2=0.996
14: ++ OPT_LAMB_BETA_2=0.996
14: ++ export START_WARMUP_STEP=0
14: ++ START_WARMUP_STEP=0
14: ++ export WARMUP_PROPORTION=0.0
14: ++ WARMUP_PROPORTION=0.0
14: ++ export WEIGHT_DECAY_RATE=0.01
14: ++ WEIGHT_DECAY_RATE=0.01
14: ++ export INIT_LOSS_SCALE=4096.0
14: ++ INIT_LOSS_SCALE=4096.0
14: ++ export SBATCH_NETWORK=sharp
14: ++ SBATCH_NETWORK=sharp
14: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
14: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
14: ++ export PHASE=2
14: ++ PHASE=2
14: ++ export EVAL_ITER_START_SAMPLES=175000
14: ++ EVAL_ITER_START_SAMPLES=175000
14: ++ export EVAL_ITER_SAMPLES=175000
14: ++ EVAL_ITER_SAMPLES=175000
14: ++ export DGXNNODES=8
14: ++ DGXNNODES=8
14: +++ sed 's/^config_//'
14: +++ sed 's/\.sh$//'
14: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
26: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
 4: + START=1665725682
26: ++ export BATCHSIZE=48
26: ++ BATCHSIZE=48
26: ++ export GRADIENT_STEPS=1
26: ++ GRADIENT_STEPS=1
26: ++ export LR=0.002
26: ++ LR=0.002
26: ++ export MAX_SAMPLES_TERMINATION=4500000
26: ++ MAX_SAMPLES_TERMINATION=4500000
26: ++ export MAX_STEPS=2254
26: ++ MAX_STEPS=2254
26: ++ export OPT_LAMB_BETA_1=0.66
26: ++ OPT_LAMB_BETA_1=0.66
26: ++ export OPT_LAMB_BETA_2=0.996
26: ++ OPT_LAMB_BETA_2=0.996
26: ++ export START_WARMUP_STEP=0
26: ++ START_WARMUP_STEP=0
26: ++ export WARMUP_PROPORTION=0.0
26: ++ WARMUP_PROPORTION=0.0
26: ++ export WEIGHT_DECAY_RATE=0.01
26: ++ WEIGHT_DECAY_RATE=0.01
 4: ++ date '+%Y-%m-%d %r'
26: ++ export INIT_LOSS_SCALE=4096.0
26: ++ INIT_LOSS_SCALE=4096.0
26: ++ export SBATCH_NETWORK=sharp
26: ++ SBATCH_NETWORK=sharp
26: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
26: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
26: ++ export PHASE=2
26: ++ PHASE=2
26: ++ export EVAL_ITER_START_SAMPLES=175000
26: ++ EVAL_ITER_START_SAMPLES=175000
26: ++ export EVAL_ITER_SAMPLES=175000
26: ++ EVAL_ITER_SAMPLES=175000
26: ++ export DGXNNODES=8
26: ++ DGXNNODES=8
16: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
26: +++ sed 's/^config_//'
26: +++ sed 's/\.sh$//'
26: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
 4: + START_FMT='2022-10-14 12:34:42 AM'
 4: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
 4: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
 4: + '[' '!' -z '' ']'
14: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
 4: + '[' 0 -gt 0 ']'
 4: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
 4: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
 4: + PHASES=("$PHASE1" "$PHASE2")
 4: + export RANK=4
 4: + RANK=4
21: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
 4: + export WORLD_SIZE=32
 4: + WORLD_SIZE=32
 4: WORLD_SIZE=32
 4: + echo WORLD_SIZE=32
21: ++ export BATCHSIZE=48
21: ++ BATCHSIZE=48
21: ++ export GRADIENT_STEPS=1
21: ++ GRADIENT_STEPS=1
21: ++ export LR=0.002
21: ++ LR=0.002
21: ++ export MAX_SAMPLES_TERMINATION=4500000
21: ++ MAX_SAMPLES_TERMINATION=4500000
21: ++ export MAX_STEPS=2254
21: ++ MAX_STEPS=2254
21: ++ export OPT_LAMB_BETA_1=0.66
21: ++ OPT_LAMB_BETA_1=0.66
21: ++ export OPT_LAMB_BETA_2=0.996
21: ++ OPT_LAMB_BETA_2=0.996
21: ++ export START_WARMUP_STEP=0
21: ++ START_WARMUP_STEP=0
21: ++ export WARMUP_PROPORTION=0.0
21: ++ WARMUP_PROPORTION=0.0
21: ++ export WEIGHT_DECAY_RATE=0.01
21: ++ WEIGHT_DECAY_RATE=0.01
21: ++ export INIT_LOSS_SCALE=4096.0
21: ++ INIT_LOSS_SCALE=4096.0
21: ++ export SBATCH_NETWORK=sharp
21: ++ SBATCH_NETWORK=sharp
21: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
21: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
21: ++ export PHASE=2
21: ++ PHASE=2
21: ++ export EVAL_ITER_START_SAMPLES=175000
21: ++ EVAL_ITER_START_SAMPLES=175000
21: ++ export EVAL_ITER_SAMPLES=175000
21: ++ EVAL_ITER_SAMPLES=175000
21: ++ export DGXNNODES=8
21: ++ DGXNNODES=8
 4: ++ cut -d - -f1
 4: ++ cut -d - -f2 -
 4: ++ tr -d '['
21: +++ sed 's/^config_//'
21: +++ sed 's/\.sh$//'
21: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
 4: ++ echo 'node[031-038]'
26: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
16: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
16: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
16: ++ export WALLTIME_MINUTES=15
16: ++ WALLTIME_MINUTES=15
16: ++ export WALLTIME=20
16: ++ WALLTIME=20
16: ++ export DGXNGPU=4
16: ++ DGXNGPU=4
16: ++ export DGXSOCKETCORES=64
16: ++ DGXSOCKETCORES=64
16: ++ export DGXNSOCKET=2
16: ++ DGXNSOCKET=2
16: ++ export DGXHT=1
16: ++ DGXHT=1
16: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
16: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
16: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
16: ++ export MLPERF_SUBMISSION_ORG=Dell
16: ++ MLPERF_SUBMISSION_ORG=Dell
16: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
16: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
16: ++ export OMP_NUM_THREADS=8
16: ++ OMP_NUM_THREADS=8
16: + ulimit -Sn 100000
16: + '[' '' = 1 ']'
16: + : 48
16: + : 1
16: + : 0.002
16: + : 2254
16: + : 2
16: + : 0
16: + : ''
16: + : ''\'''\'''
16: + : 17731
16: + : 2524
16: + : 4
16: + : 4
16: + : ''
16: + : 0
16: + : 175000
16: + : 175000
16: + : 4500000
16: + : 0.66
16: + : 0.996
16: + : 0
16: + : 0.720
16: + : 0
16: + : 0.0
16: + : 0.0
16: + : 0.01
16: + : 0
16: + : 0
16: + : 0
16: + : 0
16: + : 0
16: + : 0
16: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
16: Run vars: id 2524 gpus 4 mparams ''
14: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
14: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
16: ++ date +%s
14: ++ export WALLTIME_MINUTES=15
14: ++ WALLTIME_MINUTES=15
14: ++ export WALLTIME=20
14: ++ WALLTIME=20
14: ++ export DGXNGPU=4
14: ++ DGXNGPU=4
14: ++ export DGXSOCKETCORES=64
14: ++ DGXSOCKETCORES=64
14: ++ export DGXNSOCKET=2
14: ++ DGXNSOCKET=2
14: ++ export DGXHT=1
14: ++ DGXHT=1
14: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
14: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
14: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
14: ++ export MLPERF_SUBMISSION_ORG=Dell
14: ++ MLPERF_SUBMISSION_ORG=Dell
14: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
14: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
14: ++ export OMP_NUM_THREADS=8
14: ++ OMP_NUM_THREADS=8
14: + ulimit -Sn 100000
14: + '[' '' = 1 ']'
14: + : 48
14: + : 1
14: + : 0.002
14: + : 2254
14: + : 2
14: + : 2
14: + : ''
14: + : ''\'''\'''
14: + : 25594
14: + : 2524
14: + : 3
14: + : 4
14: + : ''
14: + : 0
14: + : 175000
14: + : 175000
14: + : 4500000
14: + : 0.66
14: + : 0.996
14: + : 0
14: + : 0.720
14: + : 0
14: + : 0.0
14: + : 0.0
14: + : 0.01
14: + : 0
14: + : 0
14: + : 0
14: + : 0
14: + : 0
14: + : 0
14: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
14: Run vars: id 2524 gpus 4 mparams ''
21: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
14: ++ date +%s
 4: + export MASTER_ADDR=node031
 4: + MASTER_ADDR=node031
 4: MASTER_ADDR=node031
 4: + echo MASTER_ADDR=node031
 4: + export MASTER_PORT=19002
 4: + MASTER_PORT=19002
 4: HOSTNAME=node031
 4: + echo HOSTNAME=node031
 4: + declare -a CMD
 4: + [[ -n 0 ]]
 4: + [[ 32 -gt 8 ]]
 4: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
 4: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 4: -bert_config_path=/workspace/phase1/bert_config.json '
 4: + '[' -n 0 ']'
 4: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 4: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
 4: + [[ 0 != 1 ]]
 4: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 4: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
 4: + [[ '' -ge 1 ]]
 4: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 4: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
 4: + [[ 0 != 0 ]]
 4: + '[' '' = apiLog.sh ']'
 4: + '[' '' = 1 ']'
 4: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
 4: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=9791'
 4: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
 4: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=9791
26: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
26: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
26: ++ export WALLTIME_MINUTES=15
26: ++ WALLTIME_MINUTES=15
26: ++ export WALLTIME=20
26: ++ WALLTIME=20
26: ++ export DGXNGPU=4
26: ++ DGXNGPU=4
26: ++ export DGXSOCKETCORES=64
26: ++ DGXSOCKETCORES=64
26: ++ export DGXNSOCKET=2
26: ++ DGXNSOCKET=2
26: ++ export DGXHT=1
26: ++ DGXHT=1
26: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
26: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
26: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
26: ++ export MLPERF_SUBMISSION_ORG=Dell
26: ++ MLPERF_SUBMISSION_ORG=Dell
26: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
26: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
26: ++ export OMP_NUM_THREADS=8
26: ++ OMP_NUM_THREADS=8
26: + ulimit -Sn 100000
26: + '[' '' = 1 ']'
26: + : 48
26: + : 1
26: + : 0.002
26: + : 2254
26: + : 2
26: + : 2
26: + : ''
26: + : ''\'''\'''
26: + : 6089
26: + : 2524
26: + : 6
26: + : 4
26: + : ''
26: + : 0
26: + : 175000
26: + : 175000
26: + : 4500000
26: + : 0.66
26: + : 0.996
26: + : 0
26: + : 0.720
26: + : 0
26: + : 0.0
26: + : 0.0
26: + : 0.01
26: + : 0
26: + : 0
26: + : 0
26: + : 0
26: + : 0
26: + : 0
26: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
26: Run vars: id 2524 gpus 4 mparams ''
26: ++ date +%s
16: + START=1665725682
16: ++ date '+%Y-%m-%d %r'
14: + START=1665725682
21: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
14: ++ date '+%Y-%m-%d %r'
21: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
21: ++ export WALLTIME_MINUTES=15
21: ++ WALLTIME_MINUTES=15
21: ++ export WALLTIME=20
21: ++ WALLTIME=20
21: ++ export DGXNGPU=4
21: ++ DGXNGPU=4
21: ++ export DGXSOCKETCORES=64
21: ++ DGXSOCKETCORES=64
21: ++ export DGXNSOCKET=2
21: ++ DGXNSOCKET=2
21: ++ export DGXHT=1
21: ++ DGXHT=1
21: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
21: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
21: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
21: ++ export MLPERF_SUBMISSION_ORG=Dell
21: ++ MLPERF_SUBMISSION_ORG=Dell
21: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
21: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
21: ++ export OMP_NUM_THREADS=8
21: ++ OMP_NUM_THREADS=8
21: + ulimit -Sn 100000
21: + '[' '' = 1 ']'
21: + : 48
21: + : 1
21: + : 0.002
21: + : 2254
21: + : 2
21: + : 1
21: + : ''
21: + : ''\'''\'''
21: + : 26817
21: + : 2524
21: + : 5
21: + : 4
21: + : ''
21: + : 0
21: + : 175000
21: + : 175000
21: + : 4500000
21: + : 0.66
21: + : 0.996
21: + : 0
21: + : 0.720
21: + : 0
21: + : 0.0
21: + : 0.0
21: + : 0.01
21: + : 0
21: + : 0
21: + : 0
21: + : 0
21: + : 0
21: + : 0
21: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
21: Run vars: id 2524 gpus 4 mparams ''
16: + START_FMT='2022-10-14 12:34:42 AM'
16: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
16: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
16: + '[' '!' -z '' ']'
16: + '[' 0 -gt 0 ']'
21: ++ date +%s
16: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
16: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
14: + START_FMT='2022-10-14 12:34:42 AM'
16: + PHASES=("$PHASE1" "$PHASE2")
16: + export RANK=16
16: + RANK=16
16: + export WORLD_SIZE=32
16: + WORLD_SIZE=32
16: WORLD_SIZE=32
14: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
16: + echo WORLD_SIZE=32
14: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
14: + '[' '!' -z '' ']'
14: + '[' 0 -gt 0 ']'
14: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
14: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
14: + PHASES=("$PHASE1" "$PHASE2")
14: + export RANK=14
14: + RANK=14
14: + export WORLD_SIZE=32
14: + WORLD_SIZE=32
14: WORLD_SIZE=32
14: + echo WORLD_SIZE=32
26: + START=1665725682
16: ++ cut -d - -f1
16: ++ cut -d - -f2 -
16: ++ tr -d '['
26: ++ date '+%Y-%m-%d %r'
14: ++ cut -d - -f1
14: ++ cut -d - -f2 -
14: ++ tr -d '['
16: ++ echo 'node[031-038]'
26: + START_FMT='2022-10-14 12:34:42 AM'
26: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
26: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
26: + '[' '!' -z '' ']'
26: + '[' 0 -gt 0 ']'
26: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
14: ++ echo 'node[031-038]'
26: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
21: + START=1665725682
26: + PHASES=("$PHASE1" "$PHASE2")
26: + export RANK=26
26: + RANK=26
26: + export WORLD_SIZE=32
26: + WORLD_SIZE=32
26: WORLD_SIZE=32
26: + echo WORLD_SIZE=32
21: ++ date '+%Y-%m-%d %r'
26: ++ cut -d - -f1
26: ++ cut -d - -f2 -
26: ++ tr -d '['
26: ++ echo 'node[031-038]'
21: + START_FMT='2022-10-14 12:34:42 AM'
21: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
21: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
21: + '[' '!' -z '' ']'
21: + '[' 0 -gt 0 ']'
21: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
21: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
21: + PHASES=("$PHASE1" "$PHASE2")
21: + export RANK=21
21: + RANK=21
21: + export WORLD_SIZE=32
21: + WORLD_SIZE=32
21: WORLD_SIZE=32
21: + echo WORLD_SIZE=32
16: + export MASTER_ADDR=node031
16: + MASTER_ADDR=node031
16: MASTER_ADDR=node031
16: + echo MASTER_ADDR=node031
16: + export MASTER_PORT=19002
16: + MASTER_PORT=19002
16: HOSTNAME=node031
16: + echo HOSTNAME=node031
16: + declare -a CMD
16: + [[ -n 0 ]]
16: + [[ 32 -gt 8 ]]
16: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
16: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
21: ++ cut -d - -f1
14: + export MASTER_ADDR=node031
14: + MASTER_ADDR=node031
16: -bert_config_path=/workspace/phase1/bert_config.json '
21: ++ cut -d - -f2 -
16: + '[' -n 0 ']'
16: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
16: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
16: + [[ 0 != 1 ]]
14: MASTER_ADDR=node031
16: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
16: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
16: + [[ '' -ge 1 ]]
14: + echo MASTER_ADDR=node031
14: HOSTNAME=node031
14: + export MASTER_PORT=19002
14: + MASTER_PORT=19002
14: + echo HOSTNAME=node031
14: + declare -a CMD
21: ++ tr -d '['
16: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
14: + [[ -n 2 ]]
16: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
14: + [[ 32 -gt 8 ]]
16: + [[ 0 != 0 ]]
14: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
16: + '[' '' = apiLog.sh ']'
16: + '[' '' = 1 ']'
21: ++ echo 'node[031-038]'
16: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
16: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=17731'
14: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
16: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
16: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=17731
14: -bert_config_path=/workspace/phase1/bert_config.json '
14: + '[' -n 2 ']'
14: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
14: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
14: + [[ 0 != 1 ]]
14: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
14: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
14: + [[ '' -ge 1 ]]
14: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
14: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
14: + [[ 0 != 0 ]]
14: + '[' '' = apiLog.sh ']'
14: + '[' '' = 1 ']'
14: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
14: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=25594'
14: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
14: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=25594
26: + export MASTER_ADDR=node031
26: + MASTER_ADDR=node031
26: MASTER_ADDR=node031
26: + echo MASTER_ADDR=node031
26: + export MASTER_PORT=19002
26: + MASTER_PORT=19002
26: HOSTNAME=node031
26: + echo HOSTNAME=node031
26: + declare -a CMD
26: + [[ -n 2 ]]
26: + [[ 32 -gt 8 ]]
26: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
26: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
26: -bert_config_path=/workspace/phase1/bert_config.json '
26: + '[' -n 2 ']'
26: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
26: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
26: + [[ 0 != 1 ]]
26: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
26: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
26: + [[ '' -ge 1 ]]
26: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
26: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
26: + [[ 0 != 0 ]]
26: + '[' '' = apiLog.sh ']'
26: + '[' '' = 1 ']'
26: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
26: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=6089'
26: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
26: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=6089
21: + export MASTER_ADDR=node031
21: + MASTER_ADDR=node031
21: MASTER_ADDR=node031
21: + echo MASTER_ADDR=node031
21: + export MASTER_PORT=19002
21: + MASTER_PORT=19002
21: + echo HOSTNAME=node031
21: HOSTNAME=node031
21: + declare -a CMD
21: + [[ -n 1 ]]
21: + [[ 32 -gt 8 ]]
21: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
21: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
21: -bert_config_path=/workspace/phase1/bert_config.json '
21: + '[' -n 1 ']'
21: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
21: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
21: + [[ 0 != 1 ]]
21: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
21: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
21: + [[ '' -ge 1 ]]
21: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
21: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
21: + [[ 0 != 0 ]]
21: + '[' '' = apiLog.sh ']'
21: + '[' '' = 1 ']'
21: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
21: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=26817'
21: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
21: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=26817
12: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
12: ++ export BATCHSIZE=48
12: ++ BATCHSIZE=48
12: ++ export GRADIENT_STEPS=1
12: ++ GRADIENT_STEPS=1
12: ++ export LR=0.002
12: ++ LR=0.002
12: ++ export MAX_SAMPLES_TERMINATION=4500000
12: ++ MAX_SAMPLES_TERMINATION=4500000
12: ++ export MAX_STEPS=2254
12: ++ MAX_STEPS=2254
12: ++ export OPT_LAMB_BETA_1=0.66
12: ++ OPT_LAMB_BETA_1=0.66
12: ++ export OPT_LAMB_BETA_2=0.996
12: ++ OPT_LAMB_BETA_2=0.996
12: ++ export START_WARMUP_STEP=0
12: ++ START_WARMUP_STEP=0
12: ++ export WARMUP_PROPORTION=0.0
12: ++ WARMUP_PROPORTION=0.0
12: ++ export WEIGHT_DECAY_RATE=0.01
12: ++ WEIGHT_DECAY_RATE=0.01
12: ++ export INIT_LOSS_SCALE=4096.0
12: ++ INIT_LOSS_SCALE=4096.0
12: ++ export SBATCH_NETWORK=sharp
12: ++ SBATCH_NETWORK=sharp
12: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
12: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
12: ++ export PHASE=2
12: ++ PHASE=2
12: ++ export EVAL_ITER_START_SAMPLES=175000
12: ++ EVAL_ITER_START_SAMPLES=175000
12: ++ export EVAL_ITER_SAMPLES=175000
12: ++ EVAL_ITER_SAMPLES=175000
12: ++ export DGXNNODES=8
12: ++ DGXNNODES=8
12: +++ sed 's/^config_//'
12: +++ sed 's/\.sh$//'
12: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
12: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
10: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
12: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
12: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
10: ++ export BATCHSIZE=48
10: ++ BATCHSIZE=48
12: ++ export WALLTIME_MINUTES=15
12: ++ WALLTIME_MINUTES=15
12: ++ export WALLTIME=20
12: ++ WALLTIME=20
12: ++ export DGXNGPU=4
12: ++ DGXNGPU=4
12: ++ export DGXSOCKETCORES=64
12: ++ DGXSOCKETCORES=64
12: ++ export DGXNSOCKET=2
12: ++ DGXNSOCKET=2
12: ++ export DGXHT=1
12: ++ DGXHT=1
12: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
12: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
12: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
10: ++ export GRADIENT_STEPS=1
10: ++ GRADIENT_STEPS=1
10: ++ export LR=0.002
10: ++ LR=0.002
10: ++ export MAX_SAMPLES_TERMINATION=4500000
10: ++ MAX_SAMPLES_TERMINATION=4500000
10: ++ export MAX_STEPS=2254
10: ++ MAX_STEPS=2254
10: ++ export OPT_LAMB_BETA_1=0.66
10: ++ OPT_LAMB_BETA_1=0.66
10: ++ export OPT_LAMB_BETA_2=0.996
10: ++ OPT_LAMB_BETA_2=0.996
12: ++ export MLPERF_SUBMISSION_ORG=Dell
10: ++ export START_WARMUP_STEP=0
10: ++ START_WARMUP_STEP=0
12: ++ MLPERF_SUBMISSION_ORG=Dell
10: ++ export WARMUP_PROPORTION=0.0
12: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
12: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
10: ++ WARMUP_PROPORTION=0.0
12: ++ export OMP_NUM_THREADS=8
12: ++ OMP_NUM_THREADS=8
10: ++ export WEIGHT_DECAY_RATE=0.01
10: ++ WEIGHT_DECAY_RATE=0.01
12: + ulimit -Sn 100000
12: + '[' '' = 1 ']'
12: + : 48
12: + : 1
12: + : 0.002
12: + : 2254
10: ++ export INIT_LOSS_SCALE=4096.0
10: ++ INIT_LOSS_SCALE=4096.0
10: ++ export SBATCH_NETWORK=sharp
10: ++ SBATCH_NETWORK=sharp
10: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
10: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
12: + : 2
10: ++ export PHASE=2
10: ++ PHASE=2
12: + : 0
10: ++ export EVAL_ITER_START_SAMPLES=175000
10: ++ EVAL_ITER_START_SAMPLES=175000
12: + : ''
10: ++ export EVAL_ITER_SAMPLES=175000
10: ++ EVAL_ITER_SAMPLES=175000
12: + : ''\'''\'''
10: ++ export DGXNNODES=8
10: ++ DGXNNODES=8
12: + : 23150
12: + : 2524
12: + : 3
12: + : 4
12: + : ''
12: + : 0
12: + : 175000
12: + : 175000
12: + : 4500000
12: + : 0.66
12: + : 0.996
12: + : 0
12: + : 0.720
12: + : 0
12: + : 0.0
12: + : 0.0
12: + : 0.01
12: + : 0
12: + : 0
12: + : 0
12: + : 0
12: + : 0
12: + : 0
12: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
12: Run vars: id 2524 gpus 4 mparams ''
12: ++ date +%s
10: +++ sed 's/^config_//'
10: +++ sed 's/\.sh$//'
10: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
12: + START=1665725682
12: ++ date '+%Y-%m-%d %r'
10: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
12: + START_FMT='2022-10-14 12:34:42 AM'
12: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
12: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
12: + '[' '!' -z '' ']'
12: + '[' 0 -gt 0 ']'
12: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
12: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
12: + PHASES=("$PHASE1" "$PHASE2")
12: + export RANK=12
12: + RANK=12
12: + export WORLD_SIZE=32
12: + WORLD_SIZE=32
12: + echo WORLD_SIZE=32
12: WORLD_SIZE=32
12: ++ cut -d - -f1
12: ++ cut -d - -f2 -
17: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
12: ++ tr -d '['
12: ++ echo 'node[031-038]'
17: ++ export BATCHSIZE=48
17: ++ BATCHSIZE=48
17: ++ export GRADIENT_STEPS=1
17: ++ GRADIENT_STEPS=1
17: ++ export LR=0.002
17: ++ LR=0.002
17: ++ export MAX_SAMPLES_TERMINATION=4500000
17: ++ MAX_SAMPLES_TERMINATION=4500000
17: ++ export MAX_STEPS=2254
17: ++ MAX_STEPS=2254
17: ++ export OPT_LAMB_BETA_1=0.66
17: ++ OPT_LAMB_BETA_1=0.66
17: ++ export OPT_LAMB_BETA_2=0.996
17: ++ OPT_LAMB_BETA_2=0.996
17: ++ export START_WARMUP_STEP=0
17: ++ START_WARMUP_STEP=0
17: ++ export WARMUP_PROPORTION=0.0
17: ++ WARMUP_PROPORTION=0.0
17: ++ export WEIGHT_DECAY_RATE=0.01
17: ++ WEIGHT_DECAY_RATE=0.01
17: ++ export INIT_LOSS_SCALE=4096.0
17: ++ INIT_LOSS_SCALE=4096.0
17: ++ export SBATCH_NETWORK=sharp
17: ++ SBATCH_NETWORK=sharp
17: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
17: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
17: ++ export PHASE=2
17: ++ PHASE=2
17: ++ export EVAL_ITER_START_SAMPLES=175000
17: ++ EVAL_ITER_START_SAMPLES=175000
17: ++ export EVAL_ITER_SAMPLES=175000
17: ++ EVAL_ITER_SAMPLES=175000
17: ++ export DGXNNODES=8
17: ++ DGXNNODES=8
10: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
10: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
10: ++ export WALLTIME_MINUTES=15
10: ++ WALLTIME_MINUTES=15
10: ++ export WALLTIME=20
10: ++ WALLTIME=20
10: ++ export DGXNGPU=4
10: ++ DGXNGPU=4
10: ++ export DGXSOCKETCORES=64
10: ++ DGXSOCKETCORES=64
10: ++ export DGXNSOCKET=2
10: ++ DGXNSOCKET=2
10: ++ export DGXHT=1
10: ++ DGXHT=1
10: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
10: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
10: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
10: ++ export MLPERF_SUBMISSION_ORG=Dell
10: ++ MLPERF_SUBMISSION_ORG=Dell
10: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
10: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
10: ++ export OMP_NUM_THREADS=8
10: ++ OMP_NUM_THREADS=8
10: + ulimit -Sn 100000
10: + '[' '' = 1 ']'
10: + : 48
10: + : 1
10: + : 0.002
10: + : 2254
10: + : 2
10: + : 2
10: + : ''
10: + : ''\'''\'''
10: + : 7539
10: + : 2524
10: + : 2
10: + : 4
10: + : ''
10: + : 0
10: + : 175000
10: + : 175000
17: +++ sed 's/^config_//'
10: + : 4500000
10: + : 0.66
10: + : 0.996
10: + : 0
10: + : 0.720
10: + : 0
10: + : 0.0
10: + : 0.0
10: + : 0.01
17: +++ sed 's/\.sh$//'
10: + : 0
10: + : 0
10: + : 0
10: + : 0
10: + : 0
10: Run vars: id 2524 gpus 4 mparams ''
10: + : 0
10: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
17: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
10: ++ date +%s
12: + export MASTER_ADDR=node031
12: + MASTER_ADDR=node031
12: + echo MASTER_ADDR=node031
12: MASTER_ADDR=node031
12: + export MASTER_PORT=19002
12: + MASTER_PORT=19002
12: HOSTNAME=node031
12: + echo HOSTNAME=node031
12: + declare -a CMD
12: + [[ -n 0 ]]
12: + [[ 32 -gt 8 ]]
12: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
12: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
12: -bert_config_path=/workspace/phase1/bert_config.json '
12: + '[' -n 0 ']'
12: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
12: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
12: + [[ 0 != 1 ]]
12: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
12: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
12: + [[ '' -ge 1 ]]
12: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
12: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
12: + [[ 0 != 0 ]]
12: + '[' '' = apiLog.sh ']'
12: + '[' '' = 1 ']'
12: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
12: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=23150'
12: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
12: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=23150
17: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
10: + START=1665725682
10: ++ date '+%Y-%m-%d %r'
10: + START_FMT='2022-10-14 12:34:42 AM'
10: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
10: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
10: + '[' '!' -z '' ']'
10: + '[' 0 -gt 0 ']'
10: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
10: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
10: + PHASES=("$PHASE1" "$PHASE2")
10: + export RANK=10
10: + RANK=10
10: + export WORLD_SIZE=32
10: + WORLD_SIZE=32
10: WORLD_SIZE=32
10: + echo WORLD_SIZE=32
17: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
17: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
17: ++ export WALLTIME_MINUTES=15
17: ++ WALLTIME_MINUTES=15
17: ++ export WALLTIME=20
17: ++ WALLTIME=20
17: ++ export DGXNGPU=4
17: ++ DGXNGPU=4
17: ++ export DGXSOCKETCORES=64
17: ++ DGXSOCKETCORES=64
17: ++ export DGXNSOCKET=2
17: ++ DGXNSOCKET=2
17: ++ export DGXHT=1
17: ++ DGXHT=1
10: ++ cut -d - -f1
17: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
17: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
17: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
17: ++ export MLPERF_SUBMISSION_ORG=Dell
17: ++ MLPERF_SUBMISSION_ORG=Dell
17: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
17: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
17: ++ export OMP_NUM_THREADS=8
17: ++ OMP_NUM_THREADS=8
17: + ulimit -Sn 100000
10: ++ cut -d - -f2 -
17: + '[' '' = 1 ']'
17: + : 48
17: + : 1
17: + : 0.002
17: + : 2254
17: + : 2
17: + : 1
17: + : ''
17: + : ''\'''\'''
17: + : 30615
17: + : 2524
17: + : 4
10: ++ tr -d '['
17: + : 4
17: + : ''
17: + : 0
17: + : 175000
17: + : 175000
17: + : 4500000
17: + : 0.66
17: + : 0.996
17: + : 0
17: + : 0.720
17: + : 0
17: + : 0.0
17: + : 0.0
17: + : 0.01
17: + : 0
17: + : 0
17: + : 0
17: + : 0
17: + : 0
17: + : 0
17: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
17: Run vars: id 2524 gpus 4 mparams ''
17: ++ date +%s
10: ++ echo 'node[031-038]'
10: + export MASTER_ADDR=node031
10: + MASTER_ADDR=node031
10: MASTER_ADDR=node031
17: + START=1665725682
10: + echo MASTER_ADDR=node031
10: + export MASTER_PORT=19002
10: + MASTER_PORT=19002
10: HOSTNAME=node031
10: + echo HOSTNAME=node031
10: + declare -a CMD
10: + [[ -n 2 ]]
10: + [[ 32 -gt 8 ]]
10: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
10: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
17: ++ date '+%Y-%m-%d %r'
10: -bert_config_path=/workspace/phase1/bert_config.json '
10: + '[' -n 2 ']'
10: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
10: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
10: + [[ 0 != 1 ]]
10: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
10: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
10: + [[ '' -ge 1 ]]
10: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
10: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
10: + [[ 0 != 0 ]]
10: + '[' '' = apiLog.sh ']'
10: + '[' '' = 1 ']'
10: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
10: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=7539'
10: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
10: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=7539
17: + START_FMT='2022-10-14 12:34:42 AM'
17: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
17: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
17: + '[' '!' -z '' ']'
17: + '[' 0 -gt 0 ']'
17: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
17: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
17: + PHASES=("$PHASE1" "$PHASE2")
17: + export RANK=17
17: + RANK=17
17: + export WORLD_SIZE=32
17: + WORLD_SIZE=32
17: WORLD_SIZE=32
17: + echo WORLD_SIZE=32
17: ++ echo 'node[031-038]'
17: ++ cut -d - -f1
17: ++ cut -d - -f2 -
17: ++ tr -d '['
17: + export MASTER_ADDR=node031
17: + MASTER_ADDR=node031
17: + echo MASTER_ADDR=node031
17: MASTER_ADDR=node031
17: + export MASTER_PORT=19002
17: + MASTER_PORT=19002
17: HOSTNAME=node031
17: + echo HOSTNAME=node031
17: + declare -a CMD
17: + [[ -n 1 ]]
17: + [[ 32 -gt 8 ]]
17: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
17: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
17: -bert_config_path=/workspace/phase1/bert_config.json '
17: + '[' -n 1 ']'
17: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
17: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
17: + [[ 0 != 1 ]]
17: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
17: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
17: + [[ '' -ge 1 ]]
17: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
17: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
17: + [[ 0 != 0 ]]
17: + '[' '' = apiLog.sh ']'
17: + '[' '' = 1 ']'
17: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
17: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=30615'
17: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
17: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=30615
 6: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
 6: ++ export BATCHSIZE=48
 6: ++ BATCHSIZE=48
 6: ++ export GRADIENT_STEPS=1
 6: ++ GRADIENT_STEPS=1
 6: ++ export LR=0.002
 6: ++ LR=0.002
 6: ++ export MAX_SAMPLES_TERMINATION=4500000
 6: ++ MAX_SAMPLES_TERMINATION=4500000
 6: ++ export MAX_STEPS=2254
 6: ++ MAX_STEPS=2254
 6: ++ export OPT_LAMB_BETA_1=0.66
 6: ++ OPT_LAMB_BETA_1=0.66
 6: ++ export OPT_LAMB_BETA_2=0.996
 6: ++ OPT_LAMB_BETA_2=0.996
 6: ++ export START_WARMUP_STEP=0
 6: ++ START_WARMUP_STEP=0
 6: ++ export WARMUP_PROPORTION=0.0
 6: ++ WARMUP_PROPORTION=0.0
 6: ++ export WEIGHT_DECAY_RATE=0.01
 6: ++ WEIGHT_DECAY_RATE=0.01
 6: ++ export INIT_LOSS_SCALE=4096.0
 6: ++ INIT_LOSS_SCALE=4096.0
 6: ++ export SBATCH_NETWORK=sharp
 6: ++ SBATCH_NETWORK=sharp
 6: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 6: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 6: ++ export PHASE=2
 6: ++ PHASE=2
 6: ++ export EVAL_ITER_START_SAMPLES=175000
 6: ++ EVAL_ITER_START_SAMPLES=175000
 6: ++ export EVAL_ITER_SAMPLES=175000
 6: ++ EVAL_ITER_SAMPLES=175000
 6: ++ export DGXNNODES=8
 6: ++ DGXNNODES=8
 6: +++ sed 's/^config_//'
19: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
 6: +++ sed 's/\.sh$//'
 6: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
19: ++ export BATCHSIZE=48
19: ++ BATCHSIZE=48
19: ++ export GRADIENT_STEPS=1
19: ++ GRADIENT_STEPS=1
19: ++ export LR=0.002
19: ++ LR=0.002
19: ++ export MAX_SAMPLES_TERMINATION=4500000
19: ++ MAX_SAMPLES_TERMINATION=4500000
19: ++ export MAX_STEPS=2254
19: ++ MAX_STEPS=2254
19: ++ export OPT_LAMB_BETA_1=0.66
19: ++ OPT_LAMB_BETA_1=0.66
19: ++ export OPT_LAMB_BETA_2=0.996
19: ++ OPT_LAMB_BETA_2=0.996
19: ++ export START_WARMUP_STEP=0
19: ++ START_WARMUP_STEP=0
19: ++ export WARMUP_PROPORTION=0.0
19: ++ WARMUP_PROPORTION=0.0
19: ++ export WEIGHT_DECAY_RATE=0.01
19: ++ WEIGHT_DECAY_RATE=0.01
19: ++ export INIT_LOSS_SCALE=4096.0
19: ++ INIT_LOSS_SCALE=4096.0
19: ++ export SBATCH_NETWORK=sharp
19: ++ SBATCH_NETWORK=sharp
19: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
19: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
19: ++ export PHASE=2
19: ++ PHASE=2
19: ++ export EVAL_ITER_START_SAMPLES=175000
19: ++ EVAL_ITER_START_SAMPLES=175000
19: ++ export EVAL_ITER_SAMPLES=175000
19: ++ EVAL_ITER_SAMPLES=175000
19: ++ export DGXNNODES=8
19: ++ DGXNNODES=8
19: +++ sed 's/^config_//'
19: +++ sed 's/\.sh$//'
19: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
 6: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
19: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
 6: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
 6: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
 6: ++ export WALLTIME_MINUTES=15
 6: ++ WALLTIME_MINUTES=15
 6: ++ export WALLTIME=20
 6: ++ WALLTIME=20
 6: ++ export DGXNGPU=4
 6: ++ DGXNGPU=4
 6: ++ export DGXSOCKETCORES=64
 6: ++ DGXSOCKETCORES=64
 6: ++ export DGXNSOCKET=2
 6: ++ DGXNSOCKET=2
 6: ++ export DGXHT=1
 6: ++ DGXHT=1
 6: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
 6: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
 6: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
 6: ++ export MLPERF_SUBMISSION_ORG=Dell
 6: ++ MLPERF_SUBMISSION_ORG=Dell
 6: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
 6: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
 6: ++ export OMP_NUM_THREADS=8
 6: ++ OMP_NUM_THREADS=8
 6: + ulimit -Sn 100000
 6: + '[' '' = 1 ']'
 6: + : 48
 6: + : 1
 6: + : 0.002
 6: + : 2254
 6: + : 2
 6: + : 2
 6: + : ''
 6: + : ''\'''\'''
 6: + : 25984
 6: + : 2524
 6: + : 1
 6: + : 4
 6: + : ''
 6: + : 0
 6: + : 175000
 6: + : 175000
 6: + : 4500000
 6: + : 0.66
 6: + : 0.996
 6: + : 0
 6: + : 0.720
 6: + : 0
 6: + : 0.0
 6: + : 0.0
 6: + : 0.01
 6: + : 0
 6: + : 0
 6: + : 0
 6: + : 0
 6: + : 0
 6: + : 0
 6: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
 6: Run vars: id 2524 gpus 4 mparams ''
 6: ++ date +%s
19: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
19: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
19: ++ export WALLTIME_MINUTES=15
19: ++ WALLTIME_MINUTES=15
19: ++ export WALLTIME=20
19: ++ WALLTIME=20
19: ++ export DGXNGPU=4
19: ++ DGXNGPU=4
19: ++ export DGXSOCKETCORES=64
19: ++ DGXSOCKETCORES=64
19: ++ export DGXNSOCKET=2
19: ++ DGXNSOCKET=2
19: ++ export DGXHT=1
19: ++ DGXHT=1
19: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
19: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
19: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
19: ++ export MLPERF_SUBMISSION_ORG=Dell
19: ++ MLPERF_SUBMISSION_ORG=Dell
19: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
19: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
19: ++ export OMP_NUM_THREADS=8
19: ++ OMP_NUM_THREADS=8
19: + ulimit -Sn 100000
19: + '[' '' = 1 ']'
19: + : 48
19: + : 1
19: + : 0.002
19: + : 2254
19: + : 2
19: + : 3
19: + : ''
19: + : ''\'''\'''
19: + : 27968
19: + : 2524
19: + : 4
19: + : 4
19: + : ''
19: + : 0
19: + : 175000
19: + : 175000
19: + : 4500000
19: + : 0.66
19: + : 0.996
19: + : 0
19: + : 0.720
19: + : 0
19: + : 0.0
19: + : 0.0
19: + : 0.01
19: + : 0
19: + : 0
19: + : 0
19: + : 0
19: + : 0
19: + : 0
19: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
19: Run vars: id 2524 gpus 4 mparams ''
 9: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
 9: ++ export BATCHSIZE=48
 9: ++ BATCHSIZE=48
19: ++ date +%s
 9: ++ export GRADIENT_STEPS=1
 9: ++ GRADIENT_STEPS=1
 9: ++ export LR=0.002
 9: ++ LR=0.002
 9: ++ export MAX_SAMPLES_TERMINATION=4500000
 9: ++ MAX_SAMPLES_TERMINATION=4500000
 9: ++ export MAX_STEPS=2254
 9: ++ MAX_STEPS=2254
 9: ++ export OPT_LAMB_BETA_1=0.66
 9: ++ OPT_LAMB_BETA_1=0.66
 9: ++ export OPT_LAMB_BETA_2=0.996
 9: ++ OPT_LAMB_BETA_2=0.996
 9: ++ export START_WARMUP_STEP=0
 9: ++ START_WARMUP_STEP=0
 9: ++ export WARMUP_PROPORTION=0.0
 9: ++ WARMUP_PROPORTION=0.0
 9: ++ export WEIGHT_DECAY_RATE=0.01
 9: ++ WEIGHT_DECAY_RATE=0.01
 9: ++ export INIT_LOSS_SCALE=4096.0
 9: ++ INIT_LOSS_SCALE=4096.0
 9: ++ export SBATCH_NETWORK=sharp
 9: ++ SBATCH_NETWORK=sharp
 9: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 9: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 9: ++ export PHASE=2
 9: ++ PHASE=2
 9: ++ export EVAL_ITER_START_SAMPLES=175000
 9: ++ EVAL_ITER_START_SAMPLES=175000
 9: ++ export EVAL_ITER_SAMPLES=175000
 9: ++ EVAL_ITER_SAMPLES=175000
 9: ++ export DGXNNODES=8
 9: ++ DGXNNODES=8
 9: +++ sed 's/^config_//'
 9: +++ sed 's/\.sh$//'
 9: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
 6: + START=1665725682
 6: ++ date '+%Y-%m-%d %r'
 6: + START_FMT='2022-10-14 12:34:42 AM'
19: + START=1665725682
 6: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
 6: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
 6: + '[' '!' -z '' ']'
 6: + '[' 0 -gt 0 ']'
 6: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
 6: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
 6: + PHASES=("$PHASE1" "$PHASE2")
 6: + export RANK=6
 6: + RANK=6
 6: + export WORLD_SIZE=32
 6: + WORLD_SIZE=32
 6: + echo WORLD_SIZE=32
 6: WORLD_SIZE=32
19: ++ date '+%Y-%m-%d %r'
 9: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
 6: ++ cut -d - -f1
 6: ++ cut -d - -f2 -
 6: ++ echo 'node[031-038]'
19: + START_FMT='2022-10-14 12:34:42 AM'
19: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
 6: ++ tr -d '['
19: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
19: + '[' '!' -z '' ']'
19: + '[' 0 -gt 0 ']'
19: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
19: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
19: + PHASES=("$PHASE1" "$PHASE2")
19: + export RANK=19
19: + RANK=19
19: + export WORLD_SIZE=32
19: + WORLD_SIZE=32
19: WORLD_SIZE=32
19: + echo WORLD_SIZE=32
19: ++ cut -d - -f1
19: ++ cut -d - -f2 -
19: ++ tr -d '['
19: ++ echo 'node[031-038]'
 9: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
 9: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
 9: ++ export WALLTIME_MINUTES=15
 9: ++ WALLTIME_MINUTES=15
 9: ++ export WALLTIME=20
 9: ++ WALLTIME=20
 9: ++ export DGXNGPU=4
 9: ++ DGXNGPU=4
 9: ++ export DGXSOCKETCORES=64
 9: ++ DGXSOCKETCORES=64
 9: ++ export DGXNSOCKET=2
 9: ++ DGXNSOCKET=2
 9: ++ export DGXHT=1
 9: ++ DGXHT=1
 9: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
 9: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
 9: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
 6: + export MASTER_ADDR=node031
 6: + MASTER_ADDR=node031
 9: ++ export MLPERF_SUBMISSION_ORG=Dell
 9: ++ MLPERF_SUBMISSION_ORG=Dell
 9: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
 9: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
 9: ++ export OMP_NUM_THREADS=8
 9: ++ OMP_NUM_THREADS=8
 9: + ulimit -Sn 100000
 9: + '[' '' = 1 ']'
 9: + : 48
 9: + : 1
 9: + : 0.002
 9: + : 2254
 9: + : 2
 6: MASTER_ADDR=node031
 6: + echo MASTER_ADDR=node031
 6: + export MASTER_PORT=19002
 6: + MASTER_PORT=19002
 6: + echo HOSTNAME=node031
 6: HOSTNAME=node031
 6: + declare -a CMD
 6: + [[ -n 2 ]]
 6: + [[ 32 -gt 8 ]]
 6: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
 9: + : 1
 9: + : ''
 9: + : ''\'''\'''
 9: + : 21967
 9: + : 2524
 9: + : 2
 9: + : 4
 9: + : ''
 9: + : 0
 9: + : 175000
 9: + : 175000
 9: + : 4500000
 9: + : 0.66
 9: + : 0.996
 6: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 9: + : 0
 9: + : 0.720
 9: + : 0
 9: + : 0.0
 9: + : 0.0
 9: + : 0.01
 9: + : 0
 9: + : 0
 9: + : 0
 9: + : 0
 9: + : 0
 9: + : 0
 9: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
 9: Run vars: id 2524 gpus 4 mparams ''
 6: -bert_config_path=/workspace/phase1/bert_config.json '
 6: + '[' -n 2 ']'
 6: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 6: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
 6: + [[ 0 != 1 ]]
 6: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 6: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
 6: + [[ '' -ge 1 ]]
 6: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 6: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
 6: + [[ 0 != 0 ]]
 6: + '[' '' = apiLog.sh ']'
 6: + '[' '' = 1 ']'
 6: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
 6: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=25984'
 9: ++ date +%s
 6: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
 6: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=25984
19: + export MASTER_ADDR=node031
19: + MASTER_ADDR=node031
19: MASTER_ADDR=node031
19: + echo MASTER_ADDR=node031
19: + export MASTER_PORT=19002
19: + MASTER_PORT=19002
19: + echo HOSTNAME=node031
19: HOSTNAME=node031
19: + declare -a CMD
19: + [[ -n 3 ]]
19: + [[ 32 -gt 8 ]]
19: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
19: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
19: -bert_config_path=/workspace/phase1/bert_config.json '
19: + '[' -n 3 ']'
19: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
19: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
19: + [[ 0 != 1 ]]
19: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
19: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
19: + [[ '' -ge 1 ]]
19: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
19: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
19: + [[ 0 != 0 ]]
19: + '[' '' = apiLog.sh ']'
19: + '[' '' = 1 ']'
19: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
19: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=27968'
19: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
19: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=27968
 9: + START=1665725682
 9: ++ date '+%Y-%m-%d %r'
 9: + START_FMT='2022-10-14 12:34:42 AM'
 9: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
 9: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
 9: + '[' '!' -z '' ']'
 9: + '[' 0 -gt 0 ']'
 9: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
 9: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
 9: + PHASES=("$PHASE1" "$PHASE2")
 9: + export RANK=9
 9: + RANK=9
 9: + export WORLD_SIZE=32
 9: + WORLD_SIZE=32
 9: WORLD_SIZE=32
 9: + echo WORLD_SIZE=32
 7: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
 9: ++ cut -d - -f1
 9: ++ cut -d - -f2 -
 7: ++ export BATCHSIZE=48
 7: ++ BATCHSIZE=48
 9: ++ tr -d '['
 7: ++ export GRADIENT_STEPS=1
 7: ++ GRADIENT_STEPS=1
 7: ++ export LR=0.002
 7: ++ LR=0.002
 9: ++ echo 'node[031-038]'
 7: ++ export MAX_SAMPLES_TERMINATION=4500000
 7: ++ MAX_SAMPLES_TERMINATION=4500000
 7: ++ export MAX_STEPS=2254
 7: ++ MAX_STEPS=2254
 7: ++ export OPT_LAMB_BETA_1=0.66
 7: ++ OPT_LAMB_BETA_1=0.66
 7: ++ export OPT_LAMB_BETA_2=0.996
 7: ++ OPT_LAMB_BETA_2=0.996
 7: ++ export START_WARMUP_STEP=0
 7: ++ START_WARMUP_STEP=0
 7: ++ export WARMUP_PROPORTION=0.0
 7: ++ WARMUP_PROPORTION=0.0
 7: ++ export WEIGHT_DECAY_RATE=0.01
 7: ++ WEIGHT_DECAY_RATE=0.01
 7: ++ export INIT_LOSS_SCALE=4096.0
 7: ++ INIT_LOSS_SCALE=4096.0
 7: ++ export SBATCH_NETWORK=sharp
 7: ++ SBATCH_NETWORK=sharp
 7: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 7: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 7: ++ export PHASE=2
 7: ++ PHASE=2
 7: ++ export EVAL_ITER_START_SAMPLES=175000
 7: ++ EVAL_ITER_START_SAMPLES=175000
 7: ++ export EVAL_ITER_SAMPLES=175000
 7: ++ EVAL_ITER_SAMPLES=175000
 7: ++ export DGXNNODES=8
 7: ++ DGXNNODES=8
 7: +++ sed 's/^config_//'
 7: +++ sed 's/\.sh$//'
 7: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
 9: + export MASTER_ADDR=node031
 9: + MASTER_ADDR=node031
 9: MASTER_ADDR=node031
 9: + echo MASTER_ADDR=node031
 9: + export MASTER_PORT=19002
 9: + MASTER_PORT=19002
 9: + echo HOSTNAME=node031
 9: HOSTNAME=node031
 9: + declare -a CMD
 9: + [[ -n 1 ]]
 9: + [[ 32 -gt 8 ]]
 9: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
 9: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 9: -bert_config_path=/workspace/phase1/bert_config.json '
 9: + '[' -n 1 ']'
 9: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 9: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
 9: + [[ 0 != 1 ]]
 9: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 9: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
 9: + [[ '' -ge 1 ]]
 9: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 9: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
 9: + [[ 0 != 0 ]]
 9: + '[' '' = apiLog.sh ']'
 9: + '[' '' = 1 ']'
 7: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
 9: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
 9: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=21967'
 9: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
 9: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=21967
 7: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
 7: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
 7: ++ export WALLTIME_MINUTES=15
 7: ++ WALLTIME_MINUTES=15
 7: ++ export WALLTIME=20
 7: ++ WALLTIME=20
 7: ++ export DGXNGPU=4
 7: ++ DGXNGPU=4
 7: ++ export DGXSOCKETCORES=64
 7: ++ DGXSOCKETCORES=64
 7: ++ export DGXNSOCKET=2
 7: ++ DGXNSOCKET=2
 7: ++ export DGXHT=1
 7: ++ DGXHT=1
 7: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
 7: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
 7: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
 7: ++ export MLPERF_SUBMISSION_ORG=Dell
 7: ++ MLPERF_SUBMISSION_ORG=Dell
 7: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
 7: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
 7: ++ export OMP_NUM_THREADS=8
 7: ++ OMP_NUM_THREADS=8
 7: + ulimit -Sn 100000
 7: + '[' '' = 1 ']'
 7: + : 48
 7: + : 1
 7: + : 0.002
 7: + : 2254
 7: + : 2
 7: + : 3
 7: + : ''
 7: + : ''\'''\'''
 7: + : 16273
 7: + : 2524
 7: + : 1
 7: + : 4
 7: + : ''
 7: + : 0
 7: + : 175000
 7: + : 175000
 7: + : 4500000
 7: + : 0.66
 7: + : 0.996
 7: + : 0
 7: + : 0.720
 7: + : 0
 7: + : 0.0
 7: + : 0.0
 7: + : 0.01
 7: + : 0
 7: + : 0
 7: + : 0
 7: + : 0
 7: + : 0
 7: + : 0
 7: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
 7: Run vars: id 2524 gpus 4 mparams ''
15: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
 7: ++ date +%s
15: ++ export BATCHSIZE=48
15: ++ BATCHSIZE=48
15: ++ export GRADIENT_STEPS=1
15: ++ GRADIENT_STEPS=1
15: ++ export LR=0.002
15: ++ LR=0.002
15: ++ export MAX_SAMPLES_TERMINATION=4500000
15: ++ MAX_SAMPLES_TERMINATION=4500000
15: ++ export MAX_STEPS=2254
15: ++ MAX_STEPS=2254
15: ++ export OPT_LAMB_BETA_1=0.66
15: ++ OPT_LAMB_BETA_1=0.66
15: ++ export OPT_LAMB_BETA_2=0.996
15: ++ OPT_LAMB_BETA_2=0.996
15: ++ export START_WARMUP_STEP=0
15: ++ START_WARMUP_STEP=0
15: ++ export WARMUP_PROPORTION=0.0
15: ++ WARMUP_PROPORTION=0.0
15: ++ export WEIGHT_DECAY_RATE=0.01
15: ++ WEIGHT_DECAY_RATE=0.01
15: ++ export INIT_LOSS_SCALE=4096.0
15: ++ INIT_LOSS_SCALE=4096.0
15: ++ export SBATCH_NETWORK=sharp
15: ++ SBATCH_NETWORK=sharp
15: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
15: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
15: ++ export PHASE=2
15: ++ PHASE=2
15: ++ export EVAL_ITER_START_SAMPLES=175000
15: ++ EVAL_ITER_START_SAMPLES=175000
15: ++ export EVAL_ITER_SAMPLES=175000
15: ++ EVAL_ITER_SAMPLES=175000
15: ++ export DGXNNODES=8
15: ++ DGXNNODES=8
15: +++ sed 's/^config_//'
15: +++ sed 's/\.sh$//'
15: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
31: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
31: ++ export BATCHSIZE=48
31: ++ BATCHSIZE=48
31: ++ export GRADIENT_STEPS=1
31: ++ GRADIENT_STEPS=1
31: ++ export LR=0.002
31: ++ LR=0.002
31: ++ export MAX_SAMPLES_TERMINATION=4500000
31: ++ MAX_SAMPLES_TERMINATION=4500000
31: ++ export MAX_STEPS=2254
31: ++ MAX_STEPS=2254
31: ++ export OPT_LAMB_BETA_1=0.66
31: ++ OPT_LAMB_BETA_1=0.66
31: ++ export OPT_LAMB_BETA_2=0.996
31: ++ OPT_LAMB_BETA_2=0.996
31: ++ export START_WARMUP_STEP=0
31: ++ START_WARMUP_STEP=0
31: ++ export WARMUP_PROPORTION=0.0
31: ++ WARMUP_PROPORTION=0.0
31: ++ export WEIGHT_DECAY_RATE=0.01
31: ++ WEIGHT_DECAY_RATE=0.01
31: ++ export INIT_LOSS_SCALE=4096.0
31: ++ INIT_LOSS_SCALE=4096.0
31: ++ export SBATCH_NETWORK=sharp
31: ++ SBATCH_NETWORK=sharp
31: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
31: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
31: ++ export PHASE=2
31: ++ PHASE=2
31: ++ export EVAL_ITER_START_SAMPLES=175000
31: ++ EVAL_ITER_START_SAMPLES=175000
31: ++ export EVAL_ITER_SAMPLES=175000
31: ++ EVAL_ITER_SAMPLES=175000
31: ++ export DGXNNODES=8
31: ++ DGXNNODES=8
31: +++ sed 's/^config_//'
 7: + START=1665725682
31: +++ sed 's/\.sh$//'
31: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
 7: ++ date '+%Y-%m-%d %r'
 7: + START_FMT='2022-10-14 12:34:42 AM'
 7: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
 7: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
 7: + '[' '!' -z '' ']'
 7: + '[' 0 -gt 0 ']'
 7: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
 7: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
15: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
 7: + PHASES=("$PHASE1" "$PHASE2")
 7: + export RANK=7
 7: + RANK=7
 7: + export WORLD_SIZE=32
 7: + WORLD_SIZE=32
 7: WORLD_SIZE=32
 7: + echo WORLD_SIZE=32
 7: ++ cut -d - -f1
 7: ++ cut -d - -f2 -
 7: ++ echo 'node[031-038]'
 7: ++ tr -d '['
31: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
15: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
15: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
15: ++ export WALLTIME_MINUTES=15
15: ++ WALLTIME_MINUTES=15
15: ++ export WALLTIME=20
15: ++ WALLTIME=20
15: ++ export DGXNGPU=4
15: ++ DGXNGPU=4
15: ++ export DGXSOCKETCORES=64
15: ++ DGXSOCKETCORES=64
15: ++ export DGXNSOCKET=2
15: ++ DGXNSOCKET=2
15: ++ export DGXHT=1
15: ++ DGXHT=1
15: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
15: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
15: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
15: ++ export MLPERF_SUBMISSION_ORG=Dell
15: ++ MLPERF_SUBMISSION_ORG=Dell
15: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
15: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
15: ++ export OMP_NUM_THREADS=8
15: ++ OMP_NUM_THREADS=8
15: + ulimit -Sn 100000
15: + '[' '' = 1 ']'
15: + : 48
15: + : 1
15: + : 0.002
15: + : 2254
15: + : 2
15: + : 3
15: + : ''
15: + : ''\'''\'''
15: + : 20924
15: + : 2524
15: + : 3
15: + : 4
15: + : ''
15: + : 0
15: + : 175000
15: + : 175000
15: + : 4500000
15: + : 0.66
15: + : 0.996
15: + : 0
15: + : 0.720
15: + : 0
15: + : 0.0
15: + : 0.0
15: + : 0.01
15: + : 0
15: + : 0
15: + : 0
15: + : 0
15: + : 0
15: + : 0
15: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
15: Run vars: id 2524 gpus 4 mparams ''
 7: + export MASTER_ADDR=node031
 7: + MASTER_ADDR=node031
 7: MASTER_ADDR=node031
 7: + echo MASTER_ADDR=node031
 7: + export MASTER_PORT=19002
 7: + MASTER_PORT=19002
 7: HOSTNAME=node031
 7: + echo HOSTNAME=node031
 7: + declare -a CMD
15: ++ date +%s
 7: + [[ -n 3 ]]
 7: + [[ 32 -gt 8 ]]
 7: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
31: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
 7: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
31: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
31: ++ export WALLTIME_MINUTES=15
31: ++ WALLTIME_MINUTES=15
31: ++ export WALLTIME=20
31: ++ WALLTIME=20
31: ++ export DGXNGPU=4
31: ++ DGXNGPU=4
31: ++ export DGXSOCKETCORES=64
31: ++ DGXSOCKETCORES=64
31: ++ export DGXNSOCKET=2
31: ++ DGXNSOCKET=2
31: ++ export DGXHT=1
31: ++ DGXHT=1
31: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
31: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
31: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
 7: -bert_config_path=/workspace/phase1/bert_config.json '
31: ++ export MLPERF_SUBMISSION_ORG=Dell
 7: + '[' -n 3 ']'
31: ++ MLPERF_SUBMISSION_ORG=Dell
 7: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
31: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
31: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
 7: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
31: ++ export OMP_NUM_THREADS=8
31: ++ OMP_NUM_THREADS=8
 7: + [[ 0 != 1 ]]
31: + ulimit -Sn 100000
 7: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
31: + '[' '' = 1 ']'
 7: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
31: + : 48
 7: + [[ '' -ge 1 ]]
31: + : 1
31: + : 0.002
31: + : 2254
31: + : 2
31: + : 3
31: + : ''
 7: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
31: + : ''\'''\'''
 7: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
31: + : 1363
 7: + [[ 0 != 0 ]]
31: + : 2524
 7: + '[' '' = apiLog.sh ']'
31: + : 7
 7: + '[' '' = 1 ']'
31: + : 4
31: + : ''
31: + : 0
31: + : 175000
31: + : 175000
31: + : 4500000
31: + : 0.66
31: + : 0.996
31: + : 0
31: Run vars: id 2524 gpus 4 mparams ''
31: + : 0.720
31: + : 0
 7: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
31: + : 0.0
 7: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=16273'
31: + : 0.0
31: + : 0.01
31: + : 0
31: + : 0
31: + : 0
31: + : 0
31: + : 0
31: + : 0
31: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
 7: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
 7: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=16273
31: ++ date +%s
15: + START=1665725682
15: ++ date '+%Y-%m-%d %r'
15: + START_FMT='2022-10-14 12:34:42 AM'
15: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
31: + START=1665725682
15: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
15: + '[' '!' -z '' ']'
15: + '[' 0 -gt 0 ']'
15: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
15: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
15: + PHASES=("$PHASE1" "$PHASE2")
15: + export RANK=15
15: + RANK=15
15: + export WORLD_SIZE=32
15: + WORLD_SIZE=32
15: + echo WORLD_SIZE=32
15: WORLD_SIZE=32
31: ++ date '+%Y-%m-%d %r'
15: ++ cut -d - -f1
15: ++ cut -d - -f2 -
15: ++ echo 'node[031-038]'
15: ++ tr -d '['
31: + START_FMT='2022-10-14 12:34:42 AM'
31: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
31: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
31: + '[' '!' -z '' ']'
31: + '[' 0 -gt 0 ']'
31: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
31: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
31: + PHASES=("$PHASE1" "$PHASE2")
31: + export RANK=31
31: + RANK=31
31: + export WORLD_SIZE=32
31: + WORLD_SIZE=32
31: + echo WORLD_SIZE=32
31: WORLD_SIZE=32
31: ++ cut -d - -f1
 8: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
31: ++ cut -d - -f2 -
31: ++ echo 'node[031-038]'
 8: ++ export BATCHSIZE=48
 8: ++ BATCHSIZE=48
31: ++ tr -d '['
 8: ++ export GRADIENT_STEPS=1
 8: ++ GRADIENT_STEPS=1
 8: ++ export LR=0.002
 8: ++ LR=0.002
 8: ++ export MAX_SAMPLES_TERMINATION=4500000
 8: ++ MAX_SAMPLES_TERMINATION=4500000
 8: ++ export MAX_STEPS=2254
 8: ++ MAX_STEPS=2254
 8: ++ export OPT_LAMB_BETA_1=0.66
 8: ++ OPT_LAMB_BETA_1=0.66
 8: ++ export OPT_LAMB_BETA_2=0.996
 8: ++ OPT_LAMB_BETA_2=0.996
 8: ++ export START_WARMUP_STEP=0
 8: ++ START_WARMUP_STEP=0
 8: ++ export WARMUP_PROPORTION=0.0
 8: ++ WARMUP_PROPORTION=0.0
 8: ++ export WEIGHT_DECAY_RATE=0.01
 8: ++ WEIGHT_DECAY_RATE=0.01
 8: ++ export INIT_LOSS_SCALE=4096.0
 8: ++ INIT_LOSS_SCALE=4096.0
 8: ++ export SBATCH_NETWORK=sharp
 8: ++ SBATCH_NETWORK=sharp
 8: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 8: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 8: ++ export PHASE=2
 8: ++ PHASE=2
 8: ++ export EVAL_ITER_START_SAMPLES=175000
 8: ++ EVAL_ITER_START_SAMPLES=175000
 8: ++ export EVAL_ITER_SAMPLES=175000
 8: ++ EVAL_ITER_SAMPLES=175000
 8: ++ export DGXNNODES=8
 8: ++ DGXNNODES=8
 8: +++ sed 's/^config_//'
 8: +++ sed 's/\.sh$//'
 8: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
15: + export MASTER_ADDR=node031
15: + MASTER_ADDR=node031
15: + echo MASTER_ADDR=node031
15: MASTER_ADDR=node031
15: + export MASTER_PORT=19002
15: + MASTER_PORT=19002
15: HOSTNAME=node031
15: + echo HOSTNAME=node031
15: + declare -a CMD
15: + [[ -n 3 ]]
15: + [[ 32 -gt 8 ]]
15: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
15: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
15: -bert_config_path=/workspace/phase1/bert_config.json '
15: + '[' -n 3 ']'
15: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
15: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
15: + [[ 0 != 1 ]]
15: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
15: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
15: + [[ '' -ge 1 ]]
15: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
15: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
15: + [[ 0 != 0 ]]
15: + '[' '' = apiLog.sh ']'
15: + '[' '' = 1 ']'
15: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
15: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=20924'
15: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
15: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=20924
31: + export MASTER_ADDR=node031
31: + MASTER_ADDR=node031
31: MASTER_ADDR=node031
31: + echo MASTER_ADDR=node031
31: + export MASTER_PORT=19002
31: + MASTER_PORT=19002
31: + echo HOSTNAME=node031
31: HOSTNAME=node031
31: + declare -a CMD
31: + [[ -n 3 ]]
31: + [[ 32 -gt 8 ]]
31: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
31: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
31: -bert_config_path=/workspace/phase1/bert_config.json '
31: + '[' -n 3 ']'
31: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
31: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
31: + [[ 0 != 1 ]]
31: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
31: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
31: + [[ '' -ge 1 ]]
31: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
31: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
31: + [[ 0 != 0 ]]
31: + '[' '' = apiLog.sh ']'
31: + '[' '' = 1 ']'
31: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
31: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=1363'
31: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
31: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=1363
 8: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
 8: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
 8: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
 8: ++ export WALLTIME_MINUTES=15
 8: ++ WALLTIME_MINUTES=15
 8: ++ export WALLTIME=20
 8: ++ WALLTIME=20
 8: ++ export DGXNGPU=4
 8: ++ DGXNGPU=4
 8: ++ export DGXSOCKETCORES=64
 8: ++ DGXSOCKETCORES=64
 8: ++ export DGXNSOCKET=2
 8: ++ DGXNSOCKET=2
 8: ++ export DGXHT=1
 8: ++ DGXHT=1
 8: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
 8: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
 8: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
 8: ++ export MLPERF_SUBMISSION_ORG=Dell
 8: ++ MLPERF_SUBMISSION_ORG=Dell
 8: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
 8: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
 8: ++ export OMP_NUM_THREADS=8
 8: ++ OMP_NUM_THREADS=8
 8: + ulimit -Sn 100000
 8: + '[' '' = 1 ']'
 8: + : 48
 8: + : 1
 8: + : 0.002
 8: + : 2254
 8: + : 2
 8: + : 0
 8: + : ''
 8: + : ''\'''\'''
 8: + : 21977
 8: + : 2524
 8: + : 2
 8: + : 4
 8: + : ''
 8: + : 0
 8: + : 175000
 8: + : 175000
 8: + : 4500000
 8: + : 0.66
 8: + : 0.996
 8: + : 0
 8: + : 0.720
 8: + : 0
 8: + : 0.0
 8: + : 0.0
 8: + : 0.01
 8: + : 0
 8: + : 0
 8: + : 0
 8: + : 0
 8: + : 0
 8: + : 0
 8: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
 8: Run vars: id 2524 gpus 4 mparams ''
 8: ++ date +%s
 8: + START=1665725682
 8: ++ date '+%Y-%m-%d %r'
 8: + START_FMT='2022-10-14 12:34:42 AM'
 8: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
 8: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
 8: + '[' '!' -z '' ']'
 8: + '[' 0 -gt 0 ']'
 8: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
 8: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
 8: + PHASES=("$PHASE1" "$PHASE2")
 8: + export RANK=8
 8: + RANK=8
 8: + export WORLD_SIZE=32
 8: + WORLD_SIZE=32
 8: WORLD_SIZE=32
 8: + echo WORLD_SIZE=32
 8: ++ cut -d - -f1
 8: ++ cut -d - -f2 -
 8: ++ echo 'node[031-038]'
 8: ++ tr -d '['
 8: + export MASTER_ADDR=node031
 8: + MASTER_ADDR=node031
 8: + echo MASTER_ADDR=node031
 8: MASTER_ADDR=node031
 8: + export MASTER_PORT=19002
 8: + MASTER_PORT=19002
 8: HOSTNAME=node031
 8: + echo HOSTNAME=node031
 8: + declare -a CMD
 8: + [[ -n 0 ]]
 8: + [[ 32 -gt 8 ]]
 8: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
 8: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 8: -bert_config_path=/workspace/phase1/bert_config.json '
 8: + '[' -n 0 ']'
 8: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 8: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
 8: + [[ 0 != 1 ]]
 8: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 8: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
 8: + [[ '' -ge 1 ]]
 8: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 8: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
 8: + [[ 0 != 0 ]]
 8: + '[' '' = apiLog.sh ']'
 8: + '[' '' = 1 ']'
 8: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
 8: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=21977'
 8: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
 8: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=21977
23: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
23: ++ export BATCHSIZE=48
23: ++ BATCHSIZE=48
23: ++ export GRADIENT_STEPS=1
23: ++ GRADIENT_STEPS=1
23: ++ export LR=0.002
23: ++ LR=0.002
23: ++ export MAX_SAMPLES_TERMINATION=4500000
23: ++ MAX_SAMPLES_TERMINATION=4500000
23: ++ export MAX_STEPS=2254
23: ++ MAX_STEPS=2254
23: ++ export OPT_LAMB_BETA_1=0.66
23: ++ OPT_LAMB_BETA_1=0.66
23: ++ export OPT_LAMB_BETA_2=0.996
23: ++ OPT_LAMB_BETA_2=0.996
23: ++ export START_WARMUP_STEP=0
23: ++ START_WARMUP_STEP=0
23: ++ export WARMUP_PROPORTION=0.0
23: ++ WARMUP_PROPORTION=0.0
23: ++ export WEIGHT_DECAY_RATE=0.01
23: ++ WEIGHT_DECAY_RATE=0.01
23: ++ export INIT_LOSS_SCALE=4096.0
23: ++ INIT_LOSS_SCALE=4096.0
23: ++ export SBATCH_NETWORK=sharp
23: ++ SBATCH_NETWORK=sharp
23: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
23: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
23: ++ export PHASE=2
23: ++ PHASE=2
23: ++ export EVAL_ITER_START_SAMPLES=175000
23: ++ EVAL_ITER_START_SAMPLES=175000
23: ++ export EVAL_ITER_SAMPLES=175000
23: ++ EVAL_ITER_SAMPLES=175000
23: ++ export DGXNNODES=8
23: ++ DGXNNODES=8
23: +++ sed 's/^config_//'
23: +++ sed 's/\.sh$//'
23: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
23: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
23: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
23: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
23: ++ export WALLTIME_MINUTES=15
23: ++ WALLTIME_MINUTES=15
23: ++ export WALLTIME=20
23: ++ WALLTIME=20
23: ++ export DGXNGPU=4
23: ++ DGXNGPU=4
23: ++ export DGXSOCKETCORES=64
23: ++ DGXSOCKETCORES=64
23: ++ export DGXNSOCKET=2
23: ++ DGXNSOCKET=2
23: ++ export DGXHT=1
23: ++ DGXHT=1
23: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
23: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
23: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
23: ++ export MLPERF_SUBMISSION_ORG=Dell
23: ++ MLPERF_SUBMISSION_ORG=Dell
23: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
23: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
23: ++ export OMP_NUM_THREADS=8
23: ++ OMP_NUM_THREADS=8
23: + ulimit -Sn 100000
23: + '[' '' = 1 ']'
23: + : 48
23: + : 1
23: + : 0.002
23: + : 2254
23: + : 2
23: + : 3
23: + : ''
23: + : ''\'''\'''
23: + : 14464
23: + : 2524
23: + : 5
23: + : 4
23: + : ''
23: + : 0
23: + : 175000
23: + : 175000
23: + : 4500000
23: + : 0.66
23: + : 0.996
23: + : 0
23: + : 0.720
23: + : 0
23: + : 0.0
23: + : 0.0
23: + : 0.01
23: + : 0
23: + : 0
23: + : 0
23: + : 0
23: + : 0
23: + : 0
23: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
23: Run vars: id 2524 gpus 4 mparams ''
23: ++ date +%s
23: + START=1665725682
23: ++ date '+%Y-%m-%d %r'
23: + START_FMT='2022-10-14 12:34:42 AM'
23: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
23: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
23: + '[' '!' -z '' ']'
23: + '[' 0 -gt 0 ']'
23: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
23: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
23: + PHASES=("$PHASE1" "$PHASE2")
23: + export RANK=23
23: + RANK=23
23: + export WORLD_SIZE=32
23: + WORLD_SIZE=32
23: WORLD_SIZE=32
23: + echo WORLD_SIZE=32
23: ++ cut -d - -f1
23: ++ echo 'node[031-038]'
23: ++ cut -d - -f2 -
23: ++ tr -d '['
23: + export MASTER_ADDR=node031
23: + MASTER_ADDR=node031
23: + echo MASTER_ADDR=node031
23: MASTER_ADDR=node031
23: + export MASTER_PORT=19002
23: + MASTER_PORT=19002
23: HOSTNAME=node031
23: + echo HOSTNAME=node031
23: + declare -a CMD
23: + [[ -n 3 ]]
23: + [[ 32 -gt 8 ]]
23: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
23: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
23: -bert_config_path=/workspace/phase1/bert_config.json '
23: + '[' -n 3 ']'
23: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
23: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
23: + [[ 0 != 1 ]]
23: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
23: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
23: + [[ '' -ge 1 ]]
23: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
23: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
23: + [[ 0 != 0 ]]
23: + '[' '' = apiLog.sh ']'
23: + '[' '' = 1 ']'
23: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
23: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=14464'
23: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
23: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=14464
24: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
24: ++ export BATCHSIZE=48
24: ++ BATCHSIZE=48
24: ++ export GRADIENT_STEPS=1
24: ++ GRADIENT_STEPS=1
24: ++ export LR=0.002
24: ++ LR=0.002
24: ++ export MAX_SAMPLES_TERMINATION=4500000
24: ++ MAX_SAMPLES_TERMINATION=4500000
24: ++ export MAX_STEPS=2254
24: ++ MAX_STEPS=2254
24: ++ export OPT_LAMB_BETA_1=0.66
24: ++ OPT_LAMB_BETA_1=0.66
24: ++ export OPT_LAMB_BETA_2=0.996
24: ++ OPT_LAMB_BETA_2=0.996
24: ++ export START_WARMUP_STEP=0
24: ++ START_WARMUP_STEP=0
24: ++ export WARMUP_PROPORTION=0.0
24: ++ WARMUP_PROPORTION=0.0
24: ++ export WEIGHT_DECAY_RATE=0.01
24: ++ WEIGHT_DECAY_RATE=0.01
24: ++ export INIT_LOSS_SCALE=4096.0
24: ++ INIT_LOSS_SCALE=4096.0
24: ++ export SBATCH_NETWORK=sharp
24: ++ SBATCH_NETWORK=sharp
24: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
24: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
24: ++ export PHASE=2
24: ++ PHASE=2
24: ++ export EVAL_ITER_START_SAMPLES=175000
24: ++ EVAL_ITER_START_SAMPLES=175000
24: ++ export EVAL_ITER_SAMPLES=175000
24: ++ EVAL_ITER_SAMPLES=175000
24: ++ export DGXNNODES=8
24: ++ DGXNNODES=8
24: +++ sed 's/^config_//'
24: +++ sed 's/\.sh$//'
24: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
24: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
24: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
24: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
24: ++ export WALLTIME_MINUTES=15
24: ++ WALLTIME_MINUTES=15
24: ++ export WALLTIME=20
24: ++ WALLTIME=20
24: ++ export DGXNGPU=4
24: ++ DGXNGPU=4
24: ++ export DGXSOCKETCORES=64
24: ++ DGXSOCKETCORES=64
24: ++ export DGXNSOCKET=2
24: ++ DGXNSOCKET=2
24: ++ export DGXHT=1
24: ++ DGXHT=1
24: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
24: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
24: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
24: ++ export MLPERF_SUBMISSION_ORG=Dell
24: ++ MLPERF_SUBMISSION_ORG=Dell
24: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
24: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
24: ++ export OMP_NUM_THREADS=8
24: ++ OMP_NUM_THREADS=8
24: + ulimit -Sn 100000
24: + '[' '' = 1 ']'
24: + : 48
24: + : 1
24: + : 0.002
24: + : 2254
24: + : 2
24: + : 0
24: + : ''
24: + : ''\'''\'''
24: + : 8199
24: + : 2524
24: + : 6
24: + : 4
24: + : ''
24: + : 0
24: + : 175000
24: + : 175000
24: + : 4500000
24: + : 0.66
24: + : 0.996
24: + : 0
24: + : 0.720
24: + : 0
24: + : 0.0
24: + : 0.0
24: + : 0.01
24: + : 0
24: + : 0
24: + : 0
24: + : 0
24: + : 0
24: + : 0
24: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
24: Run vars: id 2524 gpus 4 mparams ''
24: ++ date +%s
24: + START=1665725682
24: ++ date '+%Y-%m-%d %r'
24: + START_FMT='2022-10-14 12:34:42 AM'
24: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
24: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
24: + '[' '!' -z '' ']'
24: + '[' 0 -gt 0 ']'
24: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
24: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
24: + PHASES=("$PHASE1" "$PHASE2")
24: + export RANK=24
24: + RANK=24
24: + export WORLD_SIZE=32
24: + WORLD_SIZE=32
24: + echo WORLD_SIZE=32
24: WORLD_SIZE=32
24: ++ cut -d - -f1
24: ++ cut -d - -f2 -
24: ++ tr -d '['
24: ++ echo 'node[031-038]'
24: + export MASTER_ADDR=node031
24: + MASTER_ADDR=node031
24: MASTER_ADDR=node031
24: + echo MASTER_ADDR=node031
24: + export MASTER_PORT=19002
24: + MASTER_PORT=19002
24: + echo HOSTNAME=node031
24: HOSTNAME=node031
24: + declare -a CMD
24: + [[ -n 0 ]]
24: + [[ 32 -gt 8 ]]
24: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
24: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
24: -bert_config_path=/workspace/phase1/bert_config.json '
24: + '[' -n 0 ']'
24: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
24: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0 '
24: + [[ 0 != 1 ]]
24: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
24: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
24: + [[ '' -ge 1 ]]
24: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
24: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
24: + [[ 0 != 0 ]]
24: + '[' '' = apiLog.sh ']'
24: + '[' '' = 1 ']'
24: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
24: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=0  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=8199'
24: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=0 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
24: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=8199
18: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
18: ++ export BATCHSIZE=48
18: ++ BATCHSIZE=48
18: ++ export GRADIENT_STEPS=1
18: ++ GRADIENT_STEPS=1
18: ++ export LR=0.002
18: ++ LR=0.002
18: ++ export MAX_SAMPLES_TERMINATION=4500000
18: ++ MAX_SAMPLES_TERMINATION=4500000
18: ++ export MAX_STEPS=2254
18: ++ MAX_STEPS=2254
18: ++ export OPT_LAMB_BETA_1=0.66
18: ++ OPT_LAMB_BETA_1=0.66
18: ++ export OPT_LAMB_BETA_2=0.996
18: ++ OPT_LAMB_BETA_2=0.996
18: ++ export START_WARMUP_STEP=0
18: ++ START_WARMUP_STEP=0
18: ++ export WARMUP_PROPORTION=0.0
18: ++ WARMUP_PROPORTION=0.0
18: ++ export WEIGHT_DECAY_RATE=0.01
18: ++ WEIGHT_DECAY_RATE=0.01
18: ++ export INIT_LOSS_SCALE=4096.0
18: ++ INIT_LOSS_SCALE=4096.0
18: ++ export SBATCH_NETWORK=sharp
18: ++ SBATCH_NETWORK=sharp
18: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
18: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
18: ++ export PHASE=2
18: ++ PHASE=2
18: ++ export EVAL_ITER_START_SAMPLES=175000
18: ++ EVAL_ITER_START_SAMPLES=175000
18: ++ export EVAL_ITER_SAMPLES=175000
18: ++ EVAL_ITER_SAMPLES=175000
18: ++ export DGXNNODES=8
18: ++ DGXNNODES=8
18: +++ sed 's/^config_//'
18: +++ sed 's/\.sh$//'
18: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
18: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
18: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
18: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
18: ++ export WALLTIME_MINUTES=15
18: ++ WALLTIME_MINUTES=15
18: ++ export WALLTIME=20
18: ++ WALLTIME=20
18: ++ export DGXNGPU=4
18: ++ DGXNGPU=4
18: ++ export DGXSOCKETCORES=64
18: ++ DGXSOCKETCORES=64
18: ++ export DGXNSOCKET=2
18: ++ DGXNSOCKET=2
18: ++ export DGXHT=1
18: ++ DGXHT=1
18: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
18: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
18: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
18: ++ export MLPERF_SUBMISSION_ORG=Dell
18: ++ MLPERF_SUBMISSION_ORG=Dell
18: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
18: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
18: ++ export OMP_NUM_THREADS=8
18: ++ OMP_NUM_THREADS=8
18: + ulimit -Sn 100000
18: + '[' '' = 1 ']'
18: + : 48
18: + : 1
18: + : 0.002
18: + : 2254
18: + : 2
18: + : 2
18: + : ''
18: + : ''\'''\'''
18: + : 18449
18: + : 2524
18: + : 4
18: + : 4
18: + : ''
18: + : 0
18: + : 175000
18: + : 175000
18: + : 4500000
18: + : 0.66
18: + : 0.996
18: + : 0
18: + : 0.720
18: + : 0
18: + : 0.0
18: + : 0.0
18: + : 0.01
18: + : 0
18: + : 0
18: + : 0
18: + : 0
18: + : 0
18: + : 0
18: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
18: Run vars: id 2524 gpus 4 mparams ''
18: ++ date +%s
18: + START=1665725682
18: ++ date '+%Y-%m-%d %r'
18: + START_FMT='2022-10-14 12:34:42 AM'
18: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
18: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
18: + '[' '!' -z '' ']'
18: + '[' 0 -gt 0 ']'
18: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
18: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
18: + PHASES=("$PHASE1" "$PHASE2")
18: + export RANK=18
18: + RANK=18
18: + export WORLD_SIZE=32
18: + WORLD_SIZE=32
18: WORLD_SIZE=32
18: + echo WORLD_SIZE=32
18: ++ cut -d - -f1
18: ++ cut -d - -f2 -
18: ++ echo 'node[031-038]'
18: ++ tr -d '['
13: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
13: ++ export BATCHSIZE=48
13: ++ BATCHSIZE=48
13: ++ export GRADIENT_STEPS=1
13: ++ GRADIENT_STEPS=1
13: ++ export LR=0.002
13: ++ LR=0.002
13: ++ export MAX_SAMPLES_TERMINATION=4500000
13: ++ MAX_SAMPLES_TERMINATION=4500000
13: ++ export MAX_STEPS=2254
13: ++ MAX_STEPS=2254
13: ++ export OPT_LAMB_BETA_1=0.66
13: ++ OPT_LAMB_BETA_1=0.66
13: ++ export OPT_LAMB_BETA_2=0.996
18: + export MASTER_ADDR=node031
18: + MASTER_ADDR=node031
13: ++ OPT_LAMB_BETA_2=0.996
13: ++ export START_WARMUP_STEP=0
13: ++ START_WARMUP_STEP=0
13: ++ export WARMUP_PROPORTION=0.0
13: ++ WARMUP_PROPORTION=0.0
13: ++ export WEIGHT_DECAY_RATE=0.01
13: ++ WEIGHT_DECAY_RATE=0.01
13: ++ export INIT_LOSS_SCALE=4096.0
13: ++ INIT_LOSS_SCALE=4096.0
13: ++ export SBATCH_NETWORK=sharp
13: ++ SBATCH_NETWORK=sharp
13: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
13: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
13: ++ export PHASE=2
13: ++ PHASE=2
13: ++ export EVAL_ITER_START_SAMPLES=175000
13: ++ EVAL_ITER_START_SAMPLES=175000
13: ++ export EVAL_ITER_SAMPLES=175000
13: ++ EVAL_ITER_SAMPLES=175000
13: ++ export DGXNNODES=8
13: ++ DGXNNODES=8
18: MASTER_ADDR=node031
18: + echo MASTER_ADDR=node031
18: + export MASTER_PORT=19002
18: + MASTER_PORT=19002
18: HOSTNAME=node031
18: + echo HOSTNAME=node031
18: + declare -a CMD
18: + [[ -n 2 ]]
18: + [[ 32 -gt 8 ]]
18: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
18: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
18: -bert_config_path=/workspace/phase1/bert_config.json '
18: + '[' -n 2 ']'
18: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
18: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2 '
18: + [[ 0 != 1 ]]
18: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
18: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
18: + [[ '' -ge 1 ]]
18: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
18: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
18: + [[ 0 != 0 ]]
18: + '[' '' = apiLog.sh ']'
18: + '[' '' = 1 ']'
18: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
18: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=2  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=18449'
13: +++ sed 's/^config_//'
18: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=2 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
18: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=18449
13: +++ sed 's/\.sh$//'
13: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
 5: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
13: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
 5: ++ export BATCHSIZE=48
 5: ++ BATCHSIZE=48
 5: ++ export GRADIENT_STEPS=1
 5: ++ GRADIENT_STEPS=1
 5: ++ export LR=0.002
 5: ++ LR=0.002
 5: ++ export MAX_SAMPLES_TERMINATION=4500000
 5: ++ MAX_SAMPLES_TERMINATION=4500000
 5: ++ export MAX_STEPS=2254
 5: ++ MAX_STEPS=2254
 5: ++ export OPT_LAMB_BETA_1=0.66
 5: ++ OPT_LAMB_BETA_1=0.66
 5: ++ export OPT_LAMB_BETA_2=0.996
 5: ++ OPT_LAMB_BETA_2=0.996
 5: ++ export START_WARMUP_STEP=0
 5: ++ START_WARMUP_STEP=0
 5: ++ export WARMUP_PROPORTION=0.0
 5: ++ WARMUP_PROPORTION=0.0
 5: ++ export WEIGHT_DECAY_RATE=0.01
 5: ++ WEIGHT_DECAY_RATE=0.01
 5: ++ export INIT_LOSS_SCALE=4096.0
 5: ++ INIT_LOSS_SCALE=4096.0
 5: ++ export SBATCH_NETWORK=sharp
 5: ++ SBATCH_NETWORK=sharp
 5: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 5: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
 5: ++ export PHASE=2
 5: ++ PHASE=2
 5: ++ export EVAL_ITER_START_SAMPLES=175000
 5: ++ EVAL_ITER_START_SAMPLES=175000
 5: ++ export EVAL_ITER_SAMPLES=175000
 5: ++ EVAL_ITER_SAMPLES=175000
 5: ++ export DGXNNODES=8
 5: ++ DGXNNODES=8
 5: +++ sed 's/^config_//'
 5: +++ sed 's/\.sh$//'
 5: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
13: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
13: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
13: ++ export WALLTIME_MINUTES=15
13: ++ WALLTIME_MINUTES=15
13: ++ export WALLTIME=20
13: ++ WALLTIME=20
13: ++ export DGXNGPU=4
13: ++ DGXNGPU=4
13: ++ export DGXSOCKETCORES=64
13: ++ DGXSOCKETCORES=64
13: ++ export DGXNSOCKET=2
13: ++ DGXNSOCKET=2
13: ++ export DGXHT=1
13: ++ DGXHT=1
13: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
13: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
13: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
13: ++ export MLPERF_SUBMISSION_ORG=Dell
13: ++ MLPERF_SUBMISSION_ORG=Dell
13: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
13: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
13: ++ export OMP_NUM_THREADS=8
13: ++ OMP_NUM_THREADS=8
13: + ulimit -Sn 100000
13: + '[' '' = 1 ']'
13: + : 48
13: + : 1
13: + : 0.002
13: + : 2254
13: + : 2
13: + : 1
13: + : ''
13: + : ''\'''\'''
13: + : 23049
13: + : 2524
13: + : 3
13: + : 4
13: + : ''
13: + : 0
13: + : 175000
13: + : 175000
13: + : 4500000
13: + : 0.66
13: + : 0.996
13: + : 0
13: + : 0.720
13: + : 0
13: + : 0.0
13: + : 0.0
13: + : 0.01
13: + : 0
13: + : 0
13: + : 0
13: + : 0
13: + : 0
13: + : 0
13: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
13: Run vars: id 2524 gpus 4 mparams ''
13: ++ date +%s
 5: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
13: + START=1665725682
13: ++ date '+%Y-%m-%d %r'
 5: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
 5: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
 5: ++ export WALLTIME_MINUTES=15
 5: ++ WALLTIME_MINUTES=15
 5: ++ export WALLTIME=20
 5: ++ WALLTIME=20
 5: ++ export DGXNGPU=4
 5: ++ DGXNGPU=4
 5: ++ export DGXSOCKETCORES=64
 5: ++ DGXSOCKETCORES=64
 5: ++ export DGXNSOCKET=2
 5: ++ DGXNSOCKET=2
 5: ++ export DGXHT=1
 5: ++ DGXHT=1
 5: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
 5: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
 5: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
 5: ++ export MLPERF_SUBMISSION_ORG=Dell
 5: ++ MLPERF_SUBMISSION_ORG=Dell
 5: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
 5: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
 5: ++ export OMP_NUM_THREADS=8
 5: ++ OMP_NUM_THREADS=8
 5: + ulimit -Sn 100000
 5: + '[' '' = 1 ']'
 5: + : 48
 5: + : 1
 5: + : 0.002
 5: + : 2254
 5: + : 2
 5: + : 1
 5: + : ''
 5: + : ''\'''\'''
 5: + : 10283
 5: + : 2524
 5: + : 1
 5: + : 4
 5: + : ''
 5: + : 0
 5: + : 175000
 5: + : 175000
 5: + : 4500000
 5: + : 0.66
 5: + : 0.996
 5: + : 0
 5: + : 0.720
 5: + : 0
 5: + : 0.0
 5: + : 0.0
 5: + : 0.01
 5: + : 0
 5: + : 0
 5: + : 0
 5: + : 0
 5: + : 0
 5: + : 0
 5: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
 5: Run vars: id 2524 gpus 4 mparams ''
13: + START_FMT='2022-10-14 12:34:42 AM'
 5: ++ date +%s
13: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
13: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
13: + '[' '!' -z '' ']'
13: + '[' 0 -gt 0 ']'
13: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
13: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
13: + PHASES=("$PHASE1" "$PHASE2")
13: + export RANK=13
13: + RANK=13
13: + export WORLD_SIZE=32
13: + WORLD_SIZE=32
13: WORLD_SIZE=32
13: + echo WORLD_SIZE=32
13: ++ cut -d - -f1
13: ++ cut -d - -f2 -
13: ++ echo 'node[031-038]'
13: ++ tr -d '['
 5: + START=1665725682
 5: ++ date '+%Y-%m-%d %r'
13: + export MASTER_ADDR=node031
13: + MASTER_ADDR=node031
 5: + START_FMT='2022-10-14 12:34:42 AM'
13: MASTER_ADDR=node031
13: + echo MASTER_ADDR=node031
13: + export MASTER_PORT=19002
13: + MASTER_PORT=19002
13: HOSTNAME=node031
13: + echo HOSTNAME=node031
13: + declare -a CMD
13: + [[ -n 1 ]]
13: + [[ 32 -gt 8 ]]
 5: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
 5: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
 5: + '[' '!' -z '' ']'
 5: + '[' 0 -gt 0 ']'
13: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
 5: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
13: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
13: -bert_config_path=/workspace/phase1/bert_config.json '
 5: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
13: + '[' -n 1 ']'
 5: + PHASES=("$PHASE1" "$PHASE2")
13: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 5: WORLD_SIZE=32
 5: + export RANK=5
 5: + RANK=5
13: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
 5: + export WORLD_SIZE=32
 5: + WORLD_SIZE=32
13: + [[ 0 != 1 ]]
 5: + echo WORLD_SIZE=32
13: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
13: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
13: + [[ '' -ge 1 ]]
13: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
13: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
13: + [[ 0 != 0 ]]
13: + '[' '' = apiLog.sh ']'
13: + '[' '' = 1 ']'
13: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
13: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=23049'
13: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
13: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=23049
 5: ++ cut -d - -f1
 5: ++ cut -d - -f2 -
 5: ++ echo 'node[031-038]'
 5: ++ tr -d '['
 5: + export MASTER_ADDR=node031
 5: + MASTER_ADDR=node031
 5: MASTER_ADDR=node031
 5: + echo MASTER_ADDR=node031
 5: + export MASTER_PORT=19002
 5: + MASTER_PORT=19002
 5: HOSTNAME=node031
 5: + echo HOSTNAME=node031
 5: + declare -a CMD
 5: + [[ -n 1 ]]
 5: + [[ 32 -gt 8 ]]
 5: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
 5: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 5: -bert_config_path=/workspace/phase1/bert_config.json '
 5: + '[' -n 1 ']'
 5: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 5: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1 '
 5: + [[ 0 != 1 ]]
 5: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 5: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
 5: + [[ '' -ge 1 ]]
 5: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
 5: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
 5: + [[ 0 != 0 ]]
 5: + '[' '' = apiLog.sh ']'
 5: + '[' '' = 1 ']'
 5: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
 5: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=1  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=10283'
 5: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=1 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
 5: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=10283
11: + source ./config_8xXE8545x4A100-SXM4-40GB.sh
11: ++ export BATCHSIZE=48
11: ++ BATCHSIZE=48
11: ++ export GRADIENT_STEPS=1
11: ++ GRADIENT_STEPS=1
11: ++ export LR=0.002
11: ++ LR=0.002
11: ++ export MAX_SAMPLES_TERMINATION=4500000
11: ++ MAX_SAMPLES_TERMINATION=4500000
11: ++ export MAX_STEPS=2254
11: ++ MAX_STEPS=2254
11: ++ export OPT_LAMB_BETA_1=0.66
11: ++ OPT_LAMB_BETA_1=0.66
11: ++ export OPT_LAMB_BETA_2=0.996
11: ++ OPT_LAMB_BETA_2=0.996
11: ++ export START_WARMUP_STEP=0
11: ++ START_WARMUP_STEP=0
11: ++ export WARMUP_PROPORTION=0.0
11: ++ WARMUP_PROPORTION=0.0
11: ++ export WEIGHT_DECAY_RATE=0.01
11: ++ WEIGHT_DECAY_RATE=0.01
11: ++ export INIT_LOSS_SCALE=4096.0
11: ++ INIT_LOSS_SCALE=4096.0
11: ++ export SBATCH_NETWORK=sharp
11: ++ SBATCH_NETWORK=sharp
11: ++ export 'EXTRA_PARAMS=--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
11: ++ EXTRA_PARAMS='--dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu '
11: ++ export PHASE=2
11: ++ PHASE=2
11: ++ export EVAL_ITER_START_SAMPLES=175000
11: ++ EVAL_ITER_START_SAMPLES=175000
11: ++ export EVAL_ITER_SAMPLES=175000
11: ++ EVAL_ITER_SAMPLES=175000
11: ++ export DGXNNODES=8
11: ++ DGXNNODES=8
11: +++ sed 's/^config_//'
11: +++ sed 's/\.sh$//'
11: ++++ readlink -f ./config_8xXE8545x4A100-SXM4-40GB.sh
11: +++ basename /workspace/bert/config_8xXE8545x4A100-SXM4-40GB.sh
11: ++ export DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
11: ++ DGXSYSTEM=8xXE8545x4A100-SXM4-40GB
11: ++ export WALLTIME_MINUTES=15
11: ++ WALLTIME_MINUTES=15
11: ++ export WALLTIME=20
11: ++ WALLTIME=20
11: ++ export DGXNGPU=4
11: ++ DGXNGPU=4
11: ++ export DGXSOCKETCORES=64
11: ++ DGXSOCKETCORES=64
11: ++ export DGXNSOCKET=2
11: ++ DGXNSOCKET=2
11: ++ export DGXHT=1
11: ++ DGXHT=1
11: ++ export CUDA_VISIBLE_DEVICES=0,1,2,3
11: ++ CUDA_VISIBLE_DEVICES=0,1,2,3
11: ++ NCCL_SOCKET_IFNAME=mlx5_0,mlx5_1
11: ++ export MLPERF_SUBMISSION_ORG=Dell
11: ++ MLPERF_SUBMISSION_ORG=Dell
11: ++ export MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
11: ++ MLPERF_SUBMISSION_PLATFORM=8xXE8545x4A100-SXM4-40GB
11: ++ export OMP_NUM_THREADS=8
11: ++ OMP_NUM_THREADS=8
11: + ulimit -Sn 100000
11: + '[' '' = 1 ']'
11: + : 48
11: + : 1
11: + : 0.002
11: + : 2254
11: + : 2
11: + : 3
11: + : ''
11: + : ''\'''\'''
11: + : 13555
11: + : 2524
11: + : 2
11: + : 4
11: + : ''
11: + : 0
11: + : 175000
11: + : 175000
11: + : 4500000
11: + : 0.66
11: + : 0.996
11: + : 0
11: + : 0.720
11: + : 0
11: + : 0.0
11: + : 0.0
11: + : 0.01
11: + : 0
11: + : 0
11: + : 0
11: + : 0
11: + : 0
11: + : 0
11: + echo 'Run vars: id 2524 gpus 4 mparams '\'''\'''
11: Run vars: id 2524 gpus 4 mparams ''
11: ++ date +%s
11: + START=1665725682
11: ++ date '+%Y-%m-%d %r'
11: + START_FMT='2022-10-14 12:34:42 AM'
11: STARTING TIMING RUN AT 2022-10-14 12:34:42 AM
11: + echo 'STARTING TIMING RUN AT 2022-10-14 12:34:42 AM'
11: + '[' '!' -z '' ']'
11: + '[' 0 -gt 0 ']'
11: + PHASE1='    --train_batch_size=48     --learning_rate=0.002     --warmup_proportion=0.0     --max_steps=7038     --num_steps_per_checkpoint=2500     --max_seq_length=128     --max_predictions_per_seq=20     --input_dir=/workspace/data     '
11: + PHASE2='    --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt     '
11: + PHASES=("$PHASE1" "$PHASE2")
11: + export RANK=11
11: + RANK=11
11: + export WORLD_SIZE=32
11: + WORLD_SIZE=32
11: WORLD_SIZE=32
11: + echo WORLD_SIZE=32
11: ++ cut -d - -f1
11: ++ echo 'node[031-038]'
11: ++ cut -d - -f2 -
11: ++ tr -d '['
11: + export MASTER_ADDR=node031
11: + MASTER_ADDR=node031
11: MASTER_ADDR=node031
11: + echo MASTER_ADDR=node031
11: + export MASTER_PORT=19002
11: + MASTER_PORT=19002
11: HOSTNAME=node031
11: + echo HOSTNAME=node031
11: + declare -a CMD
11: + [[ -n 3 ]]
11: + [[ 32 -gt 8 ]]
11: + CMD=('bindpcie' '--cpu=exclusive' '--ib=single' '--' ${NSYSCMD} 'python' '-u')
11: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
11: -bert_config_path=/workspace/phase1/bert_config.json '
11: + '[' -n 3 ']'
11: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
11: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3 '
11: + [[ 0 != 1 ]]
11: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
11: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16'
11: + [[ '' -ge 1 ]]
11: + BERT_CMD='    bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     -
11: -bert_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu  '
11: + [[ 0 != 0 ]]
11: + '[' '' = apiLog.sh ']'
11: + '[' '' = 1 ']'
11: + eval '     bindpcie --cpu=exclusive --ib=single -- python -u     /workspace/bert/run_pretraining.py         --train_batch_size=48     --learning_rate=0.002     --opt_lamb_beta_1=0.66     --opt_lamb_beta_2=0.996     --warmup_proportion=0.0     --warmup_steps=0.0     --start_warmup_step=0     --max_steps=2254     --phase2     --max_seq_length=512     --max_predictions_per_seq=76     --input_dir=/workspace/data_phase2     --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt          --do_train     --skip_checkpoint     --train_mlm_accuracy_window_size=0     --target_mlm_accuracy=0.720     --weight_decay_rate=0.01     --max_samples_termination=4500000     --eval_iter_start_samples=175000 --eval_iter_samples=175000     --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000     --cache_eval_data     --output_dir=/results     --fp16      --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1     --gradient_accumulation_steps=1     --log_freq=0     --be
11: rt_config_path=/workspace/phase1/bert_config.json  --local_rank=3  --allreduce_post_accumulation --allreduce_post_accumulation_fp16  --dense_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add  --fused_gemm_gelu   --seed=13555'
11: ++ bindpcie --cpu=exclusive --ib=single -- python -u /workspace/bert/run_pretraining.py --train_batch_size=48 --learning_rate=0.002 --opt_lamb_beta_1=0.66 --opt_lamb_beta_2=0.996 --warmup_proportion=0.0 --warmup_steps=0.0 --start_warmup_step=0 --max_steps=2254 --phase2 --max_seq_length=512 --max_predictions_per_seq=76 --input_dir=/workspace/data_phase2 --init_checkpoint=/workspace/phase1/model.ckpt-28252.pt --do_train --skip_checkpoint --train_mlm_accuracy_window_size=0 --target_mlm_accuracy=0.720 --weight_decay_rate=0.01 --max_samples_termination=4500000 --eval_iter_start_samples=175000 --eval_iter_samples=175000 --eval_batch_size=16 --eval_dir=/workspace/evaldata --num_eval_examples 10000 --cache_eval_data --output_dir=/results --fp16 --distributed_lamb --dwu-num-rs-pg=1 --dwu-num-ar-pg=1 --dwu-num-ag-pg=1 --dwu-num-blocks=1 --gradient_accumulation_steps=1 --log_freq=0 --bert_config_path=/workspace/phase1/bert_config.json --local_rank=3 --allreduce_post_accumulation --allreduce_post_accumulation_fp16 --dens
11: e_seq_output --unpad --unpad_fmha --exchange_padding --dwu-group-size=4 --fused_bias_fc --fused_bias_mha --fused_dropout_add --fused_gemm_gelu --seed=13555
 0: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
 2: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
 3: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
28: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
 1: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
30: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
29: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
22: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
27: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
23: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
20: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
25: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
14: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
 6: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
 4: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
26: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
16: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
17: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
18: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
12: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
13: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
 7: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
10: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
31: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
 9: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
11: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
21: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
24: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
15: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
 5: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
19: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
 8: num_gpus=4 num_sockets = 2 num_nodes=8 cores_per_socket=64
 0: :::MLLOG {"namespace": "", "time_ms": 1665725685317, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
 3: :::MLLOG {"namespace": "", "time_ms": 1665725685317, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
 2: :::MLLOG {"namespace": "", "time_ms": 1665725685317, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
 1: :::MLLOG {"namespace": "", "time_ms": 1665725685342, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
31: :::MLLOG {"namespace": "", "time_ms": 1665725685525, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
30: :::MLLOG {"namespace": "", "time_ms": 1665725685525, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
29: :::MLLOG {"namespace": "", "time_ms": 1665725685525, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
28: :::MLLOG {"namespace": "", "time_ms": 1665725685525, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
 6: :::MLLOG {"namespace": "", "time_ms": 1665725685603, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
 4: :::MLLOG {"namespace": "", "time_ms": 1665725685603, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
 5: :::MLLOG {"namespace": "", "time_ms": 1665725685603, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
 7: :::MLLOG {"namespace": "", "time_ms": 1665725685603, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
25: :::MLLOG {"namespace": "", "time_ms": 1665725685605, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
26: :::MLLOG {"namespace": "", "time_ms": 1665725685605, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
24: :::MLLOG {"namespace": "", "time_ms": 1665725685631, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
21: :::MLLOG {"namespace": "", "time_ms": 1665725685633, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
20: :::MLLOG {"namespace": "", "time_ms": 1665725685633, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
22: :::MLLOG {"namespace": "", "time_ms": 1665725685633, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
23: :::MLLOG {"namespace": "", "time_ms": 1665725685633, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
27: :::MLLOG {"namespace": "", "time_ms": 1665725685605, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
12: :::MLLOG {"namespace": "", "time_ms": 1665725685676, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
15: :::MLLOG {"namespace": "", "time_ms": 1665725685676, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
13: :::MLLOG {"namespace": "", "time_ms": 1665725685676, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
14: :::MLLOG {"namespace": "", "time_ms": 1665725685676, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
11: :::MLLOG {"namespace": "", "time_ms": 1665725685693, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
10: :::MLLOG {"namespace": "", "time_ms": 1665725685693, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
 9: :::MLLOG {"namespace": "", "time_ms": 1665725685693, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
 8: :::MLLOG {"namespace": "", "time_ms": 1665725685693, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
19: :::MLLOG {"namespace": "", "time_ms": 1665725685723, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
18: :::MLLOG {"namespace": "", "time_ms": 1665725685724, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
17: :::MLLOG {"namespace": "", "time_ms": 1665725685724, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
16: :::MLLOG {"namespace": "", "time_ms": 1665725685724, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1178}}
 3: device: cuda:3 n_gpu: 32, distributed training: True, 16-bits training: True
 1: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
 0: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
26: device: cuda:2 n_gpu: 32, distributed training: True, 16-bits training: True
20: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1665725685785, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "bert", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1186}}
25: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1665725685785, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Dell", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1186}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725685785, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1186}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725685785, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1186}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725685786, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "8xXE8545x4A100-SXM4-40GB", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1186}}
21: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1665725685786, "event_type": "POINT_IN_TIME", "key": "seed", "value": 6521, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1188}}
 6: device: cuda:2 n_gpu: 32, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1665725685786, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 1536, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1190}}
 7: device: cuda:3 n_gpu: 32, distributed training: True, 16-bits training: True
22: device: cuda:2 n_gpu: 32, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1665725685786, "event_type": "POINT_IN_TIME", "key": "d_batch_size", "value": 48, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1192}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725685786, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1194}}
23: device: cuda:3 n_gpu: 32, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1665725685786, "event_type": "POINT_IN_TIME", "key": "max_predictions_per_seq", "value": 76, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1196}}
 4: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1665725685786, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_training_steps", "value": 2254.0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1198}}
31: device: cuda:3 n_gpu: 32, distributed training: True, 16-bits training: True
 5: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1665725685786, "event_type": "POINT_IN_TIME", "key": "num_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1200}}
 0: parsed args:
 0: Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, average_packing_rate=1, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', bypass_amp=False, cache_eval_data=True, checkpoint_activations=False, cuda_graph_mode='segmented', ddp_type='apex', dense_seq_output=True, device=device(type='cuda', index=0), disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, distributed_lamb=True, do_train=True, dwu_e5m2_allgather=False, dwu_group_size=4, dwu_num_ag_pg=1, dwu_num_ar_pg=1, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_overlap_reductions=False, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=175000, eval_iter_start_samples=175000, exchange_padding=True, fp16=True, fused_bias_fc=True, fused_bias_fc_loss_head=False, fused_bias_mha=True, fused_dropout_add=True, fused_gelu_bias=False, fused_gemm_gelu=True, fused_mha=False, g
 0: radient_accumulation_steps=1, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, input_dir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.002, local_rank=0, log_freq=0.0, loss_scale=0.0, max_iterations_per_graph=4, max_pack_factor=1, max_predictions_per_seq=76, max_samples_termination=4500000.0, max_seq_length=512, max_steps=2254.0, min_samples_to_start_checkpoints=3000000, n_gpu=32, num_epochs_to_generate_seeds_for=2, num_eval_examples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.66, opt_lamb_beta_2=0.996, output_dir='/results', packed_samples=False, pad=False, pad_fmha=False, phase2=True, resume_from_checkpoint=False, seed=6521, skip_checkpoint=True, start_warmup_step=0.0, synthetic_input=False, target_mlm_accuracy=0.72, train_batch_size=48, train_mlm_accuracy_window_size=0, unpad=True, unpad_fmha=True, use_cuda_graph=False, use_ddp=False, use_env=False, use_gradient_as_bucket_view=False, warmup_proportion=0.0, warmup_steps=0.0, wei
 0: ght_decay_rate=0.01)
14: device: cuda:2 n_gpu: 32, distributed training: True, 16-bits training: True
15: device: cuda:3 n_gpu: 32, distributed training: True, 16-bits training: True
12: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
13: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
24: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
30: device: cuda:2 n_gpu: 32, distributed training: True, 16-bits training: True
18: device: cuda:2 n_gpu: 32, distributed training: True, 16-bits training: True
19: device: cuda:3 n_gpu: 32, distributed training: True, 16-bits training: True
29: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
17: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
28: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
16: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
10: device: cuda:2 n_gpu: 32, distributed training: True, 16-bits training: True
11: device: cuda:3 n_gpu: 32, distributed training: True, 16-bits training: True
 9: device: cuda:1 n_gpu: 32, distributed training: True, 16-bits training: True
 8: device: cuda:0 n_gpu: 32, distributed training: True, 16-bits training: True
27: device: cuda:3 n_gpu: 32, distributed training: True, 16-bits training: True
 2: device: cuda:2 n_gpu: 32, distributed training: True, 16-bits training: True
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687605, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/embeddings/word_embeddings"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687605, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/embeddings/position_embeddings"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687605, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/embeddings/token_type_embeddings"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687605, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/embeddings/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687605, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/embeddings/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687605, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687605, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687605, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687606, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687606, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687606, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687606, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687606, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687606, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687606, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687606, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687606, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687606, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687606, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687606, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687606, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_0/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687606, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687607, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687607, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687607, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687607, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687607, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687607, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687607, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687607, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687607, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687607, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687607, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687607, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687607, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687607, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687607, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_1/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687608, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687608, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687608, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687608, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687608, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687608, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687608, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687608, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687608, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687608, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687608, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687608, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687608, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687608, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687609, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687609, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_2/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687609, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687609, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687609, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687609, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687609, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687609, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687609, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687609, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687609, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687609, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687609, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687609, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687609, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687610, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687610, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687610, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_3/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687610, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687610, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687610, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687610, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687610, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687610, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687610, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687610, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687610, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687610, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687610, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687610, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687611, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687611, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687611, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687611, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_4/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687611, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687611, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687611, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687611, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687611, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687611, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687611, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687611, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687611, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687611, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687612, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687612, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687612, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687612, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687612, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687612, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_5/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687612, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687612, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687612, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687612, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687612, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687612, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687612, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687612, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687612, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687613, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687613, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687613, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687613, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687613, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687613, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687613, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_6/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687613, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687613, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687613, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687613, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687613, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687613, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687613, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687613, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687614, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687614, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687614, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687614, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687614, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687614, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687614, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687614, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_7/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687614, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687614, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687614, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687614, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687614, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687614, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687614, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687615, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687615, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687615, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687615, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687615, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687615, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687615, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687615, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687615, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_8/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687615, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687615, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687615, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687615, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687615, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687616, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687616, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687616, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687616, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687616, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687616, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687616, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687616, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687616, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687616, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687616, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_9/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687616, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687616, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687616, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687616, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687617, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687617, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687617, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687617, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687617, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687617, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687617, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687617, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687617, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687617, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687617, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687617, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_10/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687617, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687617, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687617, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687618, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687618, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687618, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687618, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687618, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687618, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687618, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687618, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687618, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687618, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687618, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687618, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687618, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_11/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687618, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687618, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687619, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687619, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687619, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687619, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687619, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687619, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687619, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687619, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687619, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687619, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687619, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687619, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687619, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687619, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_12/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687619, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687620, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687620, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687620, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687620, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687620, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687620, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687620, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687620, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687620, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687620, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687620, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687620, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687620, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687620, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687621, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_13/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687621, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687621, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687621, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687621, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687621, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687621, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687621, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687621, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687621, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687621, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687621, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687621, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687621, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687621, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687622, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687622, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_14/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687622, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687622, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687622, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687622, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687622, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687622, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687622, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687622, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687622, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687622, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687622, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687622, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687622, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687623, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687623, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687623, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_15/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687623, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687623, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687623, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687623, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687623, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687623, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687623, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687623, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687623, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687623, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687623, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687623, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687624, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687624, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687624, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687624, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_16/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687624, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687624, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687624, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687624, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687624, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687624, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687624, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687624, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687624, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687624, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687624, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687625, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687625, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687625, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687625, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687625, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_17/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687625, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687625, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687625, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687625, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687625, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687625, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687625, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687625, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687625, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687625, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687626, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687626, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687626, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687626, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687626, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687626, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_18/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687626, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687626, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687626, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687626, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687626, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687626, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687626, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687626, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687626, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687627, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687627, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687627, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687627, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687627, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687627, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687627, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_19/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687627, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687627, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687627, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687627, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687627, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687627, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687627, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687627, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687628, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687628, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687628, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687628, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687628, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687628, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687628, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687628, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_20/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687628, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687628, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687628, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687628, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687628, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687628, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687628, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687629, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687629, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687629, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687629, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687629, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687629, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687629, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687629, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687629, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_21/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687629, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687629, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687629, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687629, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687629, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687630, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687630, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687630, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687630, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687630, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687630, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687630, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687630, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687630, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687630, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687630, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_22/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687630, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/self/query/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687630, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/self/query/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687630, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/self/key/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687630, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/self/key/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687631, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/self/value/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687631, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/self/value/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687631, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687631, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687631, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687631, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/attention/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687631, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/intermediate/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687631, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/intermediate/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687631, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/output/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687631, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/output/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687631, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/output/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687631, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/encoder/layer_23/output/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687631, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/pooler/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687631, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "bert/pooler/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687631, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "cls/predictions/output_bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687632, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "cls/predictions/transform/dense/kernel"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687632, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "cls/predictions/transform/dense/bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687632, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "cls/predictions/transform/LayerNorm/gamma"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687632, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "cls/predictions/transform/LayerNorm/beta"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687632, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "cls/seq_relationship/output_weights"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687632, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 789, "tensor": "cls/seq_relationship/output_bias"}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725687974, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.002, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 817}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725690645, "event_type": "POINT_IN_TIME", "key": "opt_lamb_epsilon", "value": 1e-06, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 853}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725690646, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_1", "value": 0.66, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 856}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725690646, "event_type": "POINT_IN_TIME", "key": "opt_lamb_beta_2", "value": 0.996, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 857}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725690646, "event_type": "POINT_IN_TIME", "key": "opt_lamb_weight_decay_rate", "value": 0.01, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 858}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725690812, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 86}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725690813, "event_type": "POINT_IN_TIME", "key": "opt_lamb_learning_rate_decay_poly_power", "value": 1.0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 87}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725690813, "event_type": "POINT_IN_TIME", "key": "start_warmup_step", "value": 0, "metadata": {"file": "/workspace/bert/schedulers.py", "lineno": 88}}
 5: Torch distributed is available.
 5: Torch distributed is initialized.
 1: Torch distributed is available.
 1: Torch distributed is initialized.
 2: Torch distributed is available.
 2: Torch distributed is initialized.
13: Torch distributed is available.
13: Torch distributed is initialized.
 3: Torch distributed is available.
 3: Torch distributed is initialized.
14: Torch distributed is available.
14: Torch distributed is initialized.
 7: Torch distributed is available.
 7: Torch distributed is initialized.
29: Torch distributed is available.
29: Torch distributed is initialized.
30: Torch distributed is available.
30: Torch distributed is initialized.
15: Torch distributed is available.
15: Torch distributed is initialized.
31: Torch distributed is available.
31: Torch distributed is initialized.
17: Torch distributed is available.
17: Torch distributed is initialized.
 0: Torch distributed is available.
 0: Torch distributed is initialized.
18: Torch distributed is available.
18: Torch distributed is initialized.
19: Torch distributed is available.
19: Torch distributed is initialized.
12: Torch distributed is available.
12: Torch distributed is initialized.
28: Torch distributed is available.
28: Torch distributed is initialized.
 4: Torch distributed is available.
 4: Torch distributed is initialized.
 6: Torch distributed is available.
 6: Torch distributed is initialized.
16: Torch distributed is available.
16: Torch distributed is initialized.
26: Torch distributed is available.
26: Torch distributed is initialized.
25: Torch distributed is available.
25: Torch distributed is initialized.
27: Torch distributed is available.
27: Torch distributed is initialized.
24: Torch distributed is available.
24: Torch distributed is initialized.
22: Torch distributed is available.
22: Torch distributed is initialized.
23: Torch distributed is available.
23: Torch distributed is initialized.
21: Torch distributed is available.
21: Torch distributed is initialized.
 9: Torch distributed is available.
 9: Torch distributed is initialized.
11: Torch distributed is available.
11: Torch distributed is initialized.
10: Torch distributed is available.
10: Torch distributed is initialized.
20: Torch distributed is available.
20: Torch distributed is initialized.
 8: Torch distributed is available.
 8: Torch distributed is initialized.
 0: :::MLLOG {"namespace": "", "time_ms": 1665725694877, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1521}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725694878, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1521}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725694890, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1533, "epoch_num": 0}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725694891, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1535, "first_epoch_num": 1, "epoch_count": 1}}
 0: parsed args:
 0: Namespace(allreduce_post_accumulation=True, allreduce_post_accumulation_fp16=True, average_packing_rate=1, bert_config_path='/workspace/phase1/bert_config.json', bert_model='bert-large-uncased', bypass_amp=False, cache_eval_data=True, checkpoint_activations=False, cuda_graph_mode='segmented', ddp_type='apex', dense_seq_output=True, device=device(type='cuda', index=0), disable_apex_softmax=False, disable_fuse_mask=False, disable_fuse_qkv=False, disable_fuse_scale=False, distributed_lamb=True, do_train=True, dwu_e5m2_allgather=False, dwu_group_size=4, dwu_num_ag_pg=1, dwu_num_ar_pg=1, dwu_num_blocks=1, dwu_num_chunks=1, dwu_num_rs_pg=1, dwu_overlap_reductions=False, enable_fuse_dropout=False, enable_stream=False, eval_batch_size=16, eval_dir='/workspace/evaldata', eval_iter_samples=175000, eval_iter_start_samples=175000, exchange_padding=True, fp16=True, fused_bias_fc=True, fused_bias_fc_loss_head=False, fused_bias_mha=True, fused_dropout_add=True, fused_gelu_bias=False, fused_gemm_gelu=True, fused_mha=False, g
 0: radient_accumulation_steps=1, init_checkpoint='/workspace/phase1/model.ckpt-28252.pt', init_tf_checkpoint=None, input_dir='/workspace/data_phase2', keep_n_most_recent_checkpoints=20, learning_rate=0.002, local_rank=0, log_freq=0.0, loss_scale=0.0, max_iterations_per_graph=4, max_pack_factor=1, max_predictions_per_seq=76, max_samples_termination=4500000.0, max_seq_length=512, max_steps=2254.0, min_samples_to_start_checkpoints=3000000, n_gpu=32, num_epochs_to_generate_seeds_for=2, num_eval_examples=10000, num_samples_per_checkpoint=500000, opt_lamb_beta_1=0.66, opt_lamb_beta_2=0.996, output_dir='/results', packed_samples=False, pad=False, pad_fmha=False, phase2=True, resume_from_checkpoint=False, resume_step=0, seed=6521, skip_checkpoint=True, start_warmup_step=0.0, synthetic_input=False, target_mlm_accuracy=0.72, train_batch_size=48, train_mlm_accuracy_window_size=0, unpad=True, unpad_fmha=True, use_cuda_graph=False, use_ddp=False, use_env=False, use_gradient_as_bucket_view=False, warmup_proportion=0.0, warmup
 0: _steps=0.0, weight_decay_rate=0.01)
 0: epoch: 1
 0: :::MLLOG {"namespace": "", "time_ms": 1665725694892, "event_type": "POINT_IN_TIME", "key": "data_file", "value": "/workspace/data_phase2/part_03430_of_04320.hdf5", "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1569}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725721605, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.37580767273902893, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 175104}}
 0: {'global_steps': 114, 'eval_loss': 4.099331855773926, 'eval_mlm_accuracy': 0.37580767273902893}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725746611, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.40792322158813477, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 350208}}
 0: {'global_steps': 228, 'eval_loss': 3.7753100395202637, 'eval_mlm_accuracy': 0.40792322158813477}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725771598, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.5327308773994446, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 525312}}
 0: {'global_steps': 342, 'eval_loss': 2.7075753211975098, 'eval_mlm_accuracy': 0.5327308773994446}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725796618, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6969420909881592, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 700416}}
 0: {'global_steps': 456, 'eval_loss': 1.4561851024627686, 'eval_mlm_accuracy': 0.6969420909881592}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725821637, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7064765691757202, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 875520}}
 0: {'global_steps': 570, 'eval_loss': 1.3917908668518066, 'eval_mlm_accuracy': 0.7064765691757202}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725846700, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7095122933387756, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 1050624}}
 0: {'global_steps': 684, 'eval_loss': 1.371455192565918, 'eval_mlm_accuracy': 0.7095122933387756}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725872733, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7115345597267151, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 1225728}}
 0: {'global_steps': 798, 'eval_loss': 1.359946608543396, 'eval_mlm_accuracy': 0.7115345597267151}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725898899, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7136362195014954, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 1400832}}
 0: {'global_steps': 912, 'eval_loss': 1.3496689796447754, 'eval_mlm_accuracy': 0.7136362195014954}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725924970, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.714458167552948, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 1575936}}
 0: {'global_steps': 1026, 'eval_loss': 1.3410450220108032, 'eval_mlm_accuracy': 0.714458167552948}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725950995, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7156677842140198, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 1751040}}
 0: {'global_steps': 1140, 'eval_loss': 1.3369654417037964, 'eval_mlm_accuracy': 0.7156677842140198}
 0: :::MLLOG {"namespace": "", "time_ms": 1665725977070, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7163122892379761, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 1926144}}
 0: {'global_steps': 1254, 'eval_loss': 1.3263615369796753, 'eval_mlm_accuracy': 0.7163122892379761}
 0: :::MLLOG {"namespace": "", "time_ms": 1665726003113, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7173888087272644, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 2101248}}
 0: {'global_steps': 1368, 'eval_loss': 1.321001648902893, 'eval_mlm_accuracy': 0.7173888087272644}
 0: :::MLLOG {"namespace": "", "time_ms": 1665726029227, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7185470461845398, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 2276352}}
 0: {'global_steps': 1482, 'eval_loss': 1.3171342611312866, 'eval_mlm_accuracy': 0.7185470461845398}
 0: :::MLLOG {"namespace": "", "time_ms": 1665726055839, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7191168665885925, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 2451456}}
 0: {'global_steps': 1596, 'eval_loss': 1.3147753477096558, 'eval_mlm_accuracy': 0.7191168665885925}
 0: :::MLLOG {"namespace": "", "time_ms": 1665726081782, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7201372981071472, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1722, "epoch_num": 2626560}}
 0: {'global_steps': 1709, 'eval_loss': 1.306847333908081, 'eval_mlm_accuracy': 0.7201372981071472}
 0: 0.720137 > 0.720000, Target MLM Accuracy reached at 1709
 0: (1, 1710.0) {'final_loss': 0.0}
 0: :::MLLOG {"namespace": "", "time_ms": 1665726081843, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1850, "first_epoch_num": 1}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665726081843, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1853, "epoch_num": 2626560}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665726081843, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 2626560, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1861}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665726081843, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 10000, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1864}}
 0: :::MLLOG {"namespace": "", "time_ms": 1665726081858, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/bert/run_pretraining.py", "lineno": 1867, "status": "success"}}
 0: {'e2e_time': 396.6354761123657, 'training_sequences_per_second': 8895.988643743383, 'final_loss': 0.0, 'raw_train_time': 389.1803529262543}
 3: + set +x
 3: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
 3: RESULT,bert,17081,400,root,2022-10-14 12:34:42 AM
26: + set +x
23: + set +x
23: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
23: RESULT,bert,14464,400,root,2022-10-14 12:34:42 AM
26: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
26: RESULT,bert,6089,400,root,2022-10-14 12:34:42 AM
17: + set +x
17: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
17: RESULT,bert,30615,400,root,2022-10-14 12:34:42 AM
10: + set +x
10: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
10: RESULT,bert,7539,400,root,2022-10-14 12:34:42 AM
 7: + set +x
30: + set +x
 7: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
 7: RESULT,bert,16273,400,root,2022-10-14 12:34:42 AM
30: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
30: RESULT,bert,30065,400,root,2022-10-14 12:34:42 AM
 2: + set +x
 2: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
 2: RESULT,bert,8650,400,root,2022-10-14 12:34:42 AM
25: + set +x
25: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
25: RESULT,bert,3267,400,root,2022-10-14 12:34:42 AM
 9: + set +x
 9: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
 9: RESULT,bert,21967,400,root,2022-10-14 12:34:42 AM
19: + set +x
22: + set +x
19: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
19: RESULT,bert,27968,400,root,2022-10-14 12:34:42 AM
22: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
22: RESULT,bert,124,400,root,2022-10-14 12:34:42 AM
 5: + set +x
31: + set +x
31: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
 1: + set +x
31: RESULT,bert,1363,400,root,2022-10-14 12:34:42 AM
 5: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
 5: RESULT,bert,10283,400,root,2022-10-14 12:34:42 AM
 1: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
 1: RESULT,bert,20326,400,root,2022-10-14 12:34:42 AM
14: + set +x
14: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
14: RESULT,bert,25594,400,root,2022-10-14 12:34:42 AM
11: + set +x
24: + set +x
11: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
11: RESULT,bert,13555,400,root,2022-10-14 12:34:42 AM
21: + set +x
24: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
24: RESULT,bert,8199,400,root,2022-10-14 12:34:42 AM
18: + set +x
21: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
21: RESULT,bert,26817,400,root,2022-10-14 12:34:42 AM
18: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
18: RESULT,bert,18449,400,root,2022-10-14 12:34:42 AM
29: + set +x
29: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
29: RESULT,bert,21606,400,root,2022-10-14 12:34:42 AM
13: + set +x
13: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
13: RESULT,bert,23049,400,root,2022-10-14 12:34:42 AM
 6: + set +x
 6: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
 6: RESULT,bert,25984,400,root,2022-10-14 12:34:42 AM
15: + set +x
15: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
15: RESULT,bert,20924,400,root,2022-10-14 12:34:42 AM
 0: + set +x
 0: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
 0: RESULT,bert,6521,400,root,2022-10-14 12:34:42 AM
16: + set +x
16: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
16: RESULT,bert,17731,400,root,2022-10-14 12:34:42 AM
27: + set +x
27: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
27: RESULT,bert,5671,400,root,2022-10-14 12:34:42 AM
20: + set +x
20: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
20: RESULT,bert,30995,400,root,2022-10-14 12:34:42 AM
 8: + set +x
 8: ENDING TIMING RUN AT 2022-10-14 12:41:22 AM
 8: RESULT,bert,21977,400,root,2022-10-14 12:34:42 AM
28: + set +x
28: ENDING TIMING RUN AT 2022-10-14 12:41:23 AM
28: RESULT,bert,10136,401,root,2022-10-14 12:34:42 AM
 4: + set +x
 4: ENDING TIMING RUN AT 2022-10-14 12:41:23 AM
 4: RESULT,bert,9791,401,root,2022-10-14 12:34:42 AM
12: + set +x
12: ENDING TIMING RUN AT 2022-10-14 12:41:23 AM
12: RESULT,bert,23150,401,root,2022-10-14 12:34:42 AM
