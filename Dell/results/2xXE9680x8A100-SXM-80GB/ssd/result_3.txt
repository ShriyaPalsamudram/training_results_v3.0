+ echo 'Beginning trial 4 of 5'
Beginning trial 4 of 5
+ echo ':::DLPAL dockerd://mlperf-nvidia:single_stage_detector-pytorch 38 2 xe9680node[50,60]'
:::DLPAL dockerd://mlperf-nvidia:single_stage_detector-pytorch 38 2 xe9680node[50,60]
+ srun -N1 -n1 --container-name=single_stage_detector_38 --mpi=pmi2 python -c ''
+ '[' 1 -eq 1 ']'
+ srun --ntasks=2 --mpi=pmi2 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on xe9680node60
Clearing cache on xe9680node50
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=2 --container-name=single_stage_detector_38 --mpi=pmi2 python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1684350536758, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1684350537592, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ srun --ntasks=16 --ntasks-per-node=8 --container-name=single_stage_detector_38 --container-mounts=/mount/training_datasets_v2.0/ssd/:/datasets/open-images-v6,/scripts/training_results_v3.0/ssd_multinode/:/results,/mount/training_datasets_v2.0/ssd/train/:/root/.cache/torch --container-workdir=/workspace/ssd slurm2pytorch ./run_and_time.sh
STARTING TIMING RUN AT 2023-05-17 07:09:08 PM
STARTING TIMING RUN AT 2023-05-17 07:09:08 PM
RANK 1: LOCAL_RANK 1, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 1, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
RANK 12: LOCAL_RANK 4, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 12, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 07:09:08 PM
RANK 9: LOCAL_RANK 1, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 9, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 07:09:09 PM
RANK 2: LOCAL_RANK 2, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 2, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 07:09:09 PM
RANK 8: LOCAL_RANK 0, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 8, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 07:09:09 PM
RANK 3: LOCAL_RANK 3, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 3, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 07:09:09 PM
RANK 6: LOCAL_RANK 6, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 6, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 07:09:09 PM
RANK 13: LOCAL_RANK 5, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 13, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 07:09:09 PM
RANK 15: LOCAL_RANK 7, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 15, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 07:09:09 PM
RANK 7: LOCAL_RANK 7, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 7, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 07:09:09 PM
RANK 10: LOCAL_RANK 2, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 10, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 07:09:09 PM
RANK 4: LOCAL_RANK 4, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 4, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 07:09:09 PM
RANK 11: LOCAL_RANK 3, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 11, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 07:09:09 PM
RANK 0: LOCAL_RANK 0, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 0, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 07:09:10 PM
RANK 5: LOCAL_RANK 5, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 5, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 07:09:10 PM
RANK 14: LOCAL_RANK 6, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 14, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-oesqg1qj because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-kocnp2ga because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-c0v4snxr because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-qfv2vud0 because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-rrgcxbfg because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-qkrmk2gq because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-b33_o22w because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-icy6kc8c because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-etc0p9dw because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-hnbk10r7 because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-zcvh2tl2 because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-p7c_gqcb because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-_i8hsqll because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-6hzyyfeg because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-_li35kdd because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-r2lvxgbt because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
| distributed init (rank 15): env://
| distributed init (rank 10): env://
| distributed init (rank 9): env://
| distributed init (rank 8): env://
| distributed init (rank 14): env://
| distributed init (rank 12): env://
| distributed init (rank 11): env://
| distributed init (rank 13): env://
| distributed init (rank 7): env://
| distributed init (rank 3): env://
| distributed init (rank 2): env://
| distributed init (rank 4): env://
| distributed init (rank 5): env://
| distributed init (rank 6): env://
| distributed init (rank 0): env://
| distributed init (rank 1): env://
:::MLLOG {"namespace": "", "time_ms": 1684350569423, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "ssd", "metadata": {"file": "train.py", "lineno": 313}}
:::MLLOG {"namespace": "", "time_ms": 1684350569478, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Dell", "metadata": {"file": "train.py", "lineno": 313}}
:::MLLOG {"namespace": "", "time_ms": 1684350569479, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "train.py", "lineno": 313}}
:::MLLOG {"namespace": "", "time_ms": 1684350569479, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "train.py", "lineno": 313}}
:::MLLOG {"namespace": "", "time_ms": 1684350569479, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "2xXE9680x8A100-SXM-80GB", "metadata": {"file": "train.py", "lineno": 313}}
:::MLLOG {"namespace": "", "time_ms": 1684350569479, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 314}}
:::MLLOG {"namespace": "", "time_ms": 1684350569504, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3462256890, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684350569504, "event_type": "POINT_IN_TIME", "key": "local_batch_size", "value": 16, "metadata": {"file": "train.py", "lineno": 332}}
:::MLLOG {"namespace": "", "time_ms": 1684350569504, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 256, "metadata": {"file": "train.py", "lineno": 333}}
:::MLLOG {"namespace": "", "time_ms": 1684350569504, "event_type": "POINT_IN_TIME", "key": "epoch_count", "value": 6, "metadata": {"file": "train.py", "lineno": 334}}
:::MLLOG {"namespace": "", "time_ms": 1684350569504, "event_type": "POINT_IN_TIME", "key": "first_epoch_num", "value": 0, "metadata": {"file": "train.py", "lineno": 335}}
Namespace(allreduce_barrier=False, amp=True, apex_adam=True, apex_backbone_fusion=False, apex_focal_loss=True, apex_head_fusion=True, async_coco=True, async_coco_check_freq=20, backbone='resnext50_32x4d', batch_size=16, broadcast_buffers=False, cls_head_pad=True, coco_threads=8, cocoeval='nvidia', cuda_graphs=True, cuda_graphs_eval=False, cuda_graphs_syn=True, cuda_profiler=False, cuda_profiler_eval=False, cudnn_bench=False, dali=True, dali_cmn=0, dali_cpu_decode=False, dali_eval=True, dali_eval_cache=False, dali_matched_idxs=True, dali_preallocate_height=0, dali_preallocate_width=0, dali_prefetch_queue_depth=2, data_augmentation='hflip', data_layout='channels_last', dataset='openimages-mlperf', dataset_path='/datasets/open-images-v6', ddp_bucket_sz=25, ddp_first_bucket_sz=None, device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, enable_sharp=False, epochs=6, eval_batch_size=16, eval_print_freq=20, eval_rank=0, eval_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], fp16_allreduce=True, frozen_bn_fp16=True, frozen_bn_opt=True, gpu=0, image_size=[800, 800], jit=True, lr=8.5e-05, master_weights=False, max_boxes=1000, max_eval_iters_per_epoch=None, max_iters_per_epoch=None, model_warmup_epochs=16, not_graphed_prologues=False, num_classes=None, num_eval_ranks=16, num_train_ranks=16, output_dir=None, pretrained=False, print_freq=20, rank=0, ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], reg_head_pad=True, resume='', seed=3462256890, skip_eval=False, skip_metric_loss=True, start_epoch=0, syn_dataset=False, sync_after_graph_replay=False, sync_bn=False, target_map=0.34, test_only=False, train_annotations_file=None, train_data_path=None, train_rank=0, train_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], trainable_backbone_layers=3, val_annotations_file=None, val_data_path=None, warmup_epochs=0, warmup_factor=0.001, workers=4, world_size=16)
Getting dataset information
Creating model
:::MLLOG {"namespace": "", "time_ms": 1684350569533, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569536, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569537, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p7.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569539, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p7.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569485, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3462256891, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684350569504, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3462256892, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684350569505, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3462256894, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684350569505, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3462256896, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684350569506, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3462256893, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684350569520, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3462256900, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684350569520, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3462256898, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684350569520, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3462256899, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684350569520, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3462256901, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684350569520, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3462256903, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684350569520, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3462256905, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684350569508, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3462256897, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684350569510, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3462256895, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684350569520, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3462256902, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684350569520, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3462256904, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684350569671, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569671, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569671, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569672, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569672, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569672, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569672, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569672, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569673, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569673, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569673, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569673, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569673, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569674, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569674, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569675, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569676, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569676, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569677, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569677, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569677, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569678, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569679, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569679, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569680, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569681, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569681, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569684, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569686, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569689, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569689, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569692, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569694, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569695, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569697, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569700, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569700, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569703, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569705, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569706, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569708, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569711, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569711, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569714, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569719, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569720, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569730, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569739, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569749, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569750, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569760, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569769, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569771, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569889, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569890, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569890, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569891, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569891, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569893, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569894, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569896, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569896, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569899, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569899, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569901, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569916, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569919, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569919, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569922, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569922, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569925, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569925, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569928, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569951, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 148, "tensor": "module.head.classification_head.cls_logits.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569975, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 150, "tensor": "module.head.classification_head.cls_logits.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569986, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 318, "tensor": "module.head.regression_head.bbox_reg.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569987, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 320, "tensor": "module.head.regression_head.bbox_reg.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569987, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 325, "tensor": "module.head.regression_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569989, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 327, "tensor": "module.head.regression_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569990, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 325, "tensor": "module.head.regression_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569992, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 327, "tensor": "module.head.regression_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569992, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 325, "tensor": "module.head.regression_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569995, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 327, "tensor": "module.head.regression_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569995, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 325, "tensor": "module.head.regression_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684350569998, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 327, "tensor": "module.head.regression_head.conv.6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684350570182, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adam", "metadata": {"file": "train.py", "lineno": 410}}
:::MLLOG {"namespace": "", "time_ms": 1684350570182, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 8.5e-05, "metadata": {"file": "train.py", "lineno": 411}}
:::MLLOG {"namespace": "", "time_ms": 1684350570182, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0, "metadata": {"file": "train.py", "lineno": 412}}
:::MLLOG {"namespace": "", "time_ms": 1684350570182, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 0, "metadata": {"file": "train.py", "lineno": 413}}
:::MLLOG {"namespace": "", "time_ms": 1684350570182, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0.001, "metadata": {"file": "train.py", "lineno": 414}}
:::MLLOG {"namespace": "", "time_ms": 1684350570182, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "train.py", "lineno": 415}}
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model eval warmup
Time: 55.87879991531372 sec
Creating Dali dataloader
CUDA graph capture
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
:::MLLOG {"namespace": "", "time_ms": 1684350645268, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "train.py", "lineno": 505}}
:::MLLOG {"namespace": "", "time_ms": 1684350645269, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "train.py", "lineno": 509}}
:::MLLOG {"namespace": "", "time_ms": 1684350645269, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 4572, "metadata": {"file": "train.py", "lineno": 536}}
:::MLLOG {"namespace": "", "time_ms": 1684350645897, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 97, "metadata": {"file": "train.py", "lineno": 577}}
Running ...
:::MLLOG {"namespace": "", "time_ms": 1684350645927, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 161, "epoch_num": 0}}
Epoch: [0]  [   0/4572]  eta: 0:10:04    time: 0.1323  data: 0.0003  max mem: 10802
Epoch: [0]  [  20/4572]  eta: 0:10:31    time: 0.1390  data: 0.1294  max mem: 10802
Epoch: [0]  [  40/4572]  eta: 0:10:17    time: 0.1336  data: 0.1243  max mem: 10802
Epoch: [0]  [  60/4572]  eta: 0:10:09    time: 0.1329  data: 0.1217  max mem: 10802
Epoch: [0]  [  80/4572]  eta: 0:10:04    time: 0.1327  data: 0.1240  max mem: 10802
Epoch: [0]  [ 100/4572]  eta: 0:10:00    time: 0.1331  data: 0.1188  max mem: 10802
Epoch: [0]  [ 120/4572]  eta: 0:09:56    time: 0.1328  data: 0.1241  max mem: 10802
Epoch: [0]  [ 140/4572]  eta: 0:09:53    time: 0.1340  data: 0.1204  max mem: 10802
Epoch: [0]  [ 160/4572]  eta: 0:09:50    time: 0.1329  data: 0.1241  max mem: 10802
Epoch: [0]  [ 180/4572]  eta: 0:09:47    time: 0.1330  data: 0.1252  max mem: 10802
Epoch: [0]  [ 200/4572]  eta: 0:09:44    time: 0.1326  data: 0.1239  max mem: 10802
Epoch: [0]  [ 220/4572]  eta: 0:09:41    time: 0.1330  data: 0.1221  max mem: 10802
Epoch: [0]  [ 240/4572]  eta: 0:09:38    time: 0.1327  data: 0.1186  max mem: 10802
Epoch: [0]  [ 260/4572]  eta: 0:09:35    time: 0.1331  data: 0.1244  max mem: 10802
Epoch: [0]  [ 280/4572]  eta: 0:09:32    time: 0.1331  data: 0.1254  max mem: 10802
Epoch: [0]  [ 300/4572]  eta: 0:09:29    time: 0.1328  data: 0.1237  max mem: 10802
Epoch: [0]  [ 320/4572]  eta: 0:09:27    time: 0.1329  data: 0.1243  max mem: 10802
Epoch: [0]  [ 340/4572]  eta: 0:09:24    time: 0.1328  data: 0.1251  max mem: 10802
Epoch: [0]  [ 360/4572]  eta: 0:09:21    time: 0.1329  data: 0.1190  max mem: 10802
Epoch: [0]  [ 380/4572]  eta: 0:09:18    time: 0.1332  data: 0.1194  max mem: 10802
Epoch: [0]  [ 400/4572]  eta: 0:09:16    time: 0.1328  data: 0.1190  max mem: 10802
Epoch: [0]  [ 420/4572]  eta: 0:09:13    time: 0.1331  data: 0.1222  max mem: 10802
Epoch: [0]  [ 440/4572]  eta: 0:09:10    time: 0.1329  data: 0.1187  max mem: 10802
Epoch: [0]  [ 460/4572]  eta: 0:09:07    time: 0.1328  data: 0.1218  max mem: 10802
Epoch: [0]  [ 480/4572]  eta: 0:09:05    time: 0.1329  data: 0.1219  max mem: 10802
Epoch: [0]  [ 500/4572]  eta: 0:09:02    time: 0.1330  data: 0.1243  max mem: 10802
Epoch: [0]  [ 520/4572]  eta: 0:08:59    time: 0.1328  data: 0.1218  max mem: 10802
Epoch: [0]  [ 540/4572]  eta: 0:08:56    time: 0.1328  data: 0.1240  max mem: 10802
Epoch: [0]  [ 560/4572]  eta: 0:08:54    time: 0.1331  data: 0.1189  max mem: 10802
Epoch: [0]  [ 580/4572]  eta: 0:08:51    time: 0.1329  data: 0.1192  max mem: 10802
Epoch: [0]  [ 600/4572]  eta: 0:08:48    time: 0.1333  data: 0.1193  max mem: 10802
Epoch: [0]  [ 620/4572]  eta: 0:08:46    time: 0.1330  data: 0.1220  max mem: 10802
Epoch: [0]  [ 640/4572]  eta: 0:08:43    time: 0.1327  data: 0.1217  max mem: 10802
Epoch: [0]  [ 660/4572]  eta: 0:08:40    time: 0.1330  data: 0.1221  max mem: 10802
Epoch: [0]  [ 680/4572]  eta: 0:08:38    time: 0.1331  data: 0.1222  max mem: 10802
Epoch: [0]  [ 700/4572]  eta: 0:08:35    time: 0.1329  data: 0.1220  max mem: 10802
Epoch: [0]  [ 720/4572]  eta: 0:08:32    time: 0.1330  data: 0.1242  max mem: 10802
Epoch: [0]  [ 740/4572]  eta: 0:08:30    time: 0.1327  data: 0.1186  max mem: 10802
Epoch: [0]  [ 760/4572]  eta: 0:08:27    time: 0.1328  data: 0.1240  max mem: 10802
Epoch: [0]  [ 780/4572]  eta: 0:08:24    time: 0.1330  data: 0.1188  max mem: 10802
Epoch: [0]  [ 800/4572]  eta: 0:08:22    time: 0.1330  data: 0.1221  max mem: 10802
Epoch: [0]  [ 820/4572]  eta: 0:08:19    time: 0.1329  data: 0.1221  max mem: 10802
Epoch: [0]  [ 840/4572]  eta: 0:08:16    time: 0.1330  data: 0.1220  max mem: 10802
Epoch: [0]  [ 860/4572]  eta: 0:08:14    time: 0.1332  data: 0.1191  max mem: 10802
Epoch: [0]  [ 880/4572]  eta: 0:08:11    time: 0.1329  data: 0.1189  max mem: 10802
Epoch: [0]  [ 900/4572]  eta: 0:08:08    time: 0.1328  data: 0.1187  max mem: 10802
Epoch: [0]  [ 920/4572]  eta: 0:08:06    time: 0.1328  data: 0.1217  max mem: 10802
Epoch: [0]  [ 940/4572]  eta: 0:08:03    time: 0.1330  data: 0.1189  max mem: 10802
Epoch: [0]  [ 960/4572]  eta: 0:08:00    time: 0.1327  data: 0.1186  max mem: 10802
Epoch: [0]  [ 980/4572]  eta: 0:07:57    time: 0.1328  data: 0.1187  max mem: 10802
Epoch: [0]  [1000/4572]  eta: 0:07:55    time: 0.1329  data: 0.1221  max mem: 10802
Epoch: [0]  [1020/4572]  eta: 0:07:52    time: 0.1330  data: 0.1221  max mem: 10802
Epoch: [0]  [1040/4572]  eta: 0:07:49    time: 0.1327  data: 0.1190  max mem: 10802
Epoch: [0]  [1060/4572]  eta: 0:07:47    time: 0.1326  data: 0.1191  max mem: 10802
Epoch: [0]  [1080/4572]  eta: 0:07:44    time: 0.1328  data: 0.1190  max mem: 10802
Epoch: [0]  [1100/4572]  eta: 0:07:41    time: 0.1327  data: 0.1190  max mem: 10802
Epoch: [0]  [1120/4572]  eta: 0:07:39    time: 0.1329  data: 0.1188  max mem: 10802
Epoch: [0]  [1140/4572]  eta: 0:07:36    time: 0.1328  data: 0.1187  max mem: 10802
Epoch: [0]  [1160/4572]  eta: 0:07:33    time: 0.1328  data: 0.1187  max mem: 10802
Epoch: [0]  [1180/4572]  eta: 0:07:31    time: 0.1330  data: 0.1220  max mem: 10802
Epoch: [0]  [1200/4572]  eta: 0:07:28    time: 0.1327  data: 0.1186  max mem: 10802
Epoch: [0]  [1220/4572]  eta: 0:07:25    time: 0.1327  data: 0.1187  max mem: 10802
Epoch: [0]  [1240/4572]  eta: 0:07:23    time: 0.1327  data: 0.1240  max mem: 10802
Epoch: [0]  [1260/4572]  eta: 0:07:20    time: 0.1335  data: 0.1193  max mem: 10802
Epoch: [0]  [1280/4572]  eta: 0:07:17    time: 0.1326  data: 0.1239  max mem: 10802
Epoch: [0]  [1300/4572]  eta: 0:07:15    time: 0.1329  data: 0.1242  max mem: 10802
Epoch: [0]  [1320/4572]  eta: 0:07:12    time: 0.1329  data: 0.1192  max mem: 10802
Epoch: [0]  [1340/4572]  eta: 0:07:09    time: 0.1330  data: 0.1189  max mem: 10802
Epoch: [0]  [1360/4572]  eta: 0:07:07    time: 0.1327  data: 0.1185  max mem: 10802
Epoch: [0]  [1380/4572]  eta: 0:07:04    time: 0.1327  data: 0.1189  max mem: 10802
Epoch: [0]  [1400/4572]  eta: 0:07:01    time: 0.1329  data: 0.1192  max mem: 10802
Epoch: [0]  [1420/4572]  eta: 0:06:59    time: 0.1328  data: 0.1190  max mem: 10802
Epoch: [0]  [1440/4572]  eta: 0:06:56    time: 0.1327  data: 0.1218  max mem: 10802
Epoch: [0]  [1460/4572]  eta: 0:06:53    time: 0.1328  data: 0.1241  max mem: 10802
Epoch: [0]  [1480/4572]  eta: 0:06:51    time: 0.1327  data: 0.1190  max mem: 10802
Epoch: [0]  [1500/4572]  eta: 0:06:48    time: 0.1329  data: 0.1191  max mem: 10802
Epoch: [0]  [1520/4572]  eta: 0:06:45    time: 0.1326  data: 0.1186  max mem: 10802
Epoch: [0]  [1540/4572]  eta: 0:06:43    time: 0.1327  data: 0.1190  max mem: 10802
Epoch: [0]  [1560/4572]  eta: 0:06:40    time: 0.1326  data: 0.1216  max mem: 10802
Epoch: [0]  [1580/4572]  eta: 0:06:37    time: 0.1327  data: 0.1219  max mem: 10802
Epoch: [0]  [1600/4572]  eta: 0:06:35    time: 0.1326  data: 0.1186  max mem: 10802
Epoch: [0]  [1620/4572]  eta: 0:06:32    time: 0.1329  data: 0.1185  max mem: 10802
Epoch: [0]  [1640/4572]  eta: 0:06:29    time: 0.1327  data: 0.1186  max mem: 10802
Epoch: [0]  [1660/4572]  eta: 0:06:27    time: 0.1328  data: 0.1190  max mem: 10802
Epoch: [0]  [1680/4572]  eta: 0:06:24    time: 0.1331  data: 0.1189  max mem: 10802
Epoch: [0]  [1700/4572]  eta: 0:06:21    time: 0.1329  data: 0.1219  max mem: 10802
Epoch: [0]  [1720/4572]  eta: 0:06:19    time: 0.1327  data: 0.1192  max mem: 10802
Epoch: [0]  [1740/4572]  eta: 0:06:16    time: 0.1327  data: 0.1186  max mem: 10802
Epoch: [0]  [1760/4572]  eta: 0:06:13    time: 0.1325  data: 0.1188  max mem: 10802
Epoch: [0]  [1780/4572]  eta: 0:06:11    time: 0.1326  data: 0.1216  max mem: 10802
Epoch: [0]  [1800/4572]  eta: 0:06:08    time: 0.1325  data: 0.1188  max mem: 10802
Epoch: [0]  [1820/4572]  eta: 0:06:05    time: 0.1327  data: 0.1239  max mem: 10802
Epoch: [0]  [1840/4572]  eta: 0:06:03    time: 0.1326  data: 0.1188  max mem: 10802
Epoch: [0]  [1860/4572]  eta: 0:06:00    time: 0.1329  data: 0.1193  max mem: 10802
Epoch: [0]  [1880/4572]  eta: 0:05:57    time: 0.1328  data: 0.1220  max mem: 10802
Epoch: [0]  [1900/4572]  eta: 0:05:55    time: 0.1329  data: 0.1220  max mem: 10802
Epoch: [0]  [1920/4572]  eta: 0:05:52    time: 0.1328  data: 0.1241  max mem: 10802
Epoch: [0]  [1940/4572]  eta: 0:05:49    time: 0.1326  data: 0.1191  max mem: 10802
Epoch: [0]  [1960/4572]  eta: 0:05:47    time: 0.1326  data: 0.1186  max mem: 10802
Epoch: [0]  [1980/4572]  eta: 0:05:44    time: 0.1326  data: 0.1188  max mem: 10802
Epoch: [0]  [2000/4572]  eta: 0:05:41    time: 0.1325  data: 0.1189  max mem: 10802
Epoch: [0]  [2020/4572]  eta: 0:05:39    time: 0.1325  data: 0.1190  max mem: 10802
Epoch: [0]  [2040/4572]  eta: 0:05:36    time: 0.1326  data: 0.1218  max mem: 10802
Epoch: [0]  [2060/4572]  eta: 0:05:33    time: 0.1326  data: 0.1185  max mem: 10802
Epoch: [0]  [2080/4572]  eta: 0:05:31    time: 0.1327  data: 0.1186  max mem: 10802
Epoch: [0]  [2100/4572]  eta: 0:05:28    time: 0.1325  data: 0.1185  max mem: 10802
Epoch: [0]  [2120/4572]  eta: 0:05:25    time: 0.1327  data: 0.1218  max mem: 10802
Epoch: [0]  [2140/4572]  eta: 0:05:23    time: 0.1326  data: 0.1238  max mem: 10802
Epoch: [0]  [2160/4572]  eta: 0:05:20    time: 0.1327  data: 0.1190  max mem: 10802
Epoch: [0]  [2180/4572]  eta: 0:05:17    time: 0.1327  data: 0.1191  max mem: 10802
Epoch: [0]  [2200/4572]  eta: 0:05:15    time: 0.1326  data: 0.1187  max mem: 10802
Epoch: [0]  [2220/4572]  eta: 0:05:12    time: 0.1326  data: 0.1238  max mem: 10802
Epoch: [0]  [2240/4572]  eta: 0:05:09    time: 0.1327  data: 0.1187  max mem: 10802
Epoch: [0]  [2260/4572]  eta: 0:05:07    time: 0.1330  data: 0.1190  max mem: 10802
Epoch: [0]  [2280/4572]  eta: 0:05:04    time: 0.1326  data: 0.1184  max mem: 10802
Epoch: [0]  [2300/4572]  eta: 0:05:01    time: 0.1330  data: 0.1242  max mem: 10802
Epoch: [0]  [2320/4572]  eta: 0:04:59    time: 0.1328  data: 0.1188  max mem: 10802
Epoch: [0]  [2340/4572]  eta: 0:04:56    time: 0.1324  data: 0.1214  max mem: 10802
Epoch: [0]  [2360/4572]  eta: 0:04:53    time: 0.1331  data: 0.1193  max mem: 10802
Epoch: [0]  [2380/4572]  eta: 0:04:51    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [0]  [2400/4572]  eta: 0:04:48    time: 0.1330  data: 0.1189  max mem: 10802
Epoch: [0]  [2420/4572]  eta: 0:04:45    time: 0.1327  data: 0.1218  max mem: 10802
Epoch: [0]  [2440/4572]  eta: 0:04:43    time: 0.1326  data: 0.1216  max mem: 10802
Epoch: [0]  [2460/4572]  eta: 0:04:40    time: 0.1339  data: 0.1198  max mem: 10802
Epoch: [0]  [2480/4572]  eta: 0:04:38    time: 0.1341  data: 0.1204  max mem: 10802
Epoch: [0]  [2500/4572]  eta: 0:04:35    time: 0.1327  data: 0.1240  max mem: 10802
Epoch: [0]  [2520/4572]  eta: 0:04:32    time: 0.1325  data: 0.1216  max mem: 10802
Epoch: [0]  [2540/4572]  eta: 0:04:30    time: 0.1326  data: 0.1217  max mem: 10802
Epoch: [0]  [2560/4572]  eta: 0:04:27    time: 0.1330  data: 0.1188  max mem: 10802
Epoch: [0]  [2580/4572]  eta: 0:04:24    time: 0.1327  data: 0.1186  max mem: 10802
Epoch: [0]  [2600/4572]  eta: 0:04:22    time: 0.1325  data: 0.1238  max mem: 10802
Epoch: [0]  [2620/4572]  eta: 0:04:19    time: 0.1325  data: 0.1190  max mem: 10802
Epoch: [0]  [2640/4572]  eta: 0:04:16    time: 0.1328  data: 0.1217  max mem: 10802
Epoch: [0]  [2660/4572]  eta: 0:04:14    time: 0.1328  data: 0.1219  max mem: 10802
Epoch: [0]  [2680/4572]  eta: 0:04:11    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [0]  [2700/4572]  eta: 0:04:08    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [0]  [2720/4572]  eta: 0:04:06    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [0]  [2740/4572]  eta: 0:04:03    time: 0.1325  data: 0.1185  max mem: 10802
Epoch: [0]  [2760/4572]  eta: 0:04:00    time: 0.1327  data: 0.1240  max mem: 10802
Epoch: [0]  [2780/4572]  eta: 0:03:58    time: 0.1325  data: 0.1189  max mem: 10802
Epoch: [0]  [2800/4572]  eta: 0:03:55    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [0]  [2820/4572]  eta: 0:03:52    time: 0.1326  data: 0.1239  max mem: 10802
Epoch: [0]  [2840/4572]  eta: 0:03:50    time: 0.1327  data: 0.1185  max mem: 10802
Epoch: [0]  [2860/4572]  eta: 0:03:47    time: 0.1327  data: 0.1190  max mem: 10802
Epoch: [0]  [2880/4572]  eta: 0:03:44    time: 0.1325  data: 0.1188  max mem: 10802
Epoch: [0]  [2900/4572]  eta: 0:03:42    time: 0.1324  data: 0.1215  max mem: 10802
Epoch: [0]  [2920/4572]  eta: 0:03:39    time: 0.1325  data: 0.1185  max mem: 10802
Epoch: [0]  [2940/4572]  eta: 0:03:36    time: 0.1325  data: 0.1189  max mem: 10802
Epoch: [0]  [2960/4572]  eta: 0:03:34    time: 0.1327  data: 0.1187  max mem: 10802
Epoch: [0]  [2980/4572]  eta: 0:03:31    time: 0.1327  data: 0.1185  max mem: 10802
Epoch: [0]  [3000/4572]  eta: 0:03:28    time: 0.1326  data: 0.1189  max mem: 10802
Epoch: [0]  [3020/4572]  eta: 0:03:26    time: 0.1324  data: 0.1189  max mem: 10802
Epoch: [0]  [3040/4572]  eta: 0:03:23    time: 0.1326  data: 0.1185  max mem: 10802
Epoch: [0]  [3060/4572]  eta: 0:03:20    time: 0.1329  data: 0.1219  max mem: 10802
Epoch: [0]  [3080/4572]  eta: 0:03:18    time: 0.1326  data: 0.1219  max mem: 10802
Epoch: [0]  [3100/4572]  eta: 0:03:15    time: 0.1327  data: 0.1219  max mem: 10802
Epoch: [0]  [3120/4572]  eta: 0:03:12    time: 0.1327  data: 0.1190  max mem: 10802
Epoch: [0]  [3140/4572]  eta: 0:03:10    time: 0.1329  data: 0.1252  max mem: 10802
Epoch: [0]  [3160/4572]  eta: 0:03:07    time: 0.1328  data: 0.1193  max mem: 10802
Epoch: [0]  [3180/4572]  eta: 0:03:04    time: 0.1326  data: 0.1183  max mem: 10802
Epoch: [0]  [3200/4572]  eta: 0:03:02    time: 0.1326  data: 0.1217  max mem: 10802
Epoch: [0]  [3220/4572]  eta: 0:02:59    time: 0.1325  data: 0.1238  max mem: 10802
Epoch: [0]  [3240/4572]  eta: 0:02:56    time: 0.1325  data: 0.1189  max mem: 10802
Epoch: [0]  [3260/4572]  eta: 0:02:54    time: 0.1325  data: 0.1217  max mem: 10802
Epoch: [0]  [3280/4572]  eta: 0:02:51    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [0]  [3300/4572]  eta: 0:02:48    time: 0.1327  data: 0.1192  max mem: 10802
Epoch: [0]  [3320/4572]  eta: 0:02:46    time: 0.1325  data: 0.1189  max mem: 10802
Epoch: [0]  [3340/4572]  eta: 0:02:43    time: 0.1326  data: 0.1185  max mem: 10802
Epoch: [0]  [3360/4572]  eta: 0:02:40    time: 0.1337  data: 0.1201  max mem: 10802
Epoch: [0]  [3380/4572]  eta: 0:02:38    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [0]  [3400/4572]  eta: 0:02:35    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [0]  [3420/4572]  eta: 0:02:33    time: 0.1324  data: 0.1187  max mem: 10802
Epoch: [0]  [3440/4572]  eta: 0:02:30    time: 0.1326  data: 0.1217  max mem: 10802
Epoch: [0]  [3460/4572]  eta: 0:02:27    time: 0.1329  data: 0.1188  max mem: 10802
Epoch: [0]  [3480/4572]  eta: 0:02:25    time: 0.1328  data: 0.1219  max mem: 10802
Epoch: [0]  [3500/4572]  eta: 0:02:22    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [0]  [3520/4572]  eta: 0:02:19    time: 0.1324  data: 0.1237  max mem: 10802
Epoch: [0]  [3540/4572]  eta: 0:02:17    time: 0.1325  data: 0.1188  max mem: 10802
Epoch: [0]  [3560/4572]  eta: 0:02:14    time: 0.1326  data: 0.1236  max mem: 10802
Epoch: [0]  [3580/4572]  eta: 0:02:11    time: 0.1325  data: 0.1216  max mem: 10802
Epoch: [0]  [3600/4572]  eta: 0:02:09    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [0]  [3620/4572]  eta: 0:02:06    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [0]  [3640/4572]  eta: 0:02:03    time: 0.1327  data: 0.1186  max mem: 10802
Epoch: [0]  [3660/4572]  eta: 0:02:01    time: 0.1324  data: 0.1216  max mem: 10802
Epoch: [0]  [3680/4572]  eta: 0:01:58    time: 0.1325  data: 0.1189  max mem: 10802
Epoch: [0]  [3700/4572]  eta: 0:01:55    time: 0.1326  data: 0.1239  max mem: 10802
Epoch: [0]  [3720/4572]  eta: 0:01:53    time: 0.1324  data: 0.1187  max mem: 10802
Epoch: [0]  [3740/4572]  eta: 0:01:50    time: 0.1325  data: 0.1185  max mem: 10802
Epoch: [0]  [3760/4572]  eta: 0:01:47    time: 0.1325  data: 0.1188  max mem: 10802
Epoch: [0]  [3780/4572]  eta: 0:01:45    time: 0.1324  data: 0.1215  max mem: 10802
Epoch: [0]  [3800/4572]  eta: 0:01:42    time: 0.1326  data: 0.1184  max mem: 10802
Epoch: [0]  [3820/4572]  eta: 0:01:39    time: 0.1325  data: 0.1187  max mem: 10802
Epoch: [0]  [3840/4572]  eta: 0:01:37    time: 0.1327  data: 0.1184  max mem: 10802
Epoch: [0]  [3860/4572]  eta: 0:01:34    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [0]  [3880/4572]  eta: 0:01:31    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [0]  [3900/4572]  eta: 0:01:29    time: 0.1327  data: 0.1189  max mem: 10802
Epoch: [0]  [3920/4572]  eta: 0:01:26    time: 0.1326  data: 0.1184  max mem: 10802
Epoch: [0]  [3940/4572]  eta: 0:01:23    time: 0.1324  data: 0.1187  max mem: 10802
Epoch: [0]  [3960/4572]  eta: 0:01:21    time: 0.1325  data: 0.1188  max mem: 10802
Epoch: [0]  [3980/4572]  eta: 0:01:18    time: 0.1327  data: 0.1187  max mem: 10802
Epoch: [0]  [4000/4572]  eta: 0:01:15    time: 0.1326  data: 0.1185  max mem: 10802
Epoch: [0]  [4020/4572]  eta: 0:01:13    time: 0.1328  data: 0.1220  max mem: 10802
Epoch: [0]  [4040/4572]  eta: 0:01:10    time: 0.1325  data: 0.1185  max mem: 10802
Epoch: [0]  [4060/4572]  eta: 0:01:07    time: 0.1324  data: 0.1216  max mem: 10802
Epoch: [0]  [4080/4572]  eta: 0:01:05    time: 0.1324  data: 0.1187  max mem: 10802
Epoch: [0]  [4100/4572]  eta: 0:01:02    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [0]  [4120/4572]  eta: 0:01:00    time: 0.1326  data: 0.1185  max mem: 10802
Epoch: [0]  [4140/4572]  eta: 0:00:57    time: 0.1326  data: 0.1184  max mem: 10802
Epoch: [0]  [4160/4572]  eta: 0:00:54    time: 0.1326  data: 0.1185  max mem: 10802
Epoch: [0]  [4180/4572]  eta: 0:00:52    time: 0.1324  data: 0.1237  max mem: 10802
Epoch: [0]  [4200/4572]  eta: 0:00:49    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [0]  [4220/4572]  eta: 0:00:46    time: 0.1324  data: 0.1187  max mem: 10802
Epoch: [0]  [4240/4572]  eta: 0:00:44    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [0]  [4260/4572]  eta: 0:00:41    time: 0.1326  data: 0.1184  max mem: 10802
Epoch: [0]  [4280/4572]  eta: 0:00:38    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [0]  [4300/4572]  eta: 0:00:36    time: 0.1325  data: 0.1217  max mem: 10802
Epoch: [0]  [4320/4572]  eta: 0:00:33    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [0]  [4340/4572]  eta: 0:00:30    time: 0.1326  data: 0.1189  max mem: 10802
Epoch: [0]  [4360/4572]  eta: 0:00:28    time: 0.1327  data: 0.1191  max mem: 10802
Epoch: [0]  [4380/4572]  eta: 0:00:25    time: 0.1324  data: 0.1215  max mem: 10802
Epoch: [0]  [4400/4572]  eta: 0:00:22    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [0]  [4420/4572]  eta: 0:00:20    time: 0.1324  data: 0.1216  max mem: 10802
Epoch: [0]  [4440/4572]  eta: 0:00:17    time: 0.1325  data: 0.1187  max mem: 10802
Epoch: [0]  [4460/4572]  eta: 0:00:14    time: 0.1325  data: 0.1189  max mem: 10802
Epoch: [0]  [4480/4572]  eta: 0:00:12    time: 0.1326  data: 0.1184  max mem: 10802
Epoch: [0]  [4500/4572]  eta: 0:00:09    time: 0.1327  data: 0.1185  max mem: 10802
Epoch: [0]  [4520/4572]  eta: 0:00:06    time: 0.1323  data: 0.1183  max mem: 10802
Epoch: [0]  [4540/4572]  eta: 0:00:04    time: 0.1326  data: 0.1216  max mem: 10802
Epoch: [0]  [4560/4572]  eta: 0:00:01    time: 0.1327  data: 0.1185  max mem: 10802
Epoch: [0]  [4571/4572]  eta: 0:00:00    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [0] Total time: 0:10:06 (0.1328 s / it)
:::MLLOG {"namespace": "", "time_ms": 1684351252980, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 332, "epoch_num": 0}}
:::MLLOG {"namespace": "", "time_ms": 1684351252980, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 120.53406821998877}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 336, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1684351252981, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 346, "epoch_num": 1}}
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [ 0/97]  eta: 0:00:22  model_time: 0.2287 (0.2287)  evaluator_time: 0.0019 (0.0019)  time: 0.2309  data: 0.0003  max mem: 10802
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [20/97]  eta: 0:00:14  model_time: 0.1790 (0.1798)  evaluator_time: 0.0021 (0.0020)  time: 0.1801  data: 0.0006  max mem: 10802
Test:  [40/97]  eta: 0:00:10  model_time: 0.1761 (0.1779)  evaluator_time: 0.0021 (0.0021)  time: 0.1788  data: 0.0006  max mem: 10802
Test:  [60/97]  eta: 0:00:06  model_time: 0.1811 (0.1786)  evaluator_time: 0.0021 (0.0021)  time: 0.1827  data: 0.0006  max mem: 10802
Test:  [80/97]  eta: 0:00:03  model_time: 0.1773 (0.1780)  evaluator_time: 0.0022 (0.0021)  time: 0.1792  data: 0.0006  max mem: 10802
Test:  [96/97]  eta: 0:00:00  model_time: 0.1773 (0.1777)  evaluator_time: 0.0019 (0.0021)  time: 0.1795  data: 0.0006  max mem: 10802
Test: Total time: 0:00:17 (0.1806 s / it)
Averaged stats: model_time: 0.1773 (0.1809)  evaluator_time: 0.0019 (0.0021)
:::MLLOG {"namespace": "", "time_ms": 1684351271546, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 161, "epoch_num": 1}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [1]  [   0/4571]  eta: 0:10:02    time: 0.1318  data: 0.0016  max mem: 10802
Epoch: [1]  [  20/4571]  eta: 0:10:00    time: 0.1321  data: 0.1182  max mem: 10802
Epoch: [1]  [  40/4571]  eta: 0:09:59    time: 0.1324  data: 0.1187  max mem: 10802
Epoch: [1]  [  60/4571]  eta: 0:09:56    time: 0.1321  data: 0.1178  max mem: 10802
:::MLLOG {"namespace": "", "time_ms": 1684351279863, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.24147926694895994, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 432, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1684351279863, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 433, "epoch_num": 1}}
Epoch: [1]  [  80/4571]  eta: 0:09:53    time: 0.1324  data: 0.1185  max mem: 10802
Epoch: [1]  [ 100/4571]  eta: 0:09:51    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [1]  [ 120/4571]  eta: 0:09:48    time: 0.1322  data: 0.1231  max mem: 10802
Epoch: [1]  [ 140/4571]  eta: 0:09:45    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [1]  [ 160/4571]  eta: 0:09:43    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [ 180/4571]  eta: 0:09:40    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [ 200/4571]  eta: 0:09:38    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [1]  [ 220/4571]  eta: 0:09:35    time: 0.1324  data: 0.1216  max mem: 10802
Epoch: [1]  [ 240/4571]  eta: 0:09:32    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [1]  [ 260/4571]  eta: 0:09:30    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [ 280/4571]  eta: 0:09:27    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [1]  [ 300/4571]  eta: 0:09:25    time: 0.1324  data: 0.1237  max mem: 10802
Epoch: [1]  [ 320/4571]  eta: 0:09:22    time: 0.1326  data: 0.1217  max mem: 10802
Epoch: [1]  [ 340/4571]  eta: 0:09:19    time: 0.1324  data: 0.1214  max mem: 10802
Epoch: [1]  [ 360/4571]  eta: 0:09:17    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [1]  [ 380/4571]  eta: 0:09:14    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [ 400/4571]  eta: 0:09:11    time: 0.1324  data: 0.1189  max mem: 10802
Epoch: [1]  [ 420/4571]  eta: 0:09:09    time: 0.1323  data: 0.1184  max mem: 10802
Epoch: [1]  [ 440/4571]  eta: 0:09:06    time: 0.1325  data: 0.1189  max mem: 10802
Epoch: [1]  [ 460/4571]  eta: 0:09:04    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1]  [ 480/4571]  eta: 0:09:01    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [1]  [ 500/4571]  eta: 0:08:58    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [1]  [ 520/4571]  eta: 0:08:56    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [1]  [ 540/4571]  eta: 0:08:53    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [ 560/4571]  eta: 0:08:50    time: 0.1325  data: 0.1188  max mem: 10802
Epoch: [1]  [ 580/4571]  eta: 0:08:48    time: 0.1326  data: 0.1184  max mem: 10802
Epoch: [1]  [ 600/4571]  eta: 0:08:45    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1]  [ 620/4571]  eta: 0:08:42    time: 0.1326  data: 0.1182  max mem: 10802
Epoch: [1]  [ 640/4571]  eta: 0:08:40    time: 0.1323  data: 0.1184  max mem: 10802
Epoch: [1]  [ 660/4571]  eta: 0:08:37    time: 0.1323  data: 0.1188  max mem: 10802
Epoch: [1]  [ 680/4571]  eta: 0:08:35    time: 0.1324  data: 0.1213  max mem: 10802
Epoch: [1]  [ 700/4571]  eta: 0:08:32    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [ 720/4571]  eta: 0:08:29    time: 0.1324  data: 0.1236  max mem: 10802
Epoch: [1]  [ 740/4571]  eta: 0:08:27    time: 0.1324  data: 0.1185  max mem: 10802
Epoch: [1]  [ 760/4571]  eta: 0:08:24    time: 0.1325  data: 0.1187  max mem: 10802
Epoch: [1]  [ 780/4571]  eta: 0:08:21    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [1]  [ 800/4571]  eta: 0:08:19    time: 0.1324  data: 0.1213  max mem: 10802
Epoch: [1]  [ 820/4571]  eta: 0:08:16    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [ 840/4571]  eta: 0:08:13    time: 0.1325  data: 0.1185  max mem: 10802
Epoch: [1]  [ 860/4571]  eta: 0:08:11    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [ 880/4571]  eta: 0:08:08    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [1]  [ 900/4571]  eta: 0:08:05    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [1]  [ 920/4571]  eta: 0:08:03    time: 0.1323  data: 0.1215  max mem: 10802
Epoch: [1]  [ 940/4571]  eta: 0:08:00    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [1]  [ 960/4571]  eta: 0:07:57    time: 0.1325  data: 0.1233  max mem: 10802
Epoch: [1]  [ 980/4571]  eta: 0:07:55    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [1]  [1000/4571]  eta: 0:07:52    time: 0.1326  data: 0.1189  max mem: 10802
Epoch: [1]  [1020/4571]  eta: 0:07:50    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [1]  [1040/4571]  eta: 0:07:47    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [1]  [1060/4571]  eta: 0:07:44    time: 0.1327  data: 0.1219  max mem: 10802
Epoch: [1]  [1080/4571]  eta: 0:07:42    time: 0.1325  data: 0.1216  max mem: 10802
Epoch: [1]  [1100/4571]  eta: 0:07:39    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [1120/4571]  eta: 0:07:36    time: 0.1324  data: 0.1181  max mem: 10802
Epoch: [1]  [1140/4571]  eta: 0:07:34    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1]  [1160/4571]  eta: 0:07:31    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1]  [1180/4571]  eta: 0:07:28    time: 0.1324  data: 0.1187  max mem: 10802
Epoch: [1]  [1200/4571]  eta: 0:07:26    time: 0.1327  data: 0.1240  max mem: 10802
Epoch: [1]  [1220/4571]  eta: 0:07:23    time: 0.1325  data: 0.1186  max mem: 10802
Epoch: [1]  [1240/4571]  eta: 0:07:20    time: 0.1323  data: 0.1213  max mem: 10802
Epoch: [1]  [1260/4571]  eta: 0:07:18    time: 0.1325  data: 0.1189  max mem: 10802
Epoch: [1]  [1280/4571]  eta: 0:07:15    time: 0.1325  data: 0.1189  max mem: 10802
Epoch: [1]  [1300/4571]  eta: 0:07:13    time: 0.1324  data: 0.1214  max mem: 10802
Epoch: [1]  [1320/4571]  eta: 0:07:10    time: 0.1324  data: 0.1188  max mem: 10802
Epoch: [1]  [1340/4571]  eta: 0:07:07    time: 0.1324  data: 0.1186  max mem: 10802
Epoch: [1]  [1360/4571]  eta: 0:07:05    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [1380/4571]  eta: 0:07:02    time: 0.1323  data: 0.1236  max mem: 10802
Epoch: [1]  [1400/4571]  eta: 0:06:59    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [1]  [1420/4571]  eta: 0:06:57    time: 0.1325  data: 0.1237  max mem: 10802
Epoch: [1]  [1440/4571]  eta: 0:06:54    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [1]  [1460/4571]  eta: 0:06:51    time: 0.1333  data: 0.1192  max mem: 10802
Epoch: [1]  [1480/4571]  eta: 0:06:49    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [1]  [1500/4571]  eta: 0:06:46    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [1]  [1520/4571]  eta: 0:06:43    time: 0.1324  data: 0.1187  max mem: 10802
Epoch: [1]  [1540/4571]  eta: 0:06:41    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [1]  [1560/4571]  eta: 0:06:38    time: 0.1326  data: 0.1188  max mem: 10802
Epoch: [1]  [1580/4571]  eta: 0:06:36    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [1]  [1600/4571]  eta: 0:06:33    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [1620/4571]  eta: 0:06:30    time: 0.1324  data: 0.1188  max mem: 10802
Epoch: [1]  [1640/4571]  eta: 0:06:28    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [1]  [1660/4571]  eta: 0:06:25    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [1680/4571]  eta: 0:06:22    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1]  [1700/4571]  eta: 0:06:20    time: 0.1326  data: 0.1238  max mem: 10802
Epoch: [1]  [1720/4571]  eta: 0:06:17    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [1]  [1740/4571]  eta: 0:06:14    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [1760/4571]  eta: 0:06:12    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [1]  [1780/4571]  eta: 0:06:09    time: 0.1324  data: 0.1187  max mem: 10802
Epoch: [1]  [1800/4571]  eta: 0:06:06    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1]  [1820/4571]  eta: 0:06:04    time: 0.1324  data: 0.1214  max mem: 10802
Epoch: [1]  [1840/4571]  eta: 0:06:01    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1]  [1860/4571]  eta: 0:05:58    time: 0.1327  data: 0.1189  max mem: 10802
Epoch: [1]  [1880/4571]  eta: 0:05:56    time: 0.1325  data: 0.1181  max mem: 10802
Epoch: [1]  [1900/4571]  eta: 0:05:53    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1]  [1920/4571]  eta: 0:05:50    time: 0.1326  data: 0.1234  max mem: 10802
Epoch: [1]  [1940/4571]  eta: 0:05:48    time: 0.1325  data: 0.1188  max mem: 10802
Epoch: [1]  [1960/4571]  eta: 0:05:45    time: 0.1324  data: 0.1188  max mem: 10802
Epoch: [1]  [1980/4571]  eta: 0:05:43    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [2000/4571]  eta: 0:05:40    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [2020/4571]  eta: 0:05:37    time: 0.1321  data: 0.1234  max mem: 10802
Epoch: [1]  [2040/4571]  eta: 0:05:35    time: 0.1324  data: 0.1190  max mem: 10802
Epoch: [1]  [2060/4571]  eta: 0:05:32    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [1]  [2080/4571]  eta: 0:05:29    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [2100/4571]  eta: 0:05:27    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [2120/4571]  eta: 0:05:24    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [2140/4571]  eta: 0:05:21    time: 0.1323  data: 0.1215  max mem: 10802
Epoch: [1]  [2160/4571]  eta: 0:05:19    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [1]  [2180/4571]  eta: 0:05:16    time: 0.1340  data: 0.1199  max mem: 10802
Epoch: [1]  [2200/4571]  eta: 0:05:13    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [2220/4571]  eta: 0:05:11    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [2240/4571]  eta: 0:05:08    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [2260/4571]  eta: 0:05:05    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [2280/4571]  eta: 0:05:03    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [1]  [2300/4571]  eta: 0:05:00    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [2320/4571]  eta: 0:04:58    time: 0.1324  data: 0.1217  max mem: 10802
Epoch: [1]  [2340/4571]  eta: 0:04:55    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1]  [2360/4571]  eta: 0:04:52    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [1]  [2380/4571]  eta: 0:04:50    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [1]  [2400/4571]  eta: 0:04:47    time: 0.1324  data: 0.1233  max mem: 10802
Epoch: [1]  [2420/4571]  eta: 0:04:44    time: 0.1324  data: 0.1214  max mem: 10802
Epoch: [1]  [2440/4571]  eta: 0:04:42    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [1]  [2460/4571]  eta: 0:04:39    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [1]  [2480/4571]  eta: 0:04:36    time: 0.1326  data: 0.1189  max mem: 10802
Epoch: [1]  [2500/4571]  eta: 0:04:34    time: 0.1325  data: 0.1185  max mem: 10802
Epoch: [1]  [2520/4571]  eta: 0:04:31    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [1]  [2540/4571]  eta: 0:04:28    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [2560/4571]  eta: 0:04:26    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [1]  [2580/4571]  eta: 0:04:23    time: 0.1324  data: 0.1181  max mem: 10802
Epoch: [1]  [2600/4571]  eta: 0:04:20    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [2620/4571]  eta: 0:04:18    time: 0.1323  data: 0.1185  max mem: 10802
Epoch: [1]  [2640/4571]  eta: 0:04:15    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [2660/4571]  eta: 0:04:12    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [1]  [2680/4571]  eta: 0:04:10    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [1]  [2700/4571]  eta: 0:04:07    time: 0.1322  data: 0.1234  max mem: 10802
Epoch: [1]  [2720/4571]  eta: 0:04:05    time: 0.1335  data: 0.1248  max mem: 10802
Epoch: [1]  [2740/4571]  eta: 0:04:02    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [1]  [2760/4571]  eta: 0:03:59    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [1]  [2780/4571]  eta: 0:03:57    time: 0.1324  data: 0.1188  max mem: 10802
Epoch: [1]  [2800/4571]  eta: 0:03:54    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [2820/4571]  eta: 0:03:51    time: 0.1322  data: 0.1183  max mem: 10802
Epoch: [1]  [2840/4571]  eta: 0:03:49    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [1]  [2860/4571]  eta: 0:03:46    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [2880/4571]  eta: 0:03:43    time: 0.1323  data: 0.1215  max mem: 10802
Epoch: [1]  [2900/4571]  eta: 0:03:41    time: 0.1323  data: 0.1183  max mem: 10802
Epoch: [1]  [2920/4571]  eta: 0:03:38    time: 0.1335  data: 0.1199  max mem: 10802
Epoch: [1]  [2940/4571]  eta: 0:03:35    time: 0.1325  data: 0.1216  max mem: 10802
Epoch: [1]  [2960/4571]  eta: 0:03:33    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1]  [2980/4571]  eta: 0:03:30    time: 0.1323  data: 0.1213  max mem: 10802
Epoch: [1]  [3000/4571]  eta: 0:03:28    time: 0.1328  data: 0.1191  max mem: 10802
Epoch: [1]  [3020/4571]  eta: 0:03:25    time: 0.1326  data: 0.1238  max mem: 10802
Epoch: [1]  [3040/4571]  eta: 0:03:22    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [3060/4571]  eta: 0:03:20    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [3080/4571]  eta: 0:03:17    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [3100/4571]  eta: 0:03:14    time: 0.1323  data: 0.1185  max mem: 10802
Epoch: [1]  [3120/4571]  eta: 0:03:12    time: 0.1321  data: 0.1233  max mem: 10802
Epoch: [1]  [3140/4571]  eta: 0:03:09    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [3160/4571]  eta: 0:03:06    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [1]  [3180/4571]  eta: 0:03:04    time: 0.1323  data: 0.1236  max mem: 10802
Epoch: [1]  [3200/4571]  eta: 0:03:01    time: 0.1325  data: 0.1188  max mem: 10802
Epoch: [1]  [3220/4571]  eta: 0:02:58    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [3240/4571]  eta: 0:02:56    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [3260/4571]  eta: 0:02:53    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [1]  [3280/4571]  eta: 0:02:50    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [1]  [3300/4571]  eta: 0:02:48    time: 0.1325  data: 0.1187  max mem: 10802
Epoch: [1]  [3320/4571]  eta: 0:02:45    time: 0.1323  data: 0.1185  max mem: 10802
Epoch: [1]  [3340/4571]  eta: 0:02:42    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [1]  [3360/4571]  eta: 0:02:40    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [1]  [3380/4571]  eta: 0:02:37    time: 0.1325  data: 0.1216  max mem: 10802
Epoch: [1]  [3400/4571]  eta: 0:02:35    time: 0.1321  data: 0.1182  max mem: 10802
Epoch: [1]  [3420/4571]  eta: 0:02:32    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [1]  [3440/4571]  eta: 0:02:29    time: 0.1324  data: 0.1181  max mem: 10802
Epoch: [1]  [3460/4571]  eta: 0:02:27    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [1]  [3480/4571]  eta: 0:02:24    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [1]  [3500/4571]  eta: 0:02:21    time: 0.1322  data: 0.1231  max mem: 10802
Epoch: [1]  [3520/4571]  eta: 0:02:19    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [1]  [3540/4571]  eta: 0:02:16    time: 0.1323  data: 0.1215  max mem: 10802
Epoch: [1]  [3560/4571]  eta: 0:02:13    time: 0.1324  data: 0.1215  max mem: 10802
Epoch: [1]  [3580/4571]  eta: 0:02:11    time: 0.1340  data: 0.1253  max mem: 10802
Epoch: [1]  [3600/4571]  eta: 0:02:08    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [3620/4571]  eta: 0:02:05    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [1]  [3640/4571]  eta: 0:02:03    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [1]  [3660/4571]  eta: 0:02:00    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [3680/4571]  eta: 0:01:57    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [3700/4571]  eta: 0:01:55    time: 0.1323  data: 0.1231  max mem: 10802
Epoch: [1]  [3720/4571]  eta: 0:01:52    time: 0.1323  data: 0.1180  max mem: 10802
Epoch: [1]  [3740/4571]  eta: 0:01:50    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [3760/4571]  eta: 0:01:47    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [1]  [3780/4571]  eta: 0:01:44    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [3800/4571]  eta: 0:01:42    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [3820/4571]  eta: 0:01:39    time: 0.1321  data: 0.1182  max mem: 10802
Epoch: [1]  [3840/4571]  eta: 0:01:36    time: 0.1320  data: 0.1186  max mem: 10802
Epoch: [1]  [3860/4571]  eta: 0:01:34    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [1]  [3880/4571]  eta: 0:01:31    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [1]  [3900/4571]  eta: 0:01:28    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [1]  [3920/4571]  eta: 0:01:26    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [3940/4571]  eta: 0:01:23    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [1]  [3960/4571]  eta: 0:01:20    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [1]  [3980/4571]  eta: 0:01:18    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [1]  [4000/4571]  eta: 0:01:15    time: 0.1321  data: 0.1183  max mem: 10802
Epoch: [1]  [4020/4571]  eta: 0:01:12    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [1]  [4040/4571]  eta: 0:01:10    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [1]  [4060/4571]  eta: 0:01:07    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [4080/4571]  eta: 0:01:04    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [1]  [4100/4571]  eta: 0:01:02    time: 0.1323  data: 0.1234  max mem: 10802
Epoch: [1]  [4120/4571]  eta: 0:00:59    time: 0.1325  data: 0.1237  max mem: 10802
Epoch: [1]  [4140/4571]  eta: 0:00:57    time: 0.1322  data: 0.1187  max mem: 10802
Epoch: [1]  [4160/4571]  eta: 0:00:54    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [1]  [4180/4571]  eta: 0:00:51    time: 0.1322  data: 0.1187  max mem: 10802
Epoch: [1]  [4200/4571]  eta: 0:00:49    time: 0.1321  data: 0.1234  max mem: 10802
Epoch: [1]  [4220/4571]  eta: 0:00:46    time: 0.1324  data: 0.1187  max mem: 10802
Epoch: [1]  [4240/4571]  eta: 0:00:43    time: 0.1324  data: 0.1214  max mem: 10802
Epoch: [1]  [4260/4571]  eta: 0:00:41    time: 0.1322  data: 0.1214  max mem: 10802
Epoch: [1]  [4280/4571]  eta: 0:00:38    time: 0.1325  data: 0.1188  max mem: 10802
Epoch: [1]  [4300/4571]  eta: 0:00:35    time: 0.1323  data: 0.1185  max mem: 10802
Epoch: [1]  [4320/4571]  eta: 0:00:33    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [1]  [4340/4571]  eta: 0:00:30    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [1]  [4360/4571]  eta: 0:00:27    time: 0.1324  data: 0.1234  max mem: 10802
Epoch: [1]  [4380/4571]  eta: 0:00:25    time: 0.1323  data: 0.1185  max mem: 10802
Epoch: [1]  [4400/4571]  eta: 0:00:22    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [4420/4571]  eta: 0:00:19    time: 0.1324  data: 0.1187  max mem: 10802
Epoch: [1]  [4440/4571]  eta: 0:00:17    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [4460/4571]  eta: 0:00:14    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [4480/4571]  eta: 0:00:12    time: 0.1324  data: 0.1215  max mem: 10802
Epoch: [1]  [4500/4571]  eta: 0:00:09    time: 0.1323  data: 0.1185  max mem: 10802
Epoch: [1]  [4520/4571]  eta: 0:00:06    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [1]  [4540/4571]  eta: 0:00:04    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [1]  [4560/4571]  eta: 0:00:01    time: 0.1326  data: 0.1184  max mem: 10802
Epoch: [1]  [4570/4571]  eta: 0:00:00    time: 0.1352  data: 0.1210  max mem: 10802
Epoch: [1] Total time: 0:10:05 (0.1323 s / it)
:::MLLOG {"namespace": "", "time_ms": 1684351876746, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 332, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1684351876746, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 120.88534521330463}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 336, "step": 2}}
:::MLLOG {"namespace": "", "time_ms": 1684351876747, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 346, "epoch_num": 2}}
Test:  [ 0/97]  eta: 0:00:17  model_time: 0.1741 (0.1741)  evaluator_time: 0.0020 (0.0020)  time: 0.1769  data: 0.0007  max mem: 10802
Test:  [20/97]  eta: 0:00:13  model_time: 0.1693 (0.1722)  evaluator_time: 0.0021 (0.0048)  time: 0.1777  data: 0.0006  max mem: 10802
Test:  [40/97]  eta: 0:00:10  model_time: 0.1709 (0.1716)  evaluator_time: 0.0021 (0.0035)  time: 0.1737  data: 0.0006  max mem: 10802
Test:  [60/97]  eta: 0:00:06  model_time: 0.1758 (0.1717)  evaluator_time: 0.0020 (0.0030)  time: 0.1746  data: 0.0006  max mem: 10802
Test:  [80/97]  eta: 0:00:02  model_time: 0.1725 (0.1717)  evaluator_time: 0.0020 (0.0027)  time: 0.1747  data: 0.0006  max mem: 10802
Test:  [96/97]  eta: 0:00:00  model_time: 0.1752 (0.1717)  evaluator_time: 0.0019 (0.0026)  time: 0.1747  data: 0.0006  max mem: 10802
Test: Total time: 0:00:16 (0.1751 s / it)
Averaged stats: model_time: 0.1752 (0.1737)  evaluator_time: 0.0019 (0.0025)
:::MLLOG {"namespace": "", "time_ms": 1684351894505, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 161, "epoch_num": 2}}
Epoch: [2]  [   0/4572]  eta: 0:09:59    time: 0.1312  data: 0.0008  max mem: 10802
Epoch: [2]  [  20/4572]  eta: 0:09:59    time: 0.1318  data: 0.1209  max mem: 10802
:::MLLOG {"namespace": "", "time_ms": 1684351899661, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.30521159152142197, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 432, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1684351899661, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 433, "epoch_num": 2}}
Epoch: [2]  [  40/4572]  eta: 0:09:57    time: 0.1320  data: 0.1183  max mem: 10802
Epoch: [2]  [  60/4572]  eta: 0:09:55    time: 0.1320  data: 0.1178  max mem: 10802
Epoch: [2]  [  80/4572]  eta: 0:09:52    time: 0.1321  data: 0.1234  max mem: 10802
Epoch: [2]  [ 100/4572]  eta: 0:09:50    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [2]  [ 120/4572]  eta: 0:09:47    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [2]  [ 140/4572]  eta: 0:09:45    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [ 160/4572]  eta: 0:09:42    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [2]  [ 180/4572]  eta: 0:09:39    time: 0.1320  data: 0.1180  max mem: 10802
Epoch: [2]  [ 200/4572]  eta: 0:09:37    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [2]  [ 220/4572]  eta: 0:09:34    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [ 240/4572]  eta: 0:09:32    time: 0.1325  data: 0.1188  max mem: 10802
Epoch: [2]  [ 260/4572]  eta: 0:09:29    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [ 280/4572]  eta: 0:09:27    time: 0.1322  data: 0.1187  max mem: 10802
Epoch: [2]  [ 300/4572]  eta: 0:09:24    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [2]  [ 320/4572]  eta: 0:09:21    time: 0.1322  data: 0.1187  max mem: 10802
Epoch: [2]  [ 340/4572]  eta: 0:09:19    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [ 360/4572]  eta: 0:09:16    time: 0.1322  data: 0.1212  max mem: 10802
Epoch: [2]  [ 380/4572]  eta: 0:09:13    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [2]  [ 400/4572]  eta: 0:09:11    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [2]  [ 420/4572]  eta: 0:09:08    time: 0.1322  data: 0.1236  max mem: 10802
Epoch: [2]  [ 440/4572]  eta: 0:09:06    time: 0.1324  data: 0.1184  max mem: 10802
Epoch: [2]  [ 460/4572]  eta: 0:09:03    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [2]  [ 480/4572]  eta: 0:09:00    time: 0.1323  data: 0.1188  max mem: 10802
Epoch: [2]  [ 500/4572]  eta: 0:08:58    time: 0.1326  data: 0.1192  max mem: 10802
Epoch: [2]  [ 520/4572]  eta: 0:08:55    time: 0.1324  data: 0.1217  max mem: 10802
Epoch: [2]  [ 540/4572]  eta: 0:08:53    time: 0.1323  data: 0.1215  max mem: 10802
Epoch: [2]  [ 560/4572]  eta: 0:08:50    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [ 580/4572]  eta: 0:08:47    time: 0.1321  data: 0.1213  max mem: 10802
Epoch: [2]  [ 600/4572]  eta: 0:08:45    time: 0.1324  data: 0.1185  max mem: 10802
Epoch: [2]  [ 620/4572]  eta: 0:08:42    time: 0.1323  data: 0.1235  max mem: 10802
Epoch: [2]  [ 640/4572]  eta: 0:08:39    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [ 660/4572]  eta: 0:08:37    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [2]  [ 680/4572]  eta: 0:08:34    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [ 700/4572]  eta: 0:08:31    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [ 720/4572]  eta: 0:08:29    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [2]  [ 740/4572]  eta: 0:08:26    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [2]  [ 760/4572]  eta: 0:08:23    time: 0.1322  data: 0.1182  max mem: 10802
Epoch: [2]  [ 780/4572]  eta: 0:08:21    time: 0.1323  data: 0.1237  max mem: 10802
Epoch: [2]  [ 800/4572]  eta: 0:08:18    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [2]  [ 820/4572]  eta: 0:08:16    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [2]  [ 840/4572]  eta: 0:08:13    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [ 860/4572]  eta: 0:08:10    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [ 880/4572]  eta: 0:08:08    time: 0.1322  data: 0.1187  max mem: 10802
Epoch: [2]  [ 900/4572]  eta: 0:08:05    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [2]  [ 920/4572]  eta: 0:08:02    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [2]  [ 940/4572]  eta: 0:08:00    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [ 960/4572]  eta: 0:07:57    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [2]  [ 980/4572]  eta: 0:07:54    time: 0.1324  data: 0.1215  max mem: 10802
Epoch: [2]  [1000/4572]  eta: 0:07:52    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [1020/4572]  eta: 0:07:49    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [2]  [1040/4572]  eta: 0:07:47    time: 0.1321  data: 0.1235  max mem: 10802
Epoch: [2]  [1060/4572]  eta: 0:07:44    time: 0.1325  data: 0.1215  max mem: 10802
Epoch: [2]  [1080/4572]  eta: 0:07:41    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [1100/4572]  eta: 0:07:39    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [2]  [1120/4572]  eta: 0:07:36    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [2]  [1140/4572]  eta: 0:07:33    time: 0.1323  data: 0.1189  max mem: 10802
Epoch: [2]  [1160/4572]  eta: 0:07:31    time: 0.1322  data: 0.1182  max mem: 10802
Epoch: [2]  [1180/4572]  eta: 0:07:28    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [2]  [1200/4572]  eta: 0:07:25    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [2]  [1220/4572]  eta: 0:07:23    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [2]  [1240/4572]  eta: 0:07:20    time: 0.1323  data: 0.1185  max mem: 10802
Epoch: [2]  [1260/4572]  eta: 0:07:17    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [2]  [1280/4572]  eta: 0:07:15    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [2]  [1300/4572]  eta: 0:07:12    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [1320/4572]  eta: 0:07:10    time: 0.1325  data: 0.1238  max mem: 10802
Epoch: [2]  [1340/4572]  eta: 0:07:07    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [1360/4572]  eta: 0:07:04    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [1380/4572]  eta: 0:07:02    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [1400/4572]  eta: 0:06:59    time: 0.1322  data: 0.1234  max mem: 10802
Epoch: [2]  [1420/4572]  eta: 0:06:56    time: 0.1323  data: 0.1184  max mem: 10802
Epoch: [2]  [1440/4572]  eta: 0:06:54    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [2]  [1460/4572]  eta: 0:06:51    time: 0.1326  data: 0.1217  max mem: 10802
Epoch: [2]  [1480/4572]  eta: 0:06:48    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [1500/4572]  eta: 0:06:46    time: 0.1322  data: 0.1182  max mem: 10802
Epoch: [2]  [1520/4572]  eta: 0:06:43    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [2]  [1540/4572]  eta: 0:06:40    time: 0.1322  data: 0.1212  max mem: 10802
Epoch: [2]  [1560/4572]  eta: 0:06:38    time: 0.1325  data: 0.1186  max mem: 10802
Epoch: [2]  [1580/4572]  eta: 0:06:35    time: 0.1322  data: 0.1182  max mem: 10802
Epoch: [2]  [1600/4572]  eta: 0:06:33    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [2]  [1620/4572]  eta: 0:06:30    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [2]  [1640/4572]  eta: 0:06:27    time: 0.1323  data: 0.1236  max mem: 10802
Epoch: [2]  [1660/4572]  eta: 0:06:25    time: 0.1322  data: 0.1236  max mem: 10802
Epoch: [2]  [1680/4572]  eta: 0:06:22    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [2]  [1700/4572]  eta: 0:06:19    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [2]  [1720/4572]  eta: 0:06:17    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [2]  [1740/4572]  eta: 0:06:14    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [1760/4572]  eta: 0:06:11    time: 0.1322  data: 0.1231  max mem: 10802
Epoch: [2]  [1780/4572]  eta: 0:06:09    time: 0.1322  data: 0.1214  max mem: 10802
Epoch: [2]  [1800/4572]  eta: 0:06:06    time: 0.1324  data: 0.1216  max mem: 10802
Epoch: [2]  [1820/4572]  eta: 0:06:03    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [1840/4572]  eta: 0:06:01    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [2]  [1860/4572]  eta: 0:05:58    time: 0.1321  data: 0.1231  max mem: 10802
Epoch: [2]  [1880/4572]  eta: 0:05:55    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [2]  [1900/4572]  eta: 0:05:53    time: 0.1322  data: 0.1234  max mem: 10802
Epoch: [2]  [1920/4572]  eta: 0:05:50    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [2]  [1940/4572]  eta: 0:05:48    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [2]  [1960/4572]  eta: 0:05:45    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [1980/4572]  eta: 0:05:42    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [2]  [2000/4572]  eta: 0:05:40    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [2]  [2020/4572]  eta: 0:05:37    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [2040/4572]  eta: 0:05:34    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [2]  [2060/4572]  eta: 0:05:32    time: 0.1322  data: 0.1183  max mem: 10802
Epoch: [2]  [2080/4572]  eta: 0:05:29    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [2100/4572]  eta: 0:05:26    time: 0.1322  data: 0.1214  max mem: 10802
Epoch: [2]  [2120/4572]  eta: 0:05:24    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [2]  [2140/4572]  eta: 0:05:21    time: 0.1323  data: 0.1185  max mem: 10802
Epoch: [2]  [2160/4572]  eta: 0:05:18    time: 0.1321  data: 0.1235  max mem: 10802
Epoch: [2]  [2180/4572]  eta: 0:05:16    time: 0.1323  data: 0.1185  max mem: 10802
Epoch: [2]  [2200/4572]  eta: 0:05:13    time: 0.1322  data: 0.1187  max mem: 10802
Epoch: [2]  [2220/4572]  eta: 0:05:10    time: 0.1321  data: 0.1187  max mem: 10802
Epoch: [2]  [2240/4572]  eta: 0:05:08    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [2]  [2260/4572]  eta: 0:05:05    time: 0.1325  data: 0.1185  max mem: 10802
Epoch: [2]  [2280/4572]  eta: 0:05:03    time: 0.1322  data: 0.1215  max mem: 10802
Epoch: [2]  [2300/4572]  eta: 0:05:00    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [2320/4572]  eta: 0:04:57    time: 0.1322  data: 0.1214  max mem: 10802
Epoch: [2]  [2340/4572]  eta: 0:04:55    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [2]  [2360/4572]  eta: 0:04:52    time: 0.1320  data: 0.1213  max mem: 10802
Epoch: [2]  [2380/4572]  eta: 0:04:49    time: 0.1322  data: 0.1182  max mem: 10802
Epoch: [2]  [2400/4572]  eta: 0:04:47    time: 0.1323  data: 0.1189  max mem: 10802
Epoch: [2]  [2420/4572]  eta: 0:04:44    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [2440/4572]  eta: 0:04:41    time: 0.1323  data: 0.1215  max mem: 10802
Epoch: [2]  [2460/4572]  eta: 0:04:39    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [2]  [2480/4572]  eta: 0:04:36    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [2500/4572]  eta: 0:04:33    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [2520/4572]  eta: 0:04:31    time: 0.1322  data: 0.1182  max mem: 10802
Epoch: [2]  [2540/4572]  eta: 0:04:28    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [2]  [2560/4572]  eta: 0:04:26    time: 0.1323  data: 0.1215  max mem: 10802
Epoch: [2]  [2580/4572]  eta: 0:04:23    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [2600/4572]  eta: 0:04:20    time: 0.1322  data: 0.1184  max mem: 10802
Epoch: [2]  [2620/4572]  eta: 0:04:18    time: 0.1336  data: 0.1229  max mem: 10802
Epoch: [2]  [2640/4572]  eta: 0:04:15    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [2660/4572]  eta: 0:04:12    time: 0.1323  data: 0.1188  max mem: 10802
Epoch: [2]  [2680/4572]  eta: 0:04:10    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [2]  [2700/4572]  eta: 0:04:07    time: 0.1324  data: 0.1233  max mem: 10802
Epoch: [2]  [2720/4572]  eta: 0:04:04    time: 0.1323  data: 0.1236  max mem: 10802
Epoch: [2]  [2740/4572]  eta: 0:04:02    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [2760/4572]  eta: 0:03:59    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [2780/4572]  eta: 0:03:56    time: 0.1324  data: 0.1215  max mem: 10802
Epoch: [2]  [2800/4572]  eta: 0:03:54    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [2]  [2820/4572]  eta: 0:03:51    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [2]  [2840/4572]  eta: 0:03:49    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [2860/4572]  eta: 0:03:46    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [2]  [2880/4572]  eta: 0:03:43    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [2900/4572]  eta: 0:03:41    time: 0.1322  data: 0.1182  max mem: 10802
Epoch: [2]  [2920/4572]  eta: 0:03:38    time: 0.1322  data: 0.1236  max mem: 10802
Epoch: [2]  [2940/4572]  eta: 0:03:35    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [2]  [2960/4572]  eta: 0:03:33    time: 0.1323  data: 0.1185  max mem: 10802
Epoch: [2]  [2980/4572]  eta: 0:03:30    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [3000/4572]  eta: 0:03:27    time: 0.1323  data: 0.1236  max mem: 10802
Epoch: [2]  [3020/4572]  eta: 0:03:25    time: 0.1323  data: 0.1237  max mem: 10802
Epoch: [2]  [3040/4572]  eta: 0:03:22    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [3060/4572]  eta: 0:03:19    time: 0.1324  data: 0.1184  max mem: 10802
Epoch: [2]  [3080/4572]  eta: 0:03:17    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [2]  [3100/4572]  eta: 0:03:14    time: 0.1338  data: 0.1202  max mem: 10802
Epoch: [2]  [3120/4572]  eta: 0:03:12    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [2]  [3140/4572]  eta: 0:03:09    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [2]  [3160/4572]  eta: 0:03:06    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [2]  [3180/4572]  eta: 0:03:04    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [2]  [3200/4572]  eta: 0:03:01    time: 0.1320  data: 0.1182  max mem: 10802
Epoch: [2]  [3220/4572]  eta: 0:02:58    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [2]  [3240/4572]  eta: 0:02:56    time: 0.1323  data: 0.1236  max mem: 10802
Epoch: [2]  [3260/4572]  eta: 0:02:53    time: 0.1325  data: 0.1185  max mem: 10802
Epoch: [2]  [3280/4572]  eta: 0:02:50    time: 0.1321  data: 0.1213  max mem: 10802
Epoch: [2]  [3300/4572]  eta: 0:02:48    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [2]  [3320/4572]  eta: 0:02:45    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [3340/4572]  eta: 0:02:42    time: 0.1321  data: 0.1234  max mem: 10802
Epoch: [2]  [3360/4572]  eta: 0:02:40    time: 0.1320  data: 0.1186  max mem: 10802
Epoch: [2]  [3380/4572]  eta: 0:02:37    time: 0.1323  data: 0.1188  max mem: 10802
Epoch: [2]  [3400/4572]  eta: 0:02:34    time: 0.1325  data: 0.1217  max mem: 10802
Epoch: [2]  [3420/4572]  eta: 0:02:32    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [2]  [3440/4572]  eta: 0:02:29    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [2]  [3460/4572]  eta: 0:02:27    time: 0.1323  data: 0.1212  max mem: 10802
Epoch: [2]  [3480/4572]  eta: 0:02:24    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [3500/4572]  eta: 0:02:21    time: 0.1324  data: 0.1185  max mem: 10802
Epoch: [2]  [3520/4572]  eta: 0:02:19    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [2]  [3540/4572]  eta: 0:02:16    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [2]  [3560/4572]  eta: 0:02:13    time: 0.1320  data: 0.1186  max mem: 10802
Epoch: [2]  [3580/4572]  eta: 0:02:11    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [2]  [3600/4572]  eta: 0:02:08    time: 0.1322  data: 0.1184  max mem: 10802
Epoch: [2]  [3620/4572]  eta: 0:02:05    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [2]  [3640/4572]  eta: 0:02:03    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [2]  [3660/4572]  eta: 0:02:00    time: 0.1323  data: 0.1189  max mem: 10802
Epoch: [2]  [3680/4572]  eta: 0:01:57    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [2]  [3700/4572]  eta: 0:01:55    time: 0.1321  data: 0.1214  max mem: 10802
Epoch: [2]  [3720/4572]  eta: 0:01:52    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [2]  [3740/4572]  eta: 0:01:50    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [3760/4572]  eta: 0:01:47    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [2]  [3780/4572]  eta: 0:01:44    time: 0.1322  data: 0.1184  max mem: 10802
Epoch: [2]  [3800/4572]  eta: 0:01:42    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [2]  [3820/4572]  eta: 0:01:39    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [2]  [3840/4572]  eta: 0:01:36    time: 0.1319  data: 0.1185  max mem: 10802
Epoch: [2]  [3860/4572]  eta: 0:01:34    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [2]  [3880/4572]  eta: 0:01:31    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [2]  [3900/4572]  eta: 0:01:28    time: 0.1322  data: 0.1231  max mem: 10802
Epoch: [2]  [3920/4572]  eta: 0:01:26    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [3940/4572]  eta: 0:01:23    time: 0.1322  data: 0.1236  max mem: 10802
Epoch: [2]  [3960/4572]  eta: 0:01:20    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [2]  [3980/4572]  eta: 0:01:18    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [2]  [4000/4572]  eta: 0:01:15    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [2]  [4020/4572]  eta: 0:01:12    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [2]  [4040/4572]  eta: 0:01:10    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [2]  [4060/4572]  eta: 0:01:07    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [2]  [4080/4572]  eta: 0:01:05    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [2]  [4100/4572]  eta: 0:01:02    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [2]  [4120/4572]  eta: 0:00:59    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [2]  [4140/4572]  eta: 0:00:57    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [2]  [4160/4572]  eta: 0:00:54    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [4180/4572]  eta: 0:00:51    time: 0.1322  data: 0.1182  max mem: 10802
Epoch: [2]  [4200/4572]  eta: 0:00:49    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [4220/4572]  eta: 0:00:46    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [2]  [4240/4572]  eta: 0:00:43    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [2]  [4260/4572]  eta: 0:00:41    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [2]  [4280/4572]  eta: 0:00:38    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [2]  [4300/4572]  eta: 0:00:35    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [2]  [4320/4572]  eta: 0:00:33    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [2]  [4340/4572]  eta: 0:00:30    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [2]  [4360/4572]  eta: 0:00:28    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [2]  [4380/4572]  eta: 0:00:25    time: 0.1321  data: 0.1213  max mem: 10802
Epoch: [2]  [4400/4572]  eta: 0:00:22    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [2]  [4420/4572]  eta: 0:00:20    time: 0.1320  data: 0.1186  max mem: 10802
Epoch: [2]  [4440/4572]  eta: 0:00:17    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [2]  [4460/4572]  eta: 0:00:14    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [4480/4572]  eta: 0:00:12    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [2]  [4500/4572]  eta: 0:00:09    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [4520/4572]  eta: 0:00:06    time: 0.1321  data: 0.1183  max mem: 10802
Epoch: [2]  [4540/4572]  eta: 0:00:04    time: 0.1321  data: 0.1182  max mem: 10802
Epoch: [2]  [4560/4572]  eta: 0:00:01    time: 0.1324  data: 0.1216  max mem: 10802
Epoch: [2]  [4571/4572]  eta: 0:00:00    time: 0.1321  data: 0.1213  max mem: 10802
Epoch: [2] Total time: 0:10:04 (0.1323 s / it)
:::MLLOG {"namespace": "", "time_ms": 1684352499197, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 332, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1684352499197, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 121.00484052054411}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 336, "step": 3}}
:::MLLOG {"namespace": "", "time_ms": 1684352499198, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 346, "epoch_num": 3}}
Test:  [ 0/97]  eta: 0:00:16  model_time: 0.1632 (0.1632)  evaluator_time: 0.0018 (0.0018)  time: 0.1658  data: 0.0007  max mem: 10802
Test:  [20/97]  eta: 0:00:12  model_time: 0.1618 (0.1629)  evaluator_time: 0.0019 (0.0019)  time: 0.1655  data: 0.0006  max mem: 10802
Test:  [40/97]  eta: 0:00:09  model_time: 0.1644 (0.1632)  evaluator_time: 0.0019 (0.0019)  time: 0.1662  data: 0.0006  max mem: 10802
Test:  [60/97]  eta: 0:00:06  model_time: 0.1676 (0.1635)  evaluator_time: 0.0020 (0.0028)  time: 0.1693  data: 0.0006  max mem: 10802
Test:  [80/97]  eta: 0:00:02  model_time: 0.1671 (0.1635)  evaluator_time: 0.0020 (0.0026)  time: 0.1663  data: 0.0006  max mem: 10802
Test:  [96/97]  eta: 0:00:00  model_time: 0.1639 (0.1631)  evaluator_time: 0.0018 (0.0025)  time: 0.1644  data: 0.0006  max mem: 10802
Test: Total time: 0:00:16 (0.1663 s / it)
Averaged stats: model_time: 0.1639 (0.1653)  evaluator_time: 0.0018 (0.0025)
:::MLLOG {"namespace": "", "time_ms": 1684352516104, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 161, "epoch_num": 3}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [3]  [   0/4571]  eta: 0:09:59    time: 0.1311  data: 0.0009  max mem: 10802
Epoch: [3]  [  20/4571]  eta: 0:09:59    time: 0.1317  data: 0.1226  max mem: 10802
:::MLLOG {"namespace": "", "time_ms": 1684352521227, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.32749007345289194, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 432, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1684352521227, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 433, "epoch_num": 3}}
Epoch: [3]  [  40/4571]  eta: 0:09:57    time: 0.1320  data: 0.1169  max mem: 10802
Epoch: [3]  [  60/4571]  eta: 0:09:54    time: 0.1320  data: 0.1183  max mem: 10802
Epoch: [3]  [  80/4571]  eta: 0:09:52    time: 0.1318  data: 0.1182  max mem: 10802
Epoch: [3]  [ 100/4571]  eta: 0:09:49    time: 0.1319  data: 0.1179  max mem: 10802
Epoch: [3]  [ 120/4571]  eta: 0:09:47    time: 0.1325  data: 0.1217  max mem: 10802
Epoch: [3]  [ 140/4571]  eta: 0:09:44    time: 0.1320  data: 0.1180  max mem: 10802
Epoch: [3]  [ 160/4571]  eta: 0:09:42    time: 0.1320  data: 0.1234  max mem: 10802
Epoch: [3]  [ 180/4571]  eta: 0:09:39    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [ 200/4571]  eta: 0:09:37    time: 0.1320  data: 0.1229  max mem: 10802
Epoch: [3]  [ 220/4571]  eta: 0:09:34    time: 0.1321  data: 0.1183  max mem: 10802
Epoch: [3]  [ 240/4571]  eta: 0:09:31    time: 0.1319  data: 0.1180  max mem: 10802
Epoch: [3]  [ 260/4571]  eta: 0:09:29    time: 0.1320  data: 0.1184  max mem: 10802
Epoch: [3]  [ 280/4571]  eta: 0:09:26    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [ 300/4571]  eta: 0:09:23    time: 0.1322  data: 0.1184  max mem: 10802
Epoch: [3]  [ 320/4571]  eta: 0:09:21    time: 0.1320  data: 0.1211  max mem: 10802
Epoch: [3]  [ 340/4571]  eta: 0:09:18    time: 0.1322  data: 0.1214  max mem: 10802
Epoch: [3]  [ 360/4571]  eta: 0:09:16    time: 0.1322  data: 0.1182  max mem: 10802
Epoch: [3]  [ 380/4571]  eta: 0:09:13    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [ 400/4571]  eta: 0:09:10    time: 0.1322  data: 0.1232  max mem: 10802
Epoch: [3]  [ 420/4571]  eta: 0:09:08    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [3]  [ 440/4571]  eta: 0:09:05    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [ 460/4571]  eta: 0:09:03    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [3]  [ 480/4571]  eta: 0:09:00    time: 0.1341  data: 0.1201  max mem: 10802
Epoch: [3]  [ 500/4571]  eta: 0:08:58    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [3]  [ 520/4571]  eta: 0:08:55    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [3]  [ 540/4571]  eta: 0:08:52    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [3]  [ 560/4571]  eta: 0:08:50    time: 0.1322  data: 0.1187  max mem: 10802
Epoch: [3]  [ 580/4571]  eta: 0:08:47    time: 0.1327  data: 0.1186  max mem: 10802
Epoch: [3]  [ 600/4571]  eta: 0:08:44    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [3]  [ 620/4571]  eta: 0:08:42    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [3]  [ 640/4571]  eta: 0:08:39    time: 0.1324  data: 0.1189  max mem: 10802
Epoch: [3]  [ 660/4571]  eta: 0:08:37    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [3]  [ 680/4571]  eta: 0:08:34    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [3]  [ 700/4571]  eta: 0:08:31    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [3]  [ 720/4571]  eta: 0:08:29    time: 0.1324  data: 0.1189  max mem: 10802
Epoch: [3]  [ 740/4571]  eta: 0:08:26    time: 0.1323  data: 0.1189  max mem: 10802
Epoch: [3]  [ 760/4571]  eta: 0:08:23    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [3]  [ 780/4571]  eta: 0:08:21    time: 0.1323  data: 0.1212  max mem: 10802
Epoch: [3]  [ 800/4571]  eta: 0:08:18    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [ 820/4571]  eta: 0:08:15    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [3]  [ 840/4571]  eta: 0:08:13    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [3]  [ 860/4571]  eta: 0:08:10    time: 0.1323  data: 0.1215  max mem: 10802
Epoch: [3]  [ 880/4571]  eta: 0:08:08    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [3]  [ 900/4571]  eta: 0:08:05    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [3]  [ 920/4571]  eta: 0:08:02    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [ 940/4571]  eta: 0:08:00    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [ 960/4571]  eta: 0:07:57    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [3]  [ 980/4571]  eta: 0:07:54    time: 0.1321  data: 0.1213  max mem: 10802
Epoch: [3]  [1000/4571]  eta: 0:07:52    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [1020/4571]  eta: 0:07:49    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [3]  [1040/4571]  eta: 0:07:46    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [3]  [1060/4571]  eta: 0:07:44    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [1080/4571]  eta: 0:07:41    time: 0.1340  data: 0.1254  max mem: 10802
Epoch: [3]  [1100/4571]  eta: 0:07:39    time: 0.1320  data: 0.1211  max mem: 10802
Epoch: [3]  [1120/4571]  eta: 0:07:36    time: 0.1320  data: 0.1233  max mem: 10802
Epoch: [3]  [1140/4571]  eta: 0:07:33    time: 0.1322  data: 0.1232  max mem: 10802
Epoch: [3]  [1160/4571]  eta: 0:07:31    time: 0.1320  data: 0.1182  max mem: 10802
Epoch: [3]  [1180/4571]  eta: 0:07:28    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [3]  [1200/4571]  eta: 0:07:25    time: 0.1320  data: 0.1211  max mem: 10802
Epoch: [3]  [1220/4571]  eta: 0:07:23    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [3]  [1240/4571]  eta: 0:07:20    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [3]  [1260/4571]  eta: 0:07:17    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [3]  [1280/4571]  eta: 0:07:15    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [3]  [1300/4571]  eta: 0:07:12    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [3]  [1320/4571]  eta: 0:07:09    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [3]  [1340/4571]  eta: 0:07:07    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [1360/4571]  eta: 0:07:04    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [1380/4571]  eta: 0:07:01    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [3]  [1400/4571]  eta: 0:06:59    time: 0.1320  data: 0.1233  max mem: 10802
Epoch: [3]  [1420/4571]  eta: 0:06:56    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [3]  [1440/4571]  eta: 0:06:53    time: 0.1321  data: 0.1183  max mem: 10802
Epoch: [3]  [1460/4571]  eta: 0:06:51    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [1480/4571]  eta: 0:06:48    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [3]  [1500/4571]  eta: 0:06:46    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [3]  [1520/4571]  eta: 0:06:43    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [1540/4571]  eta: 0:06:40    time: 0.1320  data: 0.1178  max mem: 10802
Epoch: [3]  [1560/4571]  eta: 0:06:38    time: 0.1321  data: 0.1183  max mem: 10802
Epoch: [3]  [1580/4571]  eta: 0:06:35    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [1600/4571]  eta: 0:06:32    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [3]  [1620/4571]  eta: 0:06:30    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [3]  [1640/4571]  eta: 0:06:27    time: 0.1322  data: 0.1178  max mem: 10802
Epoch: [3]  [1660/4571]  eta: 0:06:24    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [3]  [1680/4571]  eta: 0:06:22    time: 0.1320  data: 0.1179  max mem: 10802
Epoch: [3]  [1700/4571]  eta: 0:06:19    time: 0.1320  data: 0.1179  max mem: 10802
Epoch: [3]  [1720/4571]  eta: 0:06:16    time: 0.1321  data: 0.1183  max mem: 10802
Epoch: [3]  [1740/4571]  eta: 0:06:14    time: 0.1321  data: 0.1234  max mem: 10802
Epoch: [3]  [1760/4571]  eta: 0:06:11    time: 0.1321  data: 0.1211  max mem: 10802
Epoch: [3]  [1780/4571]  eta: 0:06:08    time: 0.1320  data: 0.1183  max mem: 10802
Epoch: [3]  [1800/4571]  eta: 0:06:06    time: 0.1321  data: 0.1232  max mem: 10802
Epoch: [3]  [1820/4571]  eta: 0:06:03    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [1840/4571]  eta: 0:06:01    time: 0.1321  data: 0.1183  max mem: 10802
Epoch: [3]  [1860/4571]  eta: 0:05:58    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [1880/4571]  eta: 0:05:55    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [1900/4571]  eta: 0:05:53    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [1920/4571]  eta: 0:05:50    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [1940/4571]  eta: 0:05:47    time: 0.1322  data: 0.1179  max mem: 10802
Epoch: [3]  [1960/4571]  eta: 0:05:45    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [1980/4571]  eta: 0:05:42    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [2000/4571]  eta: 0:05:39    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [3]  [2020/4571]  eta: 0:05:37    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [2040/4571]  eta: 0:05:34    time: 0.1322  data: 0.1182  max mem: 10802
Epoch: [3]  [2060/4571]  eta: 0:05:31    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [3]  [2080/4571]  eta: 0:05:29    time: 0.1321  data: 0.1183  max mem: 10802
Epoch: [3]  [2100/4571]  eta: 0:05:26    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [3]  [2120/4571]  eta: 0:05:24    time: 0.1323  data: 0.1185  max mem: 10802
Epoch: [3]  [2140/4571]  eta: 0:05:21    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [3]  [2160/4571]  eta: 0:05:18    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [2180/4571]  eta: 0:05:16    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [3]  [2200/4571]  eta: 0:05:13    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [2220/4571]  eta: 0:05:10    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [3]  [2240/4571]  eta: 0:05:08    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [3]  [2260/4571]  eta: 0:05:05    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [3]  [2280/4571]  eta: 0:05:02    time: 0.1321  data: 0.1234  max mem: 10802
Epoch: [3]  [2300/4571]  eta: 0:05:00    time: 0.1324  data: 0.1188  max mem: 10802
Epoch: [3]  [2320/4571]  eta: 0:04:57    time: 0.1323  data: 0.1183  max mem: 10802
Epoch: [3]  [2340/4571]  eta: 0:04:54    time: 0.1320  data: 0.1212  max mem: 10802
Epoch: [3]  [2360/4571]  eta: 0:04:52    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [3]  [2380/4571]  eta: 0:04:49    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [2400/4571]  eta: 0:04:46    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [3]  [2420/4571]  eta: 0:04:44    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [3]  [2440/4571]  eta: 0:04:41    time: 0.1321  data: 0.1211  max mem: 10802
Epoch: [3]  [2460/4571]  eta: 0:04:39    time: 0.1320  data: 0.1184  max mem: 10802
Epoch: [3]  [2480/4571]  eta: 0:04:36    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [2500/4571]  eta: 0:04:33    time: 0.1323  data: 0.1213  max mem: 10802
Epoch: [3]  [2520/4571]  eta: 0:04:31    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [3]  [2540/4571]  eta: 0:04:28    time: 0.1322  data: 0.1211  max mem: 10802
Epoch: [3]  [2560/4571]  eta: 0:04:25    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [2580/4571]  eta: 0:04:23    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [2600/4571]  eta: 0:04:20    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [2620/4571]  eta: 0:04:17    time: 0.1322  data: 0.1212  max mem: 10802
Epoch: [3]  [2640/4571]  eta: 0:04:15    time: 0.1323  data: 0.1180  max mem: 10802
Epoch: [3]  [2660/4571]  eta: 0:04:12    time: 0.1320  data: 0.1179  max mem: 10802
Epoch: [3]  [2680/4571]  eta: 0:04:09    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [3]  [2700/4571]  eta: 0:04:07    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [2720/4571]  eta: 0:04:04    time: 0.1322  data: 0.1184  max mem: 10802
Epoch: [3]  [2740/4571]  eta: 0:04:02    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [2760/4571]  eta: 0:03:59    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [2780/4571]  eta: 0:03:56    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [3]  [2800/4571]  eta: 0:03:54    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [2820/4571]  eta: 0:03:51    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [3]  [2840/4571]  eta: 0:03:48    time: 0.1321  data: 0.1178  max mem: 10802
Epoch: [3]  [2860/4571]  eta: 0:03:46    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [3]  [2880/4571]  eta: 0:03:43    time: 0.1320  data: 0.1183  max mem: 10802
Epoch: [3]  [2900/4571]  eta: 0:03:40    time: 0.1321  data: 0.1183  max mem: 10802
Epoch: [3]  [2920/4571]  eta: 0:03:38    time: 0.1320  data: 0.1178  max mem: 10802
Epoch: [3]  [2940/4571]  eta: 0:03:35    time: 0.1320  data: 0.1184  max mem: 10802
Epoch: [3]  [2960/4571]  eta: 0:03:32    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [2980/4571]  eta: 0:03:30    time: 0.1320  data: 0.1211  max mem: 10802
Epoch: [3]  [3000/4571]  eta: 0:03:27    time: 0.1324  data: 0.1185  max mem: 10802
Epoch: [3]  [3020/4571]  eta: 0:03:25    time: 0.1320  data: 0.1212  max mem: 10802
Epoch: [3]  [3040/4571]  eta: 0:03:22    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [3060/4571]  eta: 0:03:19    time: 0.1321  data: 0.1178  max mem: 10802
Epoch: [3]  [3080/4571]  eta: 0:03:17    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [3]  [3100/4571]  eta: 0:03:14    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [3120/4571]  eta: 0:03:11    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [3140/4571]  eta: 0:03:09    time: 0.1320  data: 0.1178  max mem: 10802
Epoch: [3]  [3160/4571]  eta: 0:03:06    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [3]  [3180/4571]  eta: 0:03:03    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [3200/4571]  eta: 0:03:01    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [3220/4571]  eta: 0:02:58    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [3240/4571]  eta: 0:02:55    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [3260/4571]  eta: 0:02:53    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [3]  [3280/4571]  eta: 0:02:50    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [3]  [3300/4571]  eta: 0:02:47    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [3320/4571]  eta: 0:02:45    time: 0.1321  data: 0.1183  max mem: 10802
Epoch: [3]  [3340/4571]  eta: 0:02:42    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [3360/4571]  eta: 0:02:40    time: 0.1323  data: 0.1185  max mem: 10802
Epoch: [3]  [3380/4571]  eta: 0:02:37    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [3]  [3400/4571]  eta: 0:02:34    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [3]  [3420/4571]  eta: 0:02:32    time: 0.1322  data: 0.1184  max mem: 10802
Epoch: [3]  [3440/4571]  eta: 0:02:29    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [3]  [3460/4571]  eta: 0:02:26    time: 0.1320  data: 0.1211  max mem: 10802
Epoch: [3]  [3480/4571]  eta: 0:02:24    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [3500/4571]  eta: 0:02:21    time: 0.1321  data: 0.1234  max mem: 10802
Epoch: [3]  [3520/4571]  eta: 0:02:18    time: 0.1321  data: 0.1211  max mem: 10802
Epoch: [3]  [3540/4571]  eta: 0:02:16    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [3]  [3560/4571]  eta: 0:02:13    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [3]  [3580/4571]  eta: 0:02:10    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [3600/4571]  eta: 0:02:08    time: 0.1320  data: 0.1179  max mem: 10802
Epoch: [3]  [3620/4571]  eta: 0:02:05    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [3]  [3640/4571]  eta: 0:02:03    time: 0.1321  data: 0.1213  max mem: 10802
Epoch: [3]  [3660/4571]  eta: 0:02:00    time: 0.1321  data: 0.1183  max mem: 10802
Epoch: [3]  [3680/4571]  eta: 0:01:57    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [3700/4571]  eta: 0:01:55    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [3]  [3720/4571]  eta: 0:01:52    time: 0.1320  data: 0.1183  max mem: 10802
Epoch: [3]  [3740/4571]  eta: 0:01:49    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [3]  [3760/4571]  eta: 0:01:47    time: 0.1320  data: 0.1182  max mem: 10802
Epoch: [3]  [3780/4571]  eta: 0:01:44    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [3800/4571]  eta: 0:01:41    time: 0.1323  data: 0.1185  max mem: 10802
Epoch: [3]  [3820/4571]  eta: 0:01:39    time: 0.1321  data: 0.1234  max mem: 10802
Epoch: [3]  [3840/4571]  eta: 0:01:36    time: 0.1330  data: 0.1188  max mem: 10802
Epoch: [3]  [3860/4571]  eta: 0:01:33    time: 0.1323  data: 0.1188  max mem: 10802
Epoch: [3]  [3880/4571]  eta: 0:01:31    time: 0.1321  data: 0.1178  max mem: 10802
Epoch: [3]  [3900/4571]  eta: 0:01:28    time: 0.1321  data: 0.1183  max mem: 10802
Epoch: [3]  [3920/4571]  eta: 0:01:26    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [3940/4571]  eta: 0:01:23    time: 0.1320  data: 0.1183  max mem: 10802
Epoch: [3]  [3960/4571]  eta: 0:01:20    time: 0.1320  data: 0.1210  max mem: 10802
Epoch: [3]  [3980/4571]  eta: 0:01:18    time: 0.1320  data: 0.1233  max mem: 10802
Epoch: [3]  [4000/4571]  eta: 0:01:15    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [4020/4571]  eta: 0:01:12    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [4040/4571]  eta: 0:01:10    time: 0.1322  data: 0.1187  max mem: 10802
Epoch: [3]  [4060/4571]  eta: 0:01:07    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [3]  [4080/4571]  eta: 0:01:04    time: 0.1327  data: 0.1190  max mem: 10802
Epoch: [3]  [4100/4571]  eta: 0:01:02    time: 0.1321  data: 0.1183  max mem: 10802
Epoch: [3]  [4120/4571]  eta: 0:00:59    time: 0.1320  data: 0.1180  max mem: 10802
Epoch: [3]  [4140/4571]  eta: 0:00:56    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [4160/4571]  eta: 0:00:54    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [3]  [4180/4571]  eta: 0:00:51    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [3]  [4200/4571]  eta: 0:00:49    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [3]  [4220/4571]  eta: 0:00:46    time: 0.1322  data: 0.1179  max mem: 10802
Epoch: [3]  [4240/4571]  eta: 0:00:43    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [4260/4571]  eta: 0:00:41    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [3]  [4280/4571]  eta: 0:00:38    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [3]  [4300/4571]  eta: 0:00:35    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [3]  [4320/4571]  eta: 0:00:33    time: 0.1321  data: 0.1233  max mem: 10802
Epoch: [3]  [4340/4571]  eta: 0:00:30    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [4360/4571]  eta: 0:00:27    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [3]  [4380/4571]  eta: 0:00:25    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [4400/4571]  eta: 0:00:22    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [4420/4571]  eta: 0:00:19    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [4440/4571]  eta: 0:00:17    time: 0.1321  data: 0.1234  max mem: 10802
Epoch: [3]  [4460/4571]  eta: 0:00:14    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [3]  [4480/4571]  eta: 0:00:12    time: 0.1321  data: 0.1213  max mem: 10802
Epoch: [3]  [4500/4571]  eta: 0:00:09    time: 0.1322  data: 0.1184  max mem: 10802
Epoch: [3]  [4520/4571]  eta: 0:00:06    time: 0.1320  data: 0.1184  max mem: 10802
Epoch: [3]  [4540/4571]  eta: 0:00:04    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [4560/4571]  eta: 0:00:01    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [3]  [4570/4571]  eta: 0:00:00    time: 0.1320  data: 0.1179  max mem: 10802
Epoch: [3] Total time: 0:10:04 (0.1321 s / it)
:::MLLOG {"namespace": "", "time_ms": 1684353120391, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 332, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1684353120391, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 121.08117473570798}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 336, "step": 4}}
:::MLLOG {"namespace": "", "time_ms": 1684353120391, "event_type": "INTERVAL_START", "key": "eval_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 346, "epoch_num": 4}}
Test:  [ 0/97]  eta: 0:00:15  model_time: 0.1584 (0.1584)  evaluator_time: 0.0017 (0.0017)  time: 0.1609  data: 0.0007  max mem: 10802
Test:  [20/97]  eta: 0:00:12  model_time: 0.1628 (0.1629)  evaluator_time: 0.0017 (0.0018)  time: 0.1656  data: 0.0006  max mem: 10802
Test:  [40/97]  eta: 0:00:09  model_time: 0.1649 (0.1631)  evaluator_time: 0.0018 (0.0018)  time: 0.1658  data: 0.0006  max mem: 10802
Test:  [60/97]  eta: 0:00:06  model_time: 0.1652 (0.1626)  evaluator_time: 0.0016 (0.0018)  time: 0.1640  data: 0.0006  max mem: 10802
Test:  [80/97]  eta: 0:00:02  model_time: 0.1664 (0.1631)  evaluator_time: 0.0018 (0.0018)  time: 0.1672  data: 0.0006  max mem: 10802
Test:  [96/97]  eta: 0:00:00  model_time: 0.1631 (0.1625)  evaluator_time: 0.0016 (0.0018)  time: 0.1631  data: 0.0006  max mem: 10802
Test: Total time: 0:00:16 (0.1650 s / it)
Averaged stats: model_time: 0.1631 (0.1650)  evaluator_time: 0.0016 (0.0021)
:::MLLOG {"namespace": "", "time_ms": 1684353137178, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 161, "epoch_num": 4}}
Epoch: [4]  [   0/4572]  eta: 0:10:00    time: 0.1313  data: 0.0012  max mem: 10802
Epoch: [4]  [  20/4572]  eta: 0:10:00    time: 0.1320  data: 0.1181  max mem: 10802
:::MLLOG {"namespace": "", "time_ms": 1684353141801, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.351034661594677, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 432, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1684353141801, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 433, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1684353142591, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 332, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1684353142592, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 124.87556240078496}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 336, "step": 5}}
:::MLLOG {"namespace": "", "time_ms": 1684353142604, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "train.py", "lineno": 698, "status": "success"}}
Training time 0:41:37
:::MLLOG {"namespace": "", "time_ms": 1684353142604, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684353142604, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684353142604, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684353142604, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684353142604, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684353142604, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684353142604, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684353142604, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684353142606, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684353142606, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684353142606, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684353142606, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684353142606, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684353142606, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684353142606, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684353142608, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
Loading annotations into memory...
Done (t=0.70s)
Creating index...
Done (t=0.94s)
Loading and preparing results...
DONE (t=2.72s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.19s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.24148
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.37125
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.25649
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00683
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.05902
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.26687
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.35948
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.51122
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.53298
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.02832
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.20665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.58063
Loading and preparing results...
DONE (t=2.63s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.33s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.30521
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.44735
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.32742
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00808
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.08221
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.33768
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.38810
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.55414
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.58072
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03154
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23064
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.63285
Loading and preparing results...
DONE (t=2.52s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.37s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.32749
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.47173
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.35474
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00915
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.09287
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36225
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.39670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.56946
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.59766
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03504
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.25196
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.64811
Loading and preparing results...
DONE (t=2.31s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.13s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.35103
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.49529
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.37609
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.01010
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.09680
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.38832
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.41124
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.58595
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.61437
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03989
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.26469
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.66601
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
ENDING TIMING RUN AT 2023-05-17 07:52:27 PM
RESULT,SINGLE_STAGE_DETECTOR,,2598,nvidia,2023-05-17 07:09:09 PM
ENDING TIMING RUN AT 2023-05-17 07:52:27 PM
RESULT,SINGLE_STAGE_DETECTOR,,2598,nvidia,2023-05-17 07:09:09 PM
ENDING TIMING RUN AT 2023-05-17 07:52:27 PM
RESULT,SINGLE_STAGE_DETECTOR,,2599,nvidia,2023-05-17 07:09:08 PM
ENDING TIMING RUN AT 2023-05-17 07:52:27 PM
RESULT,SINGLE_STAGE_DETECTOR,,2598,nvidia,2023-05-17 07:09:09 PM
ENDING TIMING RUN AT 2023-05-17 07:52:27 PM
RESULT,SINGLE_STAGE_DETECTOR,,2597,nvidia,2023-05-17 07:09:10 PM
ENDING TIMING RUN AT 2023-05-17 07:52:27 PM
RESULT,SINGLE_STAGE_DETECTOR,,2597,nvidia,2023-05-17 07:09:10 PM
ENDING TIMING RUN AT 2023-05-17 07:52:27 PM
RESULT,SINGLE_STAGE_DETECTOR,,2598,nvidia,2023-05-17 07:09:09 PM
ENDING TIMING RUN AT 2023-05-17 07:52:27 PM
RESULT,SINGLE_STAGE_DETECTOR,,2598,nvidia,2023-05-17 07:09:09 PM
ENDING TIMING RUN AT 2023-05-17 07:52:27 PM
RESULT,SINGLE_STAGE_DETECTOR,,2598,nvidia,2023-05-17 07:09:09 PM
ENDING TIMING RUN AT 2023-05-17 07:52:27 PM
RESULT,SINGLE_STAGE_DETECTOR,,2598,nvidia,2023-05-17 07:09:09 PM
ENDING TIMING RUN AT 2023-05-17 07:52:27 PM
RESULT,SINGLE_STAGE_DETECTOR,,2598,nvidia,2023-05-17 07:09:09 PM
ENDING TIMING RUN AT 2023-05-17 07:52:27 PM
RESULT,SINGLE_STAGE_DETECTOR,,2599,nvidia,2023-05-17 07:09:08 PM
ENDING TIMING RUN AT 2023-05-17 07:52:27 PM
RESULT,SINGLE_STAGE_DETECTOR,,2599,nvidia,2023-05-17 07:09:08 PM
ENDING TIMING RUN AT 2023-05-17 07:52:28 PM
RESULT,SINGLE_STAGE_DETECTOR,,2599,nvidia,2023-05-17 07:09:09 PM
ENDING TIMING RUN AT 2023-05-17 07:52:28 PM
RESULT,SINGLE_STAGE_DETECTOR,,2599,nvidia,2023-05-17 07:09:09 PM
ENDING TIMING RUN AT 2023-05-17 07:52:28 PM
RESULT,SINGLE_STAGE_DETECTOR,,2599,nvidia,2023-05-17 07:09:09 PM
