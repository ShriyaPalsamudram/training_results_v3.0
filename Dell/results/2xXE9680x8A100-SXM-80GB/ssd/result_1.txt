+ echo 'Beginning trial 2 of 5'
Beginning trial 2 of 5
+ echo ':::DLPAL dockerd://mlperf-nvidia:single_stage_detector-pytorch 38 2 xe9680node[50,60]'
:::DLPAL dockerd://mlperf-nvidia:single_stage_detector-pytorch 38 2 xe9680node[50,60]
+ srun -N1 -n1 --container-name=single_stage_detector_38 --mpi=pmi2 python -c ''
+ '[' 1 -eq 1 ']'
+ srun --ntasks=2 --mpi=pmi2 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on xe9680node60
Clearing cache on xe9680node50
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=2 --container-name=single_stage_detector_38 --mpi=pmi2 python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1684345252587, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1684345253479, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ srun --ntasks=16 --ntasks-per-node=8 --container-name=single_stage_detector_38 --container-mounts=/mount/training_datasets_v2.0/ssd/:/datasets/open-images-v6,/scripts/training_results_v3.0/ssd_multinode/:/results,/mount/training_datasets_v2.0/ssd/train/:/root/.cache/torch --container-workdir=/workspace/ssd slurm2pytorch ./run_and_time.sh
STARTING TIMING RUN AT 2023-05-17 05:41:04 PM
STARTING TIMING RUN AT 2023-05-17 05:41:04 PM
RANK 2: LOCAL_RANK 2, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 2, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
RANK 10: LOCAL_RANK 2, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 10, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 05:41:04 PM
RANK 1: LOCAL_RANK 1, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 1, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 05:41:04 PM
RANK 15: LOCAL_RANK 7, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 15, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 05:41:05 PM
RANK 12: LOCAL_RANK 4, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 12, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 05:41:05 PM
RANK 0: LOCAL_RANK 0, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 0, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 05:41:05 PM
RANK 14: LOCAL_RANK 6, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 14, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 05:41:05 PM
RANK 6: LOCAL_RANK 6, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 6, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 05:41:05 PM
RANK 13: LOCAL_RANK 5, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 13, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 05:41:05 PM
RANK 4: LOCAL_RANK 4, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 4, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 05:41:05 PM
RANK 9: LOCAL_RANK 1, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 9, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 05:41:05 PM
RANK 3: LOCAL_RANK 3, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 3, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 05:41:05 PM
RANK 8: LOCAL_RANK 0, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 8, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 05:41:05 PM
RANK 5: LOCAL_RANK 5, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 5, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 05:41:06 PM
RANK 11: LOCAL_RANK 3, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 11, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2023-05-17 05:41:06 PM
RANK 7: LOCAL_RANK 7, MASTER_ADDR 100.82.167.126, MASTER_PORT 9002, WORLD_SIZE 16, MLPERF_SLURM_FIRSTNODE xe9680node50, SLURM_JOB_ID 38, SLURM_NTASKS 16, SLURM_PROCID 7, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=52
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-qcokhf_g because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-kqkpu_fb because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-hfun1cgp because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-kmdgykbp because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-1zjnvwjn because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-l2anhl3e because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-mv04pc3z because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-ab1q7kfz because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-ywyy3nke because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-i3jopc6w because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-2yr9jczj because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-ux8ki5g8 because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-vlsii60d because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-z0t3ugvj because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-40f4uhl_ because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
Matplotlib created a temporary config/cache directory at /tmp/matplotlib-sj_hmn6_ because the default path (/root/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
[W init.cpp:833] Warning: Use _jit_set_fusion_strategy, bailout depth is deprecated. Setting to (STATIC, 20) (function operator())
| distributed init (rank 10): env://
| distributed init (rank 2): env://
| distributed init (rank 13): env://
| distributed init (rank 1): env://
| distributed init (rank 6): env://
| distributed init (rank 11): env://
| distributed init (rank 12): env://
| distributed init (rank 8): env://
| distributed init (rank 7): env://
| distributed init (rank 15): env://
| distributed init (rank 3): env://
| distributed init (rank 9): env://
| distributed init (rank 14): env://
| distributed init (rank 4): env://
| distributed init (rank 0): env://
| distributed init (rank 5): env://
:::MLLOG {"namespace": "", "time_ms": 1684345284994, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "ssd", "metadata": {"file": "train.py", "lineno": 313}}
:::MLLOG {"namespace": "", "time_ms": 1684345285060, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Dell", "metadata": {"file": "train.py", "lineno": 313}}
:::MLLOG {"namespace": "", "time_ms": 1684345285060, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "train.py", "lineno": 313}}
:::MLLOG {"namespace": "", "time_ms": 1684345285060, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "train.py", "lineno": 313}}
:::MLLOG {"namespace": "", "time_ms": 1684345285060, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "2xXE9680x8A100-SXM-80GB", "metadata": {"file": "train.py", "lineno": 313}}
:::MLLOG {"namespace": "", "time_ms": 1684345285060, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train.py", "lineno": 314}}
:::MLLOG {"namespace": "", "time_ms": 1684345285089, "event_type": "POINT_IN_TIME", "key": "seed", "value": 41048792, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684345285089, "event_type": "POINT_IN_TIME", "key": "local_batch_size", "value": 16, "metadata": {"file": "train.py", "lineno": 332}}
:::MLLOG {"namespace": "", "time_ms": 1684345285089, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 256, "metadata": {"file": "train.py", "lineno": 333}}
:::MLLOG {"namespace": "", "time_ms": 1684345285089, "event_type": "POINT_IN_TIME", "key": "epoch_count", "value": 6, "metadata": {"file": "train.py", "lineno": 334}}
:::MLLOG {"namespace": "", "time_ms": 1684345285089, "event_type": "POINT_IN_TIME", "key": "first_epoch_num", "value": 0, "metadata": {"file": "train.py", "lineno": 335}}
Namespace(allreduce_barrier=False, amp=True, apex_adam=True, apex_backbone_fusion=False, apex_focal_loss=True, apex_head_fusion=True, async_coco=True, async_coco_check_freq=20, backbone='resnext50_32x4d', batch_size=16, broadcast_buffers=False, cls_head_pad=True, coco_threads=8, cocoeval='nvidia', cuda_graphs=True, cuda_graphs_eval=False, cuda_graphs_syn=True, cuda_profiler=False, cuda_profiler_eval=False, cudnn_bench=False, dali=True, dali_cmn=0, dali_cpu_decode=False, dali_eval=True, dali_eval_cache=False, dali_matched_idxs=True, dali_preallocate_height=0, dali_preallocate_width=0, dali_prefetch_queue_depth=2, data_augmentation='hflip', data_layout='channels_last', dataset='openimages-mlperf', dataset_path='/datasets/open-images-v6', ddp_bucket_sz=25, ddp_first_bucket_sz=None, device='cuda', dist_backend='nccl', dist_url='env://', distributed=True, enable_sharp=False, epochs=6, eval_batch_size=16, eval_print_freq=20, eval_rank=0, eval_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], fp16_allreduce=True, frozen_bn_fp16=True, frozen_bn_opt=True, gpu=0, image_size=[800, 800], jit=True, lr=8.5e-05, master_weights=False, max_boxes=1000, max_eval_iters_per_epoch=None, max_iters_per_epoch=None, model_warmup_epochs=16, not_graphed_prologues=False, num_classes=None, num_eval_ranks=16, num_train_ranks=16, output_dir=None, pretrained=False, print_freq=20, rank=0, ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], reg_head_pad=True, resume='', seed=41048792, skip_eval=False, skip_metric_loss=True, start_epoch=0, syn_dataset=False, sync_after_graph_replay=False, sync_bn=False, target_map=0.34, test_only=False, train_annotations_file=None, train_data_path=None, train_rank=0, train_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], trainable_backbone_layers=3, val_annotations_file=None, val_data_path=None, warmup_epochs=0, warmup_factor=0.001, workers=4, world_size=16)
Getting dataset information
Creating model
:::MLLOG {"namespace": "", "time_ms": 1684345285119, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285122, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285123, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p7.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285126, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p7.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285067, "event_type": "POINT_IN_TIME", "key": "seed", "value": 41048793, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684345285089, "event_type": "POINT_IN_TIME", "key": "seed", "value": 41048795, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684345285089, "event_type": "POINT_IN_TIME", "key": "seed", "value": 41048796, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684345285089, "event_type": "POINT_IN_TIME", "key": "seed", "value": 41048798, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684345285089, "event_type": "POINT_IN_TIME", "key": "seed", "value": 41048799, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684345285089, "event_type": "POINT_IN_TIME", "key": "seed", "value": 41048794, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684345285089, "event_type": "POINT_IN_TIME", "key": "seed", "value": 41048797, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684345285101, "event_type": "POINT_IN_TIME", "key": "seed", "value": 41048805, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684345285101, "event_type": "POINT_IN_TIME", "key": "seed", "value": 41048802, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684345285101, "event_type": "POINT_IN_TIME", "key": "seed", "value": 41048800, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684345285101, "event_type": "POINT_IN_TIME", "key": "seed", "value": 41048803, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684345285101, "event_type": "POINT_IN_TIME", "key": "seed", "value": 41048801, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684345285101, "event_type": "POINT_IN_TIME", "key": "seed", "value": 41048807, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684345285101, "event_type": "POINT_IN_TIME", "key": "seed", "value": 41048804, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684345285101, "event_type": "POINT_IN_TIME", "key": "seed", "value": 41048806, "metadata": {"file": "train.py", "lineno": 329}}
:::MLLOG {"namespace": "", "time_ms": 1684345285280, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285280, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285281, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285282, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285283, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285283, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285283, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285284, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285285, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285286, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285286, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285287, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285289, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285289, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285290, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285290, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285292, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285293, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285295, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285298, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285301, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285302, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285305, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285308, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285308, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285311, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285314, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285315, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285318, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285321, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285321, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285324, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285327, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285328, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285331, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285336, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285338, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285349, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285361, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285372, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285374, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285385, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285396, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285398, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285504, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285505, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285505, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285506, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285506, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285509, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285509, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285512, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285512, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285515, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285515, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285519, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285533, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285537, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285537, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285540, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285540, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285544, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285544, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285547, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285573, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 148, "tensor": "module.head.classification_head.cls_logits.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285602, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 150, "tensor": "module.head.classification_head.cls_logits.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285615, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 318, "tensor": "module.head.regression_head.bbox_reg.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285616, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 320, "tensor": "module.head.regression_head.bbox_reg.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285616, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 325, "tensor": "module.head.regression_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285619, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 327, "tensor": "module.head.regression_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285620, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 325, "tensor": "module.head.regression_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285623, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 327, "tensor": "module.head.regression_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285623, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 325, "tensor": "module.head.regression_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285626, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 327, "tensor": "module.head.regression_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285626, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 325, "tensor": "module.head.regression_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285630, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 327, "tensor": "module.head.regression_head.conv.6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1684345285708, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adam", "metadata": {"file": "train.py", "lineno": 410}}
:::MLLOG {"namespace": "", "time_ms": 1684345285708, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 8.5e-05, "metadata": {"file": "train.py", "lineno": 411}}
:::MLLOG {"namespace": "", "time_ms": 1684345285708, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0, "metadata": {"file": "train.py", "lineno": 412}}
:::MLLOG {"namespace": "", "time_ms": 1684345285708, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 0, "metadata": {"file": "train.py", "lineno": 413}}
:::MLLOG {"namespace": "", "time_ms": 1684345285708, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0.001, "metadata": {"file": "train.py", "lineno": 414}}
:::MLLOG {"namespace": "", "time_ms": 1684345285708, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "train.py", "lineno": 415}}
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.8/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3488.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model eval warmup
Time: 56.09330415725708 sec
Creating Dali dataloader
CUDA graph capture
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/cuda/amp/grad_scaler.py:342: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
:::MLLOG {"namespace": "", "time_ms": 1684345360748, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "train.py", "lineno": 505}}
:::MLLOG {"namespace": "", "time_ms": 1684345360748, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "train.py", "lineno": 509}}
:::MLLOG {"namespace": "", "time_ms": 1684345360748, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 4572, "metadata": {"file": "train.py", "lineno": 536}}
:::MLLOG {"namespace": "", "time_ms": 1684345361370, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 97, "metadata": {"file": "train.py", "lineno": 577}}
Running ...
:::MLLOG {"namespace": "", "time_ms": 1684345361404, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 161, "epoch_num": 0}}
Epoch: [0]  [   0/4572]  eta: 0:09:57    time: 0.1307  data: 0.0003  max mem: 10802
Epoch: [0]  [  20/4572]  eta: 0:10:32    time: 0.1393  data: 0.1299  max mem: 10802
Epoch: [0]  [  40/4572]  eta: 0:10:18    time: 0.1342  data: 0.1186  max mem: 10802
Epoch: [0]  [  60/4572]  eta: 0:10:10    time: 0.1329  data: 0.1234  max mem: 10802
Epoch: [0]  [  80/4572]  eta: 0:10:05    time: 0.1327  data: 0.1237  max mem: 10802
Epoch: [0]  [ 100/4572]  eta: 0:10:00    time: 0.1330  data: 0.1183  max mem: 10802
Epoch: [0]  [ 120/4572]  eta: 0:09:57    time: 0.1330  data: 0.1186  max mem: 10802
Epoch: [0]  [ 140/4572]  eta: 0:09:53    time: 0.1331  data: 0.1242  max mem: 10802
Epoch: [0]  [ 160/4572]  eta: 0:09:50    time: 0.1327  data: 0.1238  max mem: 10802
Epoch: [0]  [ 180/4572]  eta: 0:09:47    time: 0.1329  data: 0.1250  max mem: 10802
Epoch: [0]  [ 200/4572]  eta: 0:09:44    time: 0.1328  data: 0.1188  max mem: 10802
Epoch: [0]  [ 220/4572]  eta: 0:09:41    time: 0.1329  data: 0.1189  max mem: 10802
Epoch: [0]  [ 240/4572]  eta: 0:09:38    time: 0.1328  data: 0.1184  max mem: 10802
Epoch: [0]  [ 260/4572]  eta: 0:09:35    time: 0.1331  data: 0.1243  max mem: 10802
Epoch: [0]  [ 280/4572]  eta: 0:09:32    time: 0.1330  data: 0.1252  max mem: 10802
Epoch: [0]  [ 300/4572]  eta: 0:09:29    time: 0.1327  data: 0.1240  max mem: 10802
Epoch: [0]  [ 320/4572]  eta: 0:09:26    time: 0.1328  data: 0.1240  max mem: 10802
Epoch: [0]  [ 340/4572]  eta: 0:09:24    time: 0.1326  data: 0.1248  max mem: 10802
Epoch: [0]  [ 360/4572]  eta: 0:09:21    time: 0.1329  data: 0.1192  max mem: 10802
Epoch: [0]  [ 380/4572]  eta: 0:09:18    time: 0.1328  data: 0.1118  max mem: 10802
Epoch: [0]  [ 400/4572]  eta: 0:09:15    time: 0.1327  data: 0.1189  max mem: 10802
Epoch: [0]  [ 420/4572]  eta: 0:09:13    time: 0.1329  data: 0.1219  max mem: 10802
Epoch: [0]  [ 440/4572]  eta: 0:09:10    time: 0.1331  data: 0.1190  max mem: 10802
Epoch: [0]  [ 460/4572]  eta: 0:09:07    time: 0.1327  data: 0.1187  max mem: 10802
Epoch: [0]  [ 480/4572]  eta: 0:09:04    time: 0.1329  data: 0.1185  max mem: 10802
Epoch: [0]  [ 500/4572]  eta: 0:09:02    time: 0.1329  data: 0.1239  max mem: 10802
Epoch: [0]  [ 520/4572]  eta: 0:08:59    time: 0.1328  data: 0.1183  max mem: 10802
Epoch: [0]  [ 540/4572]  eta: 0:08:56    time: 0.1326  data: 0.1236  max mem: 10802
Epoch: [0]  [ 560/4572]  eta: 0:08:54    time: 0.1329  data: 0.1184  max mem: 10802
Epoch: [0]  [ 580/4572]  eta: 0:08:51    time: 0.1328  data: 0.1190  max mem: 10802
Epoch: [0]  [ 600/4572]  eta: 0:08:48    time: 0.1334  data: 0.1192  max mem: 10802
Epoch: [0]  [ 620/4572]  eta: 0:08:46    time: 0.1329  data: 0.1189  max mem: 10802
Epoch: [0]  [ 640/4572]  eta: 0:08:43    time: 0.1328  data: 0.1192  max mem: 10802
Epoch: [0]  [ 660/4572]  eta: 0:08:40    time: 0.1329  data: 0.1219  max mem: 10802
Epoch: [0]  [ 680/4572]  eta: 0:08:37    time: 0.1328  data: 0.1190  max mem: 10802
Epoch: [0]  [ 700/4572]  eta: 0:08:35    time: 0.1328  data: 0.1214  max mem: 10802
Epoch: [0]  [ 720/4572]  eta: 0:08:32    time: 0.1329  data: 0.1237  max mem: 10802
Epoch: [0]  [ 740/4572]  eta: 0:08:29    time: 0.1327  data: 0.1186  max mem: 10802
Epoch: [0]  [ 760/4572]  eta: 0:08:27    time: 0.1327  data: 0.1239  max mem: 10802
Epoch: [0]  [ 780/4572]  eta: 0:08:24    time: 0.1328  data: 0.1185  max mem: 10802
Epoch: [0]  [ 800/4572]  eta: 0:08:21    time: 0.1329  data: 0.1219  max mem: 10802
Epoch: [0]  [ 820/4572]  eta: 0:08:19    time: 0.1329  data: 0.1219  max mem: 10802
Epoch: [0]  [ 840/4572]  eta: 0:08:16    time: 0.1332  data: 0.1190  max mem: 10802
Epoch: [0]  [ 860/4572]  eta: 0:08:13    time: 0.1331  data: 0.1189  max mem: 10802
Epoch: [0]  [ 880/4572]  eta: 0:08:11    time: 0.1329  data: 0.1188  max mem: 10802
Epoch: [0]  [ 900/4572]  eta: 0:08:08    time: 0.1327  data: 0.1184  max mem: 10802
Epoch: [0]  [ 920/4572]  eta: 0:08:05    time: 0.1328  data: 0.1190  max mem: 10802
Epoch: [0]  [ 940/4572]  eta: 0:08:03    time: 0.1330  data: 0.1188  max mem: 10802
Epoch: [0]  [ 960/4572]  eta: 0:08:00    time: 0.1326  data: 0.1184  max mem: 10802
Epoch: [0]  [ 980/4572]  eta: 0:07:57    time: 0.1328  data: 0.1191  max mem: 10802
Epoch: [0]  [1000/4572]  eta: 0:07:55    time: 0.1327  data: 0.1191  max mem: 10802
Epoch: [0]  [1020/4572]  eta: 0:07:52    time: 0.1328  data: 0.1239  max mem: 10802
Epoch: [0]  [1040/4572]  eta: 0:07:49    time: 0.1327  data: 0.1189  max mem: 10802
Epoch: [0]  [1060/4572]  eta: 0:07:47    time: 0.1327  data: 0.1185  max mem: 10802
Epoch: [0]  [1080/4572]  eta: 0:07:44    time: 0.1328  data: 0.1191  max mem: 10802
Epoch: [0]  [1100/4572]  eta: 0:07:41    time: 0.1328  data: 0.1190  max mem: 10802
Epoch: [0]  [1120/4572]  eta: 0:07:39    time: 0.1329  data: 0.1187  max mem: 10802
Epoch: [0]  [1140/4572]  eta: 0:07:36    time: 0.1329  data: 0.1187  max mem: 10802
Epoch: [0]  [1160/4572]  eta: 0:07:33    time: 0.1327  data: 0.1185  max mem: 10802
Epoch: [0]  [1180/4572]  eta: 0:07:31    time: 0.1329  data: 0.1192  max mem: 10802
Epoch: [0]  [1200/4572]  eta: 0:07:28    time: 0.1326  data: 0.1180  max mem: 10802
Epoch: [0]  [1220/4572]  eta: 0:07:25    time: 0.1327  data: 0.1189  max mem: 10802
Epoch: [0]  [1240/4572]  eta: 0:07:23    time: 0.1327  data: 0.1182  max mem: 10802
Epoch: [0]  [1260/4572]  eta: 0:07:20    time: 0.1327  data: 0.1184  max mem: 10802
Epoch: [0]  [1280/4572]  eta: 0:07:17    time: 0.1327  data: 0.1235  max mem: 10802
Epoch: [0]  [1300/4572]  eta: 0:07:15    time: 0.1327  data: 0.1235  max mem: 10802
Epoch: [0]  [1320/4572]  eta: 0:07:12    time: 0.1332  data: 0.1193  max mem: 10802
Epoch: [0]  [1340/4572]  eta: 0:07:09    time: 0.1332  data: 0.1187  max mem: 10802
Epoch: [0]  [1360/4572]  eta: 0:07:07    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [0]  [1380/4572]  eta: 0:07:04    time: 0.1326  data: 0.1184  max mem: 10802
Epoch: [0]  [1400/4572]  eta: 0:07:01    time: 0.1327  data: 0.1216  max mem: 10802
Epoch: [0]  [1420/4572]  eta: 0:06:59    time: 0.1327  data: 0.1192  max mem: 10802
Epoch: [0]  [1440/4572]  eta: 0:06:56    time: 0.1326  data: 0.1191  max mem: 10802
Epoch: [0]  [1460/4572]  eta: 0:06:53    time: 0.1328  data: 0.1240  max mem: 10802
Epoch: [0]  [1480/4572]  eta: 0:06:51    time: 0.1326  data: 0.1216  max mem: 10802
Epoch: [0]  [1500/4572]  eta: 0:06:48    time: 0.1329  data: 0.1184  max mem: 10802
Epoch: [0]  [1520/4572]  eta: 0:06:45    time: 0.1326  data: 0.1189  max mem: 10802
Epoch: [0]  [1540/4572]  eta: 0:06:43    time: 0.1330  data: 0.1220  max mem: 10802
Epoch: [0]  [1560/4572]  eta: 0:06:40    time: 0.1325  data: 0.1189  max mem: 10802
Epoch: [0]  [1580/4572]  eta: 0:06:37    time: 0.1327  data: 0.1217  max mem: 10802
Epoch: [0]  [1600/4572]  eta: 0:06:35    time: 0.1326  data: 0.1182  max mem: 10802
Epoch: [0]  [1620/4572]  eta: 0:06:32    time: 0.1329  data: 0.1184  max mem: 10802
Epoch: [0]  [1640/4572]  eta: 0:06:29    time: 0.1327  data: 0.1185  max mem: 10802
Epoch: [0]  [1660/4572]  eta: 0:06:27    time: 0.1328  data: 0.1191  max mem: 10802
Epoch: [0]  [1680/4572]  eta: 0:06:24    time: 0.1331  data: 0.1193  max mem: 10802
Epoch: [0]  [1700/4572]  eta: 0:06:21    time: 0.1329  data: 0.1219  max mem: 10802
Epoch: [0]  [1720/4572]  eta: 0:06:19    time: 0.1329  data: 0.1194  max mem: 10802
Epoch: [0]  [1740/4572]  eta: 0:06:16    time: 0.1326  data: 0.1183  max mem: 10802
Epoch: [0]  [1760/4572]  eta: 0:06:13    time: 0.1327  data: 0.1189  max mem: 10802
Epoch: [0]  [1780/4572]  eta: 0:06:11    time: 0.1326  data: 0.1187  max mem: 10802
Epoch: [0]  [1800/4572]  eta: 0:06:08    time: 0.1325  data: 0.1187  max mem: 10802
Epoch: [0]  [1820/4572]  eta: 0:06:05    time: 0.1328  data: 0.1239  max mem: 10802
Epoch: [0]  [1840/4572]  eta: 0:06:03    time: 0.1326  data: 0.1189  max mem: 10802
Epoch: [0]  [1860/4572]  eta: 0:06:00    time: 0.1329  data: 0.1220  max mem: 10802
Epoch: [0]  [1880/4572]  eta: 0:05:57    time: 0.1327  data: 0.1218  max mem: 10802
Epoch: [0]  [1900/4572]  eta: 0:05:55    time: 0.1328  data: 0.1192  max mem: 10802
Epoch: [0]  [1920/4572]  eta: 0:05:52    time: 0.1328  data: 0.1241  max mem: 10802
Epoch: [0]  [1940/4572]  eta: 0:05:49    time: 0.1327  data: 0.1192  max mem: 10802
Epoch: [0]  [1960/4572]  eta: 0:05:47    time: 0.1326  data: 0.1184  max mem: 10802
Epoch: [0]  [1980/4572]  eta: 0:05:44    time: 0.1326  data: 0.1190  max mem: 10802
Epoch: [0]  [2000/4572]  eta: 0:05:41    time: 0.1326  data: 0.1188  max mem: 10802
Epoch: [0]  [2020/4572]  eta: 0:05:39    time: 0.1325  data: 0.1237  max mem: 10802
Epoch: [0]  [2040/4572]  eta: 0:05:36    time: 0.1326  data: 0.1218  max mem: 10802
Epoch: [0]  [2060/4572]  eta: 0:05:33    time: 0.1326  data: 0.1184  max mem: 10802
Epoch: [0]  [2080/4572]  eta: 0:05:31    time: 0.1327  data: 0.1185  max mem: 10802
Epoch: [0]  [2100/4572]  eta: 0:05:28    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [0]  [2120/4572]  eta: 0:05:25    time: 0.1326  data: 0.1239  max mem: 10802
Epoch: [0]  [2140/4572]  eta: 0:05:23    time: 0.1326  data: 0.1238  max mem: 10802
Epoch: [0]  [2160/4572]  eta: 0:05:20    time: 0.1326  data: 0.1187  max mem: 10802
Epoch: [0]  [2180/4572]  eta: 0:05:17    time: 0.1325  data: 0.1189  max mem: 10802
Epoch: [0]  [2200/4572]  eta: 0:05:15    time: 0.1326  data: 0.1183  max mem: 10802
Epoch: [0]  [2220/4572]  eta: 0:05:12    time: 0.1327  data: 0.1239  max mem: 10802
Epoch: [0]  [2240/4572]  eta: 0:05:09    time: 0.1325  data: 0.1189  max mem: 10802
Epoch: [0]  [2260/4572]  eta: 0:05:07    time: 0.1330  data: 0.1188  max mem: 10802
Epoch: [0]  [2280/4572]  eta: 0:05:04    time: 0.1326  data: 0.1184  max mem: 10802
Epoch: [0]  [2300/4572]  eta: 0:05:01    time: 0.1330  data: 0.1240  max mem: 10802
Epoch: [0]  [2320/4572]  eta: 0:04:59    time: 0.1328  data: 0.1187  max mem: 10802
Epoch: [0]  [2340/4572]  eta: 0:04:56    time: 0.1325  data: 0.1217  max mem: 10802
Epoch: [0]  [2360/4572]  eta: 0:04:53    time: 0.1329  data: 0.1219  max mem: 10802
Epoch: [0]  [2380/4572]  eta: 0:04:51    time: 0.1327  data: 0.1185  max mem: 10802
Epoch: [0]  [2400/4572]  eta: 0:04:48    time: 0.1331  data: 0.1188  max mem: 10802
Epoch: [0]  [2420/4572]  eta: 0:04:45    time: 0.1326  data: 0.1191  max mem: 10802
Epoch: [0]  [2440/4572]  eta: 0:04:43    time: 0.1326  data: 0.1190  max mem: 10802
Epoch: [0]  [2460/4572]  eta: 0:04:40    time: 0.1339  data: 0.1198  max mem: 10802
Epoch: [0]  [2480/4572]  eta: 0:04:37    time: 0.1327  data: 0.1185  max mem: 10802
Epoch: [0]  [2500/4572]  eta: 0:04:35    time: 0.1326  data: 0.1237  max mem: 10802
Epoch: [0]  [2520/4572]  eta: 0:04:32    time: 0.1326  data: 0.1184  max mem: 10802
Epoch: [0]  [2540/4572]  eta: 0:04:29    time: 0.1326  data: 0.1217  max mem: 10802
Epoch: [0]  [2560/4572]  eta: 0:04:27    time: 0.1328  data: 0.1187  max mem: 10802
Epoch: [0]  [2580/4572]  eta: 0:04:24    time: 0.1326  data: 0.1185  max mem: 10802
Epoch: [0]  [2600/4572]  eta: 0:04:21    time: 0.1324  data: 0.1234  max mem: 10802
Epoch: [0]  [2620/4572]  eta: 0:04:19    time: 0.1323  data: 0.1185  max mem: 10802
Epoch: [0]  [2640/4572]  eta: 0:04:16    time: 0.1326  data: 0.1188  max mem: 10802
Epoch: [0]  [2660/4572]  eta: 0:04:13    time: 0.1325  data: 0.1190  max mem: 10802
Epoch: [0]  [2680/4572]  eta: 0:04:11    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [0]  [2700/4572]  eta: 0:04:08    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [0]  [2720/4572]  eta: 0:04:05    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [0]  [2740/4572]  eta: 0:04:03    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [0]  [2760/4572]  eta: 0:04:00    time: 0.1327  data: 0.1218  max mem: 10802
Epoch: [0]  [2780/4572]  eta: 0:03:58    time: 0.1325  data: 0.1216  max mem: 10802
Epoch: [0]  [2800/4572]  eta: 0:03:55    time: 0.1324  data: 0.1181  max mem: 10802
Epoch: [0]  [2820/4572]  eta: 0:03:52    time: 0.1326  data: 0.1188  max mem: 10802
Epoch: [0]  [2840/4572]  eta: 0:03:50    time: 0.1327  data: 0.1186  max mem: 10802
Epoch: [0]  [2860/4572]  eta: 0:03:47    time: 0.1328  data: 0.1218  max mem: 10802
Epoch: [0]  [2880/4572]  eta: 0:03:44    time: 0.1325  data: 0.1186  max mem: 10802
Epoch: [0]  [2900/4572]  eta: 0:03:42    time: 0.1324  data: 0.1214  max mem: 10802
Epoch: [0]  [2920/4572]  eta: 0:03:39    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [0]  [2940/4572]  eta: 0:03:36    time: 0.1325  data: 0.1216  max mem: 10802
Epoch: [0]  [2960/4572]  eta: 0:03:34    time: 0.1325  data: 0.1189  max mem: 10802
Epoch: [0]  [2980/4572]  eta: 0:03:31    time: 0.1327  data: 0.1217  max mem: 10802
Epoch: [0]  [3000/4572]  eta: 0:03:28    time: 0.1325  data: 0.1188  max mem: 10802
Epoch: [0]  [3020/4572]  eta: 0:03:26    time: 0.1326  data: 0.1217  max mem: 10802
Epoch: [0]  [3040/4572]  eta: 0:03:23    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [0]  [3060/4572]  eta: 0:03:20    time: 0.1327  data: 0.1190  max mem: 10802
Epoch: [0]  [3080/4572]  eta: 0:03:18    time: 0.1326  data: 0.1188  max mem: 10802
Epoch: [0]  [3100/4572]  eta: 0:03:15    time: 0.1327  data: 0.1217  max mem: 10802
Epoch: [0]  [3120/4572]  eta: 0:03:12    time: 0.1326  data: 0.1190  max mem: 10802
Epoch: [0]  [3140/4572]  eta: 0:03:10    time: 0.1327  data: 0.1251  max mem: 10802
Epoch: [0]  [3160/4572]  eta: 0:03:07    time: 0.1327  data: 0.1185  max mem: 10802
Epoch: [0]  [3180/4572]  eta: 0:03:04    time: 0.1325  data: 0.1174  max mem: 10802
Epoch: [0]  [3200/4572]  eta: 0:03:02    time: 0.1326  data: 0.1186  max mem: 10802
Epoch: [0]  [3220/4572]  eta: 0:02:59    time: 0.1326  data: 0.1191  max mem: 10802
Epoch: [0]  [3240/4572]  eta: 0:02:56    time: 0.1325  data: 0.1188  max mem: 10802
Epoch: [0]  [3260/4572]  eta: 0:02:54    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [0]  [3280/4572]  eta: 0:02:51    time: 0.1326  data: 0.1183  max mem: 10802
Epoch: [0]  [3300/4572]  eta: 0:02:48    time: 0.1325  data: 0.1189  max mem: 10802
Epoch: [0]  [3320/4572]  eta: 0:02:46    time: 0.1324  data: 0.1189  max mem: 10802
Epoch: [0]  [3340/4572]  eta: 0:02:43    time: 0.1326  data: 0.1185  max mem: 10802
Epoch: [0]  [3360/4572]  eta: 0:02:40    time: 0.1337  data: 0.1198  max mem: 10802
Epoch: [0]  [3380/4572]  eta: 0:02:38    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [0]  [3400/4572]  eta: 0:02:35    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [0]  [3420/4572]  eta: 0:02:32    time: 0.1324  data: 0.1215  max mem: 10802
Epoch: [0]  [3440/4572]  eta: 0:02:30    time: 0.1325  data: 0.1216  max mem: 10802
Epoch: [0]  [3460/4572]  eta: 0:02:27    time: 0.1327  data: 0.1186  max mem: 10802
Epoch: [0]  [3480/4572]  eta: 0:02:24    time: 0.1328  data: 0.1190  max mem: 10802
Epoch: [0]  [3500/4572]  eta: 0:02:22    time: 0.1326  data: 0.1183  max mem: 10802
Epoch: [0]  [3520/4572]  eta: 0:02:19    time: 0.1324  data: 0.1238  max mem: 10802
Epoch: [0]  [3540/4572]  eta: 0:02:17    time: 0.1326  data: 0.1189  max mem: 10802
Epoch: [0]  [3560/4572]  eta: 0:02:14    time: 0.1327  data: 0.1239  max mem: 10802
Epoch: [0]  [3580/4572]  eta: 0:02:11    time: 0.1325  data: 0.1188  max mem: 10802
Epoch: [0]  [3600/4572]  eta: 0:02:09    time: 0.1326  data: 0.1183  max mem: 10802
Epoch: [0]  [3620/4572]  eta: 0:02:06    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [0]  [3640/4572]  eta: 0:02:03    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [0]  [3660/4572]  eta: 0:02:01    time: 0.1324  data: 0.1215  max mem: 10802
Epoch: [0]  [3680/4572]  eta: 0:01:58    time: 0.1324  data: 0.1189  max mem: 10802
Epoch: [0]  [3700/4572]  eta: 0:01:55    time: 0.1327  data: 0.1184  max mem: 10802
Epoch: [0]  [3720/4572]  eta: 0:01:53    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [0]  [3740/4572]  eta: 0:01:50    time: 0.1325  data: 0.1189  max mem: 10802
Epoch: [0]  [3760/4572]  eta: 0:01:47    time: 0.1326  data: 0.1217  max mem: 10802
Epoch: [0]  [3780/4572]  eta: 0:01:45    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [0]  [3800/4572]  eta: 0:01:42    time: 0.1324  data: 0.1181  max mem: 10802
Epoch: [0]  [3820/4572]  eta: 0:01:39    time: 0.1326  data: 0.1190  max mem: 10802
Epoch: [0]  [3840/4572]  eta: 0:01:37    time: 0.1326  data: 0.1189  max mem: 10802
Epoch: [0]  [3860/4572]  eta: 0:01:34    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [0]  [3880/4572]  eta: 0:01:31    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [0]  [3900/4572]  eta: 0:01:29    time: 0.1326  data: 0.1215  max mem: 10802
Epoch: [0]  [3920/4572]  eta: 0:01:26    time: 0.1327  data: 0.1185  max mem: 10802
Epoch: [0]  [3940/4572]  eta: 0:01:23    time: 0.1325  data: 0.1216  max mem: 10802
Epoch: [0]  [3960/4572]  eta: 0:01:21    time: 0.1326  data: 0.1217  max mem: 10802
Epoch: [0]  [3980/4572]  eta: 0:01:18    time: 0.1328  data: 0.1192  max mem: 10802
Epoch: [0]  [4000/4572]  eta: 0:01:15    time: 0.1324  data: 0.1184  max mem: 10802
Epoch: [0]  [4020/4572]  eta: 0:01:13    time: 0.1328  data: 0.1187  max mem: 10802
Epoch: [0]  [4040/4572]  eta: 0:01:10    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [0]  [4060/4572]  eta: 0:01:07    time: 0.1326  data: 0.1217  max mem: 10802
Epoch: [0]  [4080/4572]  eta: 0:01:05    time: 0.1324  data: 0.1236  max mem: 10802
Epoch: [0]  [4100/4572]  eta: 0:01:02    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [0]  [4120/4572]  eta: 0:00:59    time: 0.1326  data: 0.1184  max mem: 10802
Epoch: [0]  [4140/4572]  eta: 0:00:57    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [0]  [4160/4572]  eta: 0:00:54    time: 0.1325  data: 0.1217  max mem: 10802
Epoch: [0]  [4180/4572]  eta: 0:00:52    time: 0.1326  data: 0.1238  max mem: 10802
Epoch: [0]  [4200/4572]  eta: 0:00:49    time: 0.1325  data: 0.1182  max mem: 10802
Epoch: [0]  [4220/4572]  eta: 0:00:46    time: 0.1325  data: 0.1217  max mem: 10802
Epoch: [0]  [4240/4572]  eta: 0:00:44    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [0]  [4260/4572]  eta: 0:00:41    time: 0.1326  data: 0.1238  max mem: 10802
Epoch: [0]  [4280/4572]  eta: 0:00:38    time: 0.1323  data: 0.1188  max mem: 10802
Epoch: [0]  [4300/4572]  eta: 0:00:36    time: 0.1324  data: 0.1185  max mem: 10802
Epoch: [0]  [4320/4572]  eta: 0:00:33    time: 0.1323  data: 0.1183  max mem: 10802
Epoch: [0]  [4340/4572]  eta: 0:00:30    time: 0.1326  data: 0.1190  max mem: 10802
Epoch: [0]  [4360/4572]  eta: 0:00:28    time: 0.1328  data: 0.1218  max mem: 10802
Epoch: [0]  [4380/4572]  eta: 0:00:25    time: 0.1324  data: 0.1214  max mem: 10802
Epoch: [0]  [4400/4572]  eta: 0:00:22    time: 0.1324  data: 0.1181  max mem: 10802
Epoch: [0]  [4420/4572]  eta: 0:00:20    time: 0.1323  data: 0.1236  max mem: 10802
Epoch: [0]  [4440/4572]  eta: 0:00:17    time: 0.1325  data: 0.1217  max mem: 10802
Epoch: [0]  [4460/4572]  eta: 0:00:14    time: 0.1326  data: 0.1189  max mem: 10802
Epoch: [0]  [4480/4572]  eta: 0:00:12    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [0]  [4500/4572]  eta: 0:00:09    time: 0.1327  data: 0.1183  max mem: 10802
Epoch: [0]  [4520/4572]  eta: 0:00:06    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [0]  [4540/4572]  eta: 0:00:04    time: 0.1324  data: 0.1214  max mem: 10802
Epoch: [0]  [4560/4572]  eta: 0:00:01    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [0]  [4571/4572]  eta: 0:00:00    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [0] Total time: 0:10:06 (0.1327 s / it)
:::MLLOG {"namespace": "", "time_ms": 1684345968311, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 332, "epoch_num": 0}}
:::MLLOG {"namespace": "", "time_ms": 1684345968311, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 120.56299365318549}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 336, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1684345968312, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 346, "epoch_num": 1}}
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [ 0/97]  eta: 0:00:24  model_time: 0.2527 (0.2527)  evaluator_time: 0.0020 (0.0020)  time: 0.2551  data: 0.0003  max mem: 10802
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [20/97]  eta: 0:00:14  model_time: 0.1767 (0.1818)  evaluator_time: 0.0021 (0.0022)  time: 0.1811  data: 0.0006  max mem: 10802
Test:  [40/97]  eta: 0:00:10  model_time: 0.1796 (0.1802)  evaluator_time: 0.0022 (0.0022)  time: 0.1815  data: 0.0006  max mem: 10802
Test:  [60/97]  eta: 0:00:06  model_time: 0.1822 (0.1805)  evaluator_time: 0.0021 (0.0022)  time: 0.1839  data: 0.0006  max mem: 10802
Test:  [80/97]  eta: 0:00:03  model_time: 0.1808 (0.1803)  evaluator_time: 0.0022 (0.0022)  time: 0.1825  data: 0.0006  max mem: 10802
Test:  [96/97]  eta: 0:00:00  model_time: 0.1825 (0.1801)  evaluator_time: 0.0020 (0.0022)  time: 0.1832  data: 0.0006  max mem: 10802
Test: Total time: 0:00:17 (0.1831 s / it)
Averaged stats: model_time: 0.1825 (0.1830)  evaluator_time: 0.0020 (0.0022)
:::MLLOG {"namespace": "", "time_ms": 1684345987002, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 161, "epoch_num": 1}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [1]  [   0/4571]  eta: 0:10:00    time: 0.1314  data: 0.0014  max mem: 10802
Epoch: [1]  [  20/4571]  eta: 0:10:01    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [1]  [  40/4571]  eta: 0:09:59    time: 0.1325  data: 0.1181  max mem: 10802
Epoch: [1]  [  60/4571]  eta: 0:09:56    time: 0.1323  data: 0.1179  max mem: 10802
:::MLLOG {"namespace": "", "time_ms": 1684345995585, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.2444206343923902, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 432, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1684345995586, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 433, "epoch_num": 1}}
Epoch: [1]  [  80/4571]  eta: 0:09:53    time: 0.1323  data: 0.1179  max mem: 10802
Epoch: [1]  [ 100/4571]  eta: 0:09:51    time: 0.1322  data: 0.1183  max mem: 10802
Epoch: [1]  [ 120/4571]  eta: 0:09:48    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [1]  [ 140/4571]  eta: 0:09:46    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [1]  [ 160/4571]  eta: 0:09:43    time: 0.1323  data: 0.1236  max mem: 10802
Epoch: [1]  [ 180/4571]  eta: 0:09:40    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [ 200/4571]  eta: 0:09:38    time: 0.1321  data: 0.1234  max mem: 10802
Epoch: [1]  [ 220/4571]  eta: 0:09:35    time: 0.1324  data: 0.1189  max mem: 10802
Epoch: [1]  [ 240/4571]  eta: 0:09:32    time: 0.1325  data: 0.1182  max mem: 10802
Epoch: [1]  [ 260/4571]  eta: 0:09:30    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1]  [ 280/4571]  eta: 0:09:27    time: 0.1324  data: 0.1186  max mem: 10802
Epoch: [1]  [ 300/4571]  eta: 0:09:25    time: 0.1325  data: 0.1190  max mem: 10802
Epoch: [1]  [ 320/4571]  eta: 0:09:22    time: 0.1328  data: 0.1186  max mem: 10802
Epoch: [1]  [ 340/4571]  eta: 0:09:19    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [1]  [ 360/4571]  eta: 0:09:17    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [1]  [ 380/4571]  eta: 0:09:14    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [1]  [ 400/4571]  eta: 0:09:12    time: 0.1323  data: 0.1188  max mem: 10802
Epoch: [1]  [ 420/4571]  eta: 0:09:09    time: 0.1323  data: 0.1213  max mem: 10802
Epoch: [1]  [ 440/4571]  eta: 0:09:06    time: 0.1325  data: 0.1187  max mem: 10802
Epoch: [1]  [ 460/4571]  eta: 0:09:04    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [ 480/4571]  eta: 0:09:01    time: 0.1324  data: 0.1186  max mem: 10802
Epoch: [1]  [ 500/4571]  eta: 0:08:58    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [ 520/4571]  eta: 0:08:56    time: 0.1325  data: 0.1186  max mem: 10802
Epoch: [1]  [ 540/4571]  eta: 0:08:53    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [1]  [ 560/4571]  eta: 0:08:50    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [1]  [ 580/4571]  eta: 0:08:48    time: 0.1326  data: 0.1182  max mem: 10802
Epoch: [1]  [ 600/4571]  eta: 0:08:45    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [1]  [ 620/4571]  eta: 0:08:42    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [1]  [ 640/4571]  eta: 0:08:40    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [ 660/4571]  eta: 0:08:37    time: 0.1324  data: 0.1215  max mem: 10802
Epoch: [1]  [ 680/4571]  eta: 0:08:35    time: 0.1323  data: 0.1215  max mem: 10802
Epoch: [1]  [ 700/4571]  eta: 0:08:32    time: 0.1325  data: 0.1182  max mem: 10802
Epoch: [1]  [ 720/4571]  eta: 0:08:29    time: 0.1325  data: 0.1237  max mem: 10802
Epoch: [1]  [ 740/4571]  eta: 0:08:27    time: 0.1325  data: 0.1188  max mem: 10802
Epoch: [1]  [ 760/4571]  eta: 0:08:24    time: 0.1326  data: 0.1189  max mem: 10802
Epoch: [1]  [ 780/4571]  eta: 0:08:21    time: 0.1323  data: 0.1189  max mem: 10802
Epoch: [1]  [ 800/4571]  eta: 0:08:19    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1]  [ 820/4571]  eta: 0:08:16    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [1]  [ 840/4571]  eta: 0:08:13    time: 0.1326  data: 0.1188  max mem: 10802
Epoch: [1]  [ 860/4571]  eta: 0:08:11    time: 0.1324  data: 0.1187  max mem: 10802
Epoch: [1]  [ 880/4571]  eta: 0:08:08    time: 0.1324  data: 0.1187  max mem: 10802
Epoch: [1]  [ 900/4571]  eta: 0:08:05    time: 0.1324  data: 0.1238  max mem: 10802
Epoch: [1]  [ 920/4571]  eta: 0:08:03    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1]  [ 940/4571]  eta: 0:08:00    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [ 960/4571]  eta: 0:07:58    time: 0.1323  data: 0.1232  max mem: 10802
Epoch: [1]  [ 980/4571]  eta: 0:07:55    time: 0.1322  data: 0.1182  max mem: 10802
Epoch: [1]  [1000/4571]  eta: 0:07:52    time: 0.1326  data: 0.1216  max mem: 10802
Epoch: [1]  [1020/4571]  eta: 0:07:50    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [1]  [1040/4571]  eta: 0:07:47    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [1]  [1060/4571]  eta: 0:07:44    time: 0.1352  data: 0.1243  max mem: 10802
Epoch: [1]  [1080/4571]  eta: 0:07:42    time: 0.1324  data: 0.1215  max mem: 10802
Epoch: [1]  [1100/4571]  eta: 0:07:39    time: 0.1323  data: 0.1213  max mem: 10802
Epoch: [1]  [1120/4571]  eta: 0:07:37    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1]  [1140/4571]  eta: 0:07:34    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [1]  [1160/4571]  eta: 0:07:31    time: 0.1325  data: 0.1191  max mem: 10802
Epoch: [1]  [1180/4571]  eta: 0:07:29    time: 0.1325  data: 0.1190  max mem: 10802
Epoch: [1]  [1200/4571]  eta: 0:07:26    time: 0.1326  data: 0.1239  max mem: 10802
Epoch: [1]  [1220/4571]  eta: 0:07:23    time: 0.1326  data: 0.1185  max mem: 10802
Epoch: [1]  [1240/4571]  eta: 0:07:21    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [1260/4571]  eta: 0:07:18    time: 0.1323  data: 0.1188  max mem: 10802
Epoch: [1]  [1280/4571]  eta: 0:07:15    time: 0.1324  data: 0.1190  max mem: 10802
Epoch: [1]  [1300/4571]  eta: 0:07:13    time: 0.1324  data: 0.1215  max mem: 10802
Epoch: [1]  [1320/4571]  eta: 0:07:10    time: 0.1326  data: 0.1190  max mem: 10802
Epoch: [1]  [1340/4571]  eta: 0:07:07    time: 0.1322  data: 0.1182  max mem: 10802
Epoch: [1]  [1360/4571]  eta: 0:07:05    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1]  [1380/4571]  eta: 0:07:02    time: 0.1324  data: 0.1237  max mem: 10802
Epoch: [1]  [1400/4571]  eta: 0:06:59    time: 0.1326  data: 0.1185  max mem: 10802
Epoch: [1]  [1420/4571]  eta: 0:06:57    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [1]  [1440/4571]  eta: 0:06:54    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [1460/4571]  eta: 0:06:52    time: 0.1335  data: 0.1194  max mem: 10802
Epoch: [1]  [1480/4571]  eta: 0:06:49    time: 0.1326  data: 0.1192  max mem: 10802
Epoch: [1]  [1500/4571]  eta: 0:06:46    time: 0.1322  data: 0.1214  max mem: 10802
Epoch: [1]  [1520/4571]  eta: 0:06:44    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [1540/4571]  eta: 0:06:41    time: 0.1326  data: 0.1188  max mem: 10802
Epoch: [1]  [1560/4571]  eta: 0:06:38    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1]  [1580/4571]  eta: 0:06:36    time: 0.1323  data: 0.1235  max mem: 10802
Epoch: [1]  [1600/4571]  eta: 0:06:33    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [1620/4571]  eta: 0:06:30    time: 0.1326  data: 0.1189  max mem: 10802
Epoch: [1]  [1640/4571]  eta: 0:06:28    time: 0.1324  data: 0.1232  max mem: 10802
Epoch: [1]  [1660/4571]  eta: 0:06:25    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [1]  [1680/4571]  eta: 0:06:22    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1]  [1700/4571]  eta: 0:06:20    time: 0.1327  data: 0.1240  max mem: 10802
Epoch: [1]  [1720/4571]  eta: 0:06:17    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [1]  [1740/4571]  eta: 0:06:14    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [1]  [1760/4571]  eta: 0:06:12    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [1]  [1780/4571]  eta: 0:06:09    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1]  [1800/4571]  eta: 0:06:06    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [1]  [1820/4571]  eta: 0:06:04    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [1]  [1840/4571]  eta: 0:06:01    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [1]  [1860/4571]  eta: 0:05:59    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [1]  [1880/4571]  eta: 0:05:56    time: 0.1325  data: 0.1181  max mem: 10802
Epoch: [1]  [1900/4571]  eta: 0:05:53    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [1]  [1920/4571]  eta: 0:05:51    time: 0.1325  data: 0.1217  max mem: 10802
Epoch: [1]  [1940/4571]  eta: 0:05:48    time: 0.1324  data: 0.1188  max mem: 10802
Epoch: [1]  [1960/4571]  eta: 0:05:45    time: 0.1322  data: 0.1187  max mem: 10802
Epoch: [1]  [1980/4571]  eta: 0:05:43    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [1]  [2000/4571]  eta: 0:05:40    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [2020/4571]  eta: 0:05:37    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [1]  [2040/4571]  eta: 0:05:35    time: 0.1324  data: 0.1215  max mem: 10802
Epoch: [1]  [2060/4571]  eta: 0:05:32    time: 0.1322  data: 0.1236  max mem: 10802
Epoch: [1]  [2080/4571]  eta: 0:05:29    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [2100/4571]  eta: 0:05:27    time: 0.1322  data: 0.1182  max mem: 10802
Epoch: [1]  [2120/4571]  eta: 0:05:24    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [2140/4571]  eta: 0:05:21    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [1]  [2160/4571]  eta: 0:05:19    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [1]  [2180/4571]  eta: 0:05:16    time: 0.1340  data: 0.1253  max mem: 10802
Epoch: [1]  [2200/4571]  eta: 0:05:14    time: 0.1322  data: 0.1182  max mem: 10802
Epoch: [1]  [2220/4571]  eta: 0:05:11    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [1]  [2240/4571]  eta: 0:05:08    time: 0.1323  data: 0.1185  max mem: 10802
Epoch: [1]  [2260/4571]  eta: 0:05:06    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [2280/4571]  eta: 0:05:03    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [1]  [2300/4571]  eta: 0:05:00    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [2320/4571]  eta: 0:04:58    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [2340/4571]  eta: 0:04:55    time: 0.1326  data: 0.1184  max mem: 10802
Epoch: [1]  [2360/4571]  eta: 0:04:52    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [2380/4571]  eta: 0:04:50    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [1]  [2400/4571]  eta: 0:04:47    time: 0.1322  data: 0.1231  max mem: 10802
Epoch: [1]  [2420/4571]  eta: 0:04:44    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [1]  [2440/4571]  eta: 0:04:42    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [1]  [2460/4571]  eta: 0:04:39    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [2480/4571]  eta: 0:04:36    time: 0.1327  data: 0.1189  max mem: 10802
Epoch: [1]  [2500/4571]  eta: 0:04:34    time: 0.1326  data: 0.1185  max mem: 10802
Epoch: [1]  [2520/4571]  eta: 0:04:31    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [1]  [2540/4571]  eta: 0:04:28    time: 0.1324  data: 0.1189  max mem: 10802
Epoch: [1]  [2560/4571]  eta: 0:04:26    time: 0.1323  data: 0.1216  max mem: 10802
Epoch: [1]  [2580/4571]  eta: 0:04:23    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [1]  [2600/4571]  eta: 0:04:20    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1]  [2620/4571]  eta: 0:04:18    time: 0.1337  data: 0.1202  max mem: 10802
Epoch: [1]  [2640/4571]  eta: 0:04:15    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [1]  [2660/4571]  eta: 0:04:13    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [1]  [2680/4571]  eta: 0:04:10    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [1]  [2700/4571]  eta: 0:04:07    time: 0.1321  data: 0.1234  max mem: 10802
Epoch: [1]  [2720/4571]  eta: 0:04:05    time: 0.1322  data: 0.1234  max mem: 10802
Epoch: [1]  [2740/4571]  eta: 0:04:02    time: 0.1324  data: 0.1184  max mem: 10802
Epoch: [1]  [2760/4571]  eta: 0:03:59    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [1]  [2780/4571]  eta: 0:03:57    time: 0.1338  data: 0.1229  max mem: 10802
Epoch: [1]  [2800/4571]  eta: 0:03:54    time: 0.1347  data: 0.1238  max mem: 10802
Epoch: [1]  [2820/4571]  eta: 0:03:51    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [1]  [2840/4571]  eta: 0:03:49    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [2860/4571]  eta: 0:03:46    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [2880/4571]  eta: 0:03:43    time: 0.1325  data: 0.1216  max mem: 10802
Epoch: [1]  [2900/4571]  eta: 0:03:41    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [2920/4571]  eta: 0:03:38    time: 0.1336  data: 0.1201  max mem: 10802
Epoch: [1]  [2940/4571]  eta: 0:03:36    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [1]  [2960/4571]  eta: 0:03:33    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [2980/4571]  eta: 0:03:30    time: 0.1323  data: 0.1216  max mem: 10802
Epoch: [1]  [3000/4571]  eta: 0:03:28    time: 0.1325  data: 0.1189  max mem: 10802
Epoch: [1]  [3020/4571]  eta: 0:03:25    time: 0.1327  data: 0.1218  max mem: 10802
Epoch: [1]  [3040/4571]  eta: 0:03:22    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [3060/4571]  eta: 0:03:20    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [3080/4571]  eta: 0:03:17    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [3100/4571]  eta: 0:03:14    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [1]  [3120/4571]  eta: 0:03:12    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [1]  [3140/4571]  eta: 0:03:09    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [3160/4571]  eta: 0:03:06    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [1]  [3180/4571]  eta: 0:03:04    time: 0.1324  data: 0.1237  max mem: 10802
Epoch: [1]  [3200/4571]  eta: 0:03:01    time: 0.1325  data: 0.1214  max mem: 10802
Epoch: [1]  [3220/4571]  eta: 0:02:58    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [3240/4571]  eta: 0:02:56    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [3260/4571]  eta: 0:02:53    time: 0.1324  data: 0.1215  max mem: 10802
Epoch: [1]  [3280/4571]  eta: 0:02:50    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [1]  [3300/4571]  eta: 0:02:48    time: 0.1325  data: 0.1190  max mem: 10802
Epoch: [1]  [3320/4571]  eta: 0:02:45    time: 0.1323  data: 0.1183  max mem: 10802
Epoch: [1]  [3340/4571]  eta: 0:02:43    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [1]  [3360/4571]  eta: 0:02:40    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [1]  [3380/4571]  eta: 0:02:37    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [1]  [3400/4571]  eta: 0:02:35    time: 0.1322  data: 0.1212  max mem: 10802
Epoch: [1]  [3420/4571]  eta: 0:02:32    time: 0.1321  data: 0.1235  max mem: 10802
Epoch: [1]  [3440/4571]  eta: 0:02:29    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [3460/4571]  eta: 0:02:27    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [1]  [3480/4571]  eta: 0:02:24    time: 0.1325  data: 0.1188  max mem: 10802
Epoch: [1]  [3500/4571]  eta: 0:02:21    time: 0.1323  data: 0.1215  max mem: 10802
Epoch: [1]  [3520/4571]  eta: 0:02:19    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [1]  [3540/4571]  eta: 0:02:16    time: 0.1324  data: 0.1185  max mem: 10802
Epoch: [1]  [3560/4571]  eta: 0:02:13    time: 0.1325  data: 0.1188  max mem: 10802
Epoch: [1]  [3580/4571]  eta: 0:02:11    time: 0.1341  data: 0.1254  max mem: 10802
Epoch: [1]  [3600/4571]  eta: 0:02:08    time: 0.1345  data: 0.1204  max mem: 10802
Epoch: [1]  [3620/4571]  eta: 0:02:05    time: 0.1324  data: 0.1181  max mem: 10802
Epoch: [1]  [3640/4571]  eta: 0:02:03    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1]  [3660/4571]  eta: 0:02:00    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [3680/4571]  eta: 0:01:58    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [3700/4571]  eta: 0:01:55    time: 0.1322  data: 0.1215  max mem: 10802
Epoch: [1]  [3720/4571]  eta: 0:01:52    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [3740/4571]  eta: 0:01:50    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [1]  [3760/4571]  eta: 0:01:47    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [3780/4571]  eta: 0:01:44    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [1]  [3800/4571]  eta: 0:01:42    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [3820/4571]  eta: 0:01:39    time: 0.1321  data: 0.1183  max mem: 10802
Epoch: [1]  [3840/4571]  eta: 0:01:36    time: 0.1322  data: 0.1214  max mem: 10802
Epoch: [1]  [3860/4571]  eta: 0:01:34    time: 0.1322  data: 0.1214  max mem: 10802
Epoch: [1]  [3880/4571]  eta: 0:01:31    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [3900/4571]  eta: 0:01:28    time: 0.1320  data: 0.1184  max mem: 10802
Epoch: [1]  [3920/4571]  eta: 0:01:26    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [3940/4571]  eta: 0:01:23    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [3960/4571]  eta: 0:01:20    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [1]  [3980/4571]  eta: 0:01:18    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [1]  [4000/4571]  eta: 0:01:15    time: 0.1322  data: 0.1184  max mem: 10802
Epoch: [1]  [4020/4571]  eta: 0:01:12    time: 0.1320  data: 0.1179  max mem: 10802
Epoch: [1]  [4040/4571]  eta: 0:01:10    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [1]  [4060/4571]  eta: 0:01:07    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [4080/4571]  eta: 0:01:05    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [1]  [4100/4571]  eta: 0:01:02    time: 0.1323  data: 0.1235  max mem: 10802
Epoch: [1]  [4120/4571]  eta: 0:00:59    time: 0.1325  data: 0.1182  max mem: 10802
Epoch: [1]  [4140/4571]  eta: 0:00:57    time: 0.1323  data: 0.1188  max mem: 10802
Epoch: [1]  [4160/4571]  eta: 0:00:54    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [1]  [4180/4571]  eta: 0:00:51    time: 0.1322  data: 0.1179  max mem: 10802
Epoch: [1]  [4200/4571]  eta: 0:00:49    time: 0.1321  data: 0.1233  max mem: 10802
Epoch: [1]  [4220/4571]  eta: 0:00:46    time: 0.1324  data: 0.1216  max mem: 10802
Epoch: [1]  [4240/4571]  eta: 0:00:43    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [1]  [4260/4571]  eta: 0:00:41    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [1]  [4280/4571]  eta: 0:00:38    time: 0.1326  data: 0.1185  max mem: 10802
Epoch: [1]  [4300/4571]  eta: 0:00:35    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1]  [4320/4571]  eta: 0:00:33    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [1]  [4340/4571]  eta: 0:00:30    time: 0.1323  data: 0.1215  max mem: 10802
Epoch: [1]  [4360/4571]  eta: 0:00:27    time: 0.1323  data: 0.1235  max mem: 10802
Epoch: [1]  [4380/4571]  eta: 0:00:25    time: 0.1322  data: 0.1187  max mem: 10802
Epoch: [1]  [4400/4571]  eta: 0:00:22    time: 0.1322  data: 0.1190  max mem: 10802
Epoch: [1]  [4420/4571]  eta: 0:00:19    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [1]  [4440/4571]  eta: 0:00:17    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [4460/4571]  eta: 0:00:14    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [1]  [4480/4571]  eta: 0:00:12    time: 0.1325  data: 0.1217  max mem: 10802
Epoch: [1]  [4500/4571]  eta: 0:00:09    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [1]  [4520/4571]  eta: 0:00:06    time: 0.1322  data: 0.1188  max mem: 10802
Epoch: [1]  [4540/4571]  eta: 0:00:04    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [1]  [4560/4571]  eta: 0:00:01    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [1]  [4570/4571]  eta: 0:00:00    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [1] Total time: 0:10:05 (0.1324 s / it)
:::MLLOG {"namespace": "", "time_ms": 1684346592391, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 332, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1684346592391, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 120.84755813840249}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 336, "step": 2}}
:::MLLOG {"namespace": "", "time_ms": 1684346592391, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 346, "epoch_num": 2}}
Test:  [ 0/97]  eta: 0:00:17  model_time: 0.1751 (0.1751)  evaluator_time: 0.0020 (0.0020)  time: 0.1779  data: 0.0007  max mem: 10802
Test:  [20/97]  eta: 0:00:14  model_time: 0.1770 (0.1763)  evaluator_time: 0.0021 (0.0049)  time: 0.1821  data: 0.0006  max mem: 10802
Test:  [40/97]  eta: 0:00:10  model_time: 0.1712 (0.1754)  evaluator_time: 0.0021 (0.0036)  time: 0.1772  data: 0.0006  max mem: 10802
Test:  [60/97]  eta: 0:00:06  model_time: 0.1748 (0.1752)  evaluator_time: 0.0021 (0.0031)  time: 0.1778  data: 0.0006  max mem: 10802
Test:  [80/97]  eta: 0:00:03  model_time: 0.1755 (0.1756)  evaluator_time: 0.0022 (0.0028)  time: 0.1795  data: 0.0006  max mem: 10802
Test:  [96/97]  eta: 0:00:00  model_time: 0.1799 (0.1759)  evaluator_time: 0.0021 (0.0027)  time: 0.1805  data: 0.0006  max mem: 10802
Test: Total time: 0:00:17 (0.1793 s / it)
Averaged stats: model_time: 0.1799 (0.1776)  evaluator_time: 0.0021 (0.0025)
:::MLLOG {"namespace": "", "time_ms": 1684346610483, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 161, "epoch_num": 2}}
Epoch: [2]  [   0/4572]  eta: 0:10:00    time: 0.1312  data: 0.0009  max mem: 10802
Epoch: [2]  [  20/4572]  eta: 0:10:00    time: 0.1320  data: 0.1183  max mem: 10802
Epoch: [2]  [  40/4572]  eta: 0:09:57    time: 0.1319  data: 0.1184  max mem: 10802
:::MLLOG {"namespace": "", "time_ms": 1684346616142, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3016901573008763, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 432, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1684346616142, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 433, "epoch_num": 2}}
Epoch: [2]  [  60/4572]  eta: 0:09:55    time: 0.1320  data: 0.1182  max mem: 10802
Epoch: [2]  [  80/4572]  eta: 0:09:53    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [2]  [ 100/4572]  eta: 0:09:50    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [2]  [ 120/4572]  eta: 0:09:47    time: 0.1320  data: 0.1186  max mem: 10802
Epoch: [2]  [ 140/4572]  eta: 0:09:45    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [2]  [ 160/4572]  eta: 0:09:42    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [2]  [ 180/4572]  eta: 0:09:40    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [2]  [ 200/4572]  eta: 0:09:37    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [2]  [ 220/4572]  eta: 0:09:34    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [2]  [ 240/4572]  eta: 0:09:32    time: 0.1324  data: 0.1216  max mem: 10802
Epoch: [2]  [ 260/4572]  eta: 0:09:29    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [ 280/4572]  eta: 0:09:27    time: 0.1321  data: 0.1234  max mem: 10802
Epoch: [2]  [ 300/4572]  eta: 0:09:24    time: 0.1320  data: 0.1233  max mem: 10802
Epoch: [2]  [ 320/4572]  eta: 0:09:21    time: 0.1320  data: 0.1185  max mem: 10802
Epoch: [2]  [ 340/4572]  eta: 0:09:19    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [ 360/4572]  eta: 0:09:16    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [2]  [ 380/4572]  eta: 0:09:13    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [2]  [ 400/4572]  eta: 0:09:11    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [2]  [ 420/4572]  eta: 0:09:08    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [2]  [ 440/4572]  eta: 0:09:06    time: 0.1324  data: 0.1184  max mem: 10802
Epoch: [2]  [ 460/4572]  eta: 0:09:03    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [ 480/4572]  eta: 0:09:00    time: 0.1322  data: 0.1234  max mem: 10802
Epoch: [2]  [ 500/4572]  eta: 0:08:58    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [2]  [ 520/4572]  eta: 0:08:55    time: 0.1326  data: 0.1216  max mem: 10802
Epoch: [2]  [ 540/4572]  eta: 0:08:52    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [2]  [ 560/4572]  eta: 0:08:50    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [ 580/4572]  eta: 0:08:47    time: 0.1320  data: 0.1180  max mem: 10802
Epoch: [2]  [ 600/4572]  eta: 0:08:45    time: 0.1324  data: 0.1216  max mem: 10802
Epoch: [2]  [ 620/4572]  eta: 0:08:42    time: 0.1323  data: 0.1213  max mem: 10802
Epoch: [2]  [ 640/4572]  eta: 0:08:39    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [2]  [ 660/4572]  eta: 0:08:37    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [2]  [ 680/4572]  eta: 0:08:34    time: 0.1322  data: 0.1183  max mem: 10802
Epoch: [2]  [ 700/4572]  eta: 0:08:31    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [ 720/4572]  eta: 0:08:29    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [ 740/4572]  eta: 0:08:26    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [ 760/4572]  eta: 0:08:23    time: 0.1320  data: 0.1179  max mem: 10802
Epoch: [2]  [ 780/4572]  eta: 0:08:21    time: 0.1321  data: 0.1234  max mem: 10802
Epoch: [2]  [ 800/4572]  eta: 0:08:18    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [ 820/4572]  eta: 0:08:15    time: 0.1324  data: 0.1189  max mem: 10802
Epoch: [2]  [ 840/4572]  eta: 0:08:13    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [2]  [ 860/4572]  eta: 0:08:10    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [2]  [ 880/4572]  eta: 0:08:08    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [ 900/4572]  eta: 0:08:05    time: 0.1322  data: 0.1182  max mem: 10802
Epoch: [2]  [ 920/4572]  eta: 0:08:02    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [ 940/4572]  eta: 0:08:00    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [ 960/4572]  eta: 0:07:57    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [2]  [ 980/4572]  eta: 0:07:54    time: 0.1324  data: 0.1186  max mem: 10802
Epoch: [2]  [1000/4572]  eta: 0:07:52    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [1020/4572]  eta: 0:07:49    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [2]  [1040/4572]  eta: 0:07:46    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [1060/4572]  eta: 0:07:44    time: 0.1322  data: 0.1212  max mem: 10802
Epoch: [2]  [1080/4572]  eta: 0:07:41    time: 0.1322  data: 0.1214  max mem: 10802
Epoch: [2]  [1100/4572]  eta: 0:07:38    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [2]  [1120/4572]  eta: 0:07:36    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [2]  [1140/4572]  eta: 0:07:33    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [2]  [1160/4572]  eta: 0:07:31    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [2]  [1180/4572]  eta: 0:07:28    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [1200/4572]  eta: 0:07:25    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [2]  [1220/4572]  eta: 0:07:23    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [2]  [1240/4572]  eta: 0:07:20    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [2]  [1260/4572]  eta: 0:07:17    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [2]  [1280/4572]  eta: 0:07:15    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [2]  [1300/4572]  eta: 0:07:12    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [2]  [1320/4572]  eta: 0:07:09    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [2]  [1340/4572]  eta: 0:07:07    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [1360/4572]  eta: 0:07:04    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [1380/4572]  eta: 0:07:01    time: 0.1321  data: 0.1234  max mem: 10802
Epoch: [2]  [1400/4572]  eta: 0:06:59    time: 0.1321  data: 0.1234  max mem: 10802
Epoch: [2]  [1420/4572]  eta: 0:06:56    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [1440/4572]  eta: 0:06:54    time: 0.1322  data: 0.1182  max mem: 10802
Epoch: [2]  [1460/4572]  eta: 0:06:51    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [2]  [1480/4572]  eta: 0:06:48    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [1500/4572]  eta: 0:06:46    time: 0.1322  data: 0.1187  max mem: 10802
Epoch: [2]  [1520/4572]  eta: 0:06:43    time: 0.1322  data: 0.1188  max mem: 10802
Epoch: [2]  [1540/4572]  eta: 0:06:40    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [2]  [1560/4572]  eta: 0:06:38    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [2]  [1580/4572]  eta: 0:06:35    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [1600/4572]  eta: 0:06:32    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [2]  [1620/4572]  eta: 0:06:30    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [2]  [1640/4572]  eta: 0:06:27    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [2]  [1660/4572]  eta: 0:06:24    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [1680/4572]  eta: 0:06:22    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [2]  [1700/4572]  eta: 0:06:19    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [2]  [1720/4572]  eta: 0:06:17    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [1740/4572]  eta: 0:06:14    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [1760/4572]  eta: 0:06:11    time: 0.1321  data: 0.1234  max mem: 10802
Epoch: [2]  [1780/4572]  eta: 0:06:09    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [2]  [1800/4572]  eta: 0:06:06    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [2]  [1820/4572]  eta: 0:06:03    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [1840/4572]  eta: 0:06:01    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [2]  [1860/4572]  eta: 0:05:58    time: 0.1322  data: 0.1231  max mem: 10802
Epoch: [2]  [1880/4572]  eta: 0:05:55    time: 0.1322  data: 0.1231  max mem: 10802
Epoch: [2]  [1900/4572]  eta: 0:05:53    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [2]  [1920/4572]  eta: 0:05:50    time: 0.1320  data: 0.1179  max mem: 10802
Epoch: [2]  [1940/4572]  eta: 0:05:47    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [2]  [1960/4572]  eta: 0:05:45    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [1980/4572]  eta: 0:05:42    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [2]  [2000/4572]  eta: 0:05:39    time: 0.1324  data: 0.1237  max mem: 10802
Epoch: [2]  [2020/4572]  eta: 0:05:37    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [2]  [2040/4572]  eta: 0:05:34    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [2]  [2060/4572]  eta: 0:05:32    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [2]  [2080/4572]  eta: 0:05:29    time: 0.1324  data: 0.1182  max mem: 10802
Epoch: [2]  [2100/4572]  eta: 0:05:26    time: 0.1322  data: 0.1214  max mem: 10802
Epoch: [2]  [2120/4572]  eta: 0:05:24    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [2]  [2140/4572]  eta: 0:05:21    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [2]  [2160/4572]  eta: 0:05:18    time: 0.1322  data: 0.1234  max mem: 10802
Epoch: [2]  [2180/4572]  eta: 0:05:16    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [2]  [2200/4572]  eta: 0:05:13    time: 0.1322  data: 0.1187  max mem: 10802
Epoch: [2]  [2220/4572]  eta: 0:05:10    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [2]  [2240/4572]  eta: 0:05:08    time: 0.1322  data: 0.1184  max mem: 10802
Epoch: [2]  [2260/4572]  eta: 0:05:05    time: 0.1324  data: 0.1184  max mem: 10802
Epoch: [2]  [2280/4572]  eta: 0:05:02    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [2]  [2300/4572]  eta: 0:05:00    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [2]  [2320/4572]  eta: 0:04:57    time: 0.1322  data: 0.1234  max mem: 10802
Epoch: [2]  [2340/4572]  eta: 0:04:55    time: 0.1323  data: 0.1188  max mem: 10802
Epoch: [2]  [2360/4572]  eta: 0:04:52    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [2]  [2380/4572]  eta: 0:04:49    time: 0.1320  data: 0.1180  max mem: 10802
Epoch: [2]  [2400/4572]  eta: 0:04:47    time: 0.1324  data: 0.1215  max mem: 10802
Epoch: [2]  [2420/4572]  eta: 0:04:44    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [2]  [2440/4572]  eta: 0:04:41    time: 0.1322  data: 0.1188  max mem: 10802
Epoch: [2]  [2460/4572]  eta: 0:04:39    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [2]  [2480/4572]  eta: 0:04:36    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [2500/4572]  eta: 0:04:33    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [2]  [2520/4572]  eta: 0:04:31    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [2540/4572]  eta: 0:04:28    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [2560/4572]  eta: 0:04:25    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [2]  [2580/4572]  eta: 0:04:23    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [2]  [2600/4572]  eta: 0:04:20    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [2]  [2620/4572]  eta: 0:04:18    time: 0.1323  data: 0.1216  max mem: 10802
Epoch: [2]  [2640/4572]  eta: 0:04:15    time: 0.1322  data: 0.1215  max mem: 10802
Epoch: [2]  [2660/4572]  eta: 0:04:12    time: 0.1322  data: 0.1212  max mem: 10802
Epoch: [2]  [2680/4572]  eta: 0:04:10    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [2700/4572]  eta: 0:04:07    time: 0.1324  data: 0.1232  max mem: 10802
Epoch: [2]  [2720/4572]  eta: 0:04:04    time: 0.1323  data: 0.1188  max mem: 10802
Epoch: [2]  [2740/4572]  eta: 0:04:02    time: 0.1322  data: 0.1187  max mem: 10802
Epoch: [2]  [2760/4572]  eta: 0:03:59    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [2780/4572]  eta: 0:03:56    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [2]  [2800/4572]  eta: 0:03:54    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [2]  [2820/4572]  eta: 0:03:51    time: 0.1322  data: 0.1212  max mem: 10802
Epoch: [2]  [2840/4572]  eta: 0:03:48    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [2]  [2860/4572]  eta: 0:03:46    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [2]  [2880/4572]  eta: 0:03:43    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [2900/4572]  eta: 0:03:41    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [2]  [2920/4572]  eta: 0:03:38    time: 0.1322  data: 0.1236  max mem: 10802
Epoch: [2]  [2940/4572]  eta: 0:03:35    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [2]  [2960/4572]  eta: 0:03:33    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [2]  [2980/4572]  eta: 0:03:30    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [3000/4572]  eta: 0:03:27    time: 0.1323  data: 0.1236  max mem: 10802
Epoch: [2]  [3020/4572]  eta: 0:03:25    time: 0.1323  data: 0.1236  max mem: 10802
Epoch: [2]  [3040/4572]  eta: 0:03:22    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [3060/4572]  eta: 0:03:19    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [2]  [3080/4572]  eta: 0:03:17    time: 0.1323  data: 0.1179  max mem: 10802
Epoch: [2]  [3100/4572]  eta: 0:03:14    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [3120/4572]  eta: 0:03:11    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [2]  [3140/4572]  eta: 0:03:09    time: 0.1320  data: 0.1180  max mem: 10802
Epoch: [2]  [3160/4572]  eta: 0:03:06    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [3180/4572]  eta: 0:03:04    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [2]  [3200/4572]  eta: 0:03:01    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [2]  [3220/4572]  eta: 0:02:58    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [2]  [3240/4572]  eta: 0:02:56    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [2]  [3260/4572]  eta: 0:02:53    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [2]  [3280/4572]  eta: 0:02:50    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [2]  [3300/4572]  eta: 0:02:48    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [2]  [3320/4572]  eta: 0:02:45    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [2]  [3340/4572]  eta: 0:02:42    time: 0.1323  data: 0.1235  max mem: 10802
Epoch: [2]  [3360/4572]  eta: 0:02:40    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [3380/4572]  eta: 0:02:37    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [2]  [3400/4572]  eta: 0:02:34    time: 0.1323  data: 0.1233  max mem: 10802
Epoch: [2]  [3420/4572]  eta: 0:02:32    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [2]  [3440/4572]  eta: 0:02:29    time: 0.1321  data: 0.1233  max mem: 10802
Epoch: [2]  [3460/4572]  eta: 0:02:27    time: 0.1325  data: 0.1183  max mem: 10802
Epoch: [2]  [3480/4572]  eta: 0:02:24    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [2]  [3500/4572]  eta: 0:02:21    time: 0.1324  data: 0.1188  max mem: 10802
Epoch: [2]  [3520/4572]  eta: 0:02:19    time: 0.1320  data: 0.1179  max mem: 10802
Epoch: [2]  [3540/4572]  eta: 0:02:16    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [2]  [3560/4572]  eta: 0:02:13    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [2]  [3580/4572]  eta: 0:02:11    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [2]  [3600/4572]  eta: 0:02:08    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [2]  [3620/4572]  eta: 0:02:05    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [3640/4572]  eta: 0:02:03    time: 0.1322  data: 0.1230  max mem: 10802
Epoch: [2]  [3660/4572]  eta: 0:02:00    time: 0.1321  data: 0.1187  max mem: 10802
Epoch: [2]  [3680/4572]  eta: 0:01:57    time: 0.1322  data: 0.1184  max mem: 10802
Epoch: [2]  [3700/4572]  eta: 0:01:55    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [2]  [3720/4572]  eta: 0:01:52    time: 0.1323  data: 0.1236  max mem: 10802
Epoch: [2]  [3740/4572]  eta: 0:01:49    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [3760/4572]  eta: 0:01:47    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [2]  [3780/4572]  eta: 0:01:44    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [2]  [3800/4572]  eta: 0:01:42    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [3820/4572]  eta: 0:01:39    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [2]  [3840/4572]  eta: 0:01:36    time: 0.1321  data: 0.1234  max mem: 10802
Epoch: [2]  [3860/4572]  eta: 0:01:34    time: 0.1323  data: 0.1180  max mem: 10802
Epoch: [2]  [3880/4572]  eta: 0:01:31    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [2]  [3900/4572]  eta: 0:01:28    time: 0.1322  data: 0.1187  max mem: 10802
Epoch: [2]  [3920/4572]  eta: 0:01:26    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [2]  [3940/4572]  eta: 0:01:23    time: 0.1321  data: 0.1230  max mem: 10802
Epoch: [2]  [3960/4572]  eta: 0:01:20    time: 0.1322  data: 0.1188  max mem: 10802
Epoch: [2]  [3980/4572]  eta: 0:01:18    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [2]  [4000/4572]  eta: 0:01:15    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [2]  [4020/4572]  eta: 0:01:12    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [2]  [4040/4572]  eta: 0:01:10    time: 0.1320  data: 0.1184  max mem: 10802
Epoch: [2]  [4060/4572]  eta: 0:01:07    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [4080/4572]  eta: 0:01:05    time: 0.1324  data: 0.1237  max mem: 10802
Epoch: [2]  [4100/4572]  eta: 0:01:02    time: 0.1323  data: 0.1188  max mem: 10802
Epoch: [2]  [4120/4572]  eta: 0:00:59    time: 0.1322  data: 0.1212  max mem: 10802
Epoch: [2]  [4140/4572]  eta: 0:00:57    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [2]  [4160/4572]  eta: 0:00:54    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [2]  [4180/4572]  eta: 0:00:51    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [4200/4572]  eta: 0:00:49    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [4220/4572]  eta: 0:00:46    time: 0.1323  data: 0.1183  max mem: 10802
Epoch: [2]  [4240/4572]  eta: 0:00:43    time: 0.1322  data: 0.1212  max mem: 10802
Epoch: [2]  [4260/4572]  eta: 0:00:41    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [2]  [4280/4572]  eta: 0:00:38    time: 0.1322  data: 0.1187  max mem: 10802
Epoch: [2]  [4300/4572]  eta: 0:00:35    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [2]  [4320/4572]  eta: 0:00:33    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [2]  [4340/4572]  eta: 0:00:30    time: 0.1323  data: 0.1215  max mem: 10802
Epoch: [2]  [4360/4572]  eta: 0:00:28    time: 0.1324  data: 0.1188  max mem: 10802
Epoch: [2]  [4380/4572]  eta: 0:00:25    time: 0.1324  data: 0.1216  max mem: 10802
Epoch: [2]  [4400/4572]  eta: 0:00:22    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [2]  [4420/4572]  eta: 0:00:20    time: 0.1320  data: 0.1184  max mem: 10802
Epoch: [2]  [4440/4572]  eta: 0:00:17    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [2]  [4460/4572]  eta: 0:00:14    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [2]  [4480/4572]  eta: 0:00:12    time: 0.1321  data: 0.1213  max mem: 10802
Epoch: [2]  [4500/4572]  eta: 0:00:09    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [2]  [4520/4572]  eta: 0:00:06    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [2]  [4540/4572]  eta: 0:00:04    time: 0.1322  data: 0.1182  max mem: 10802
Epoch: [2]  [4560/4572]  eta: 0:00:01    time: 0.1323  data: 0.1216  max mem: 10802
Epoch: [2]  [4571/4572]  eta: 0:00:00    time: 0.1321  data: 0.1213  max mem: 10802
Epoch: [2] Total time: 0:10:04 (0.1322 s / it)
:::MLLOG {"namespace": "", "time_ms": 1684347215052, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 332, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1684347215052, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 121.02948769563251}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 336, "step": 3}}
:::MLLOG {"namespace": "", "time_ms": 1684347215053, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 346, "epoch_num": 3}}
Test:  [ 0/97]  eta: 0:00:16  model_time: 0.1659 (0.1659)  evaluator_time: 0.0018 (0.0018)  time: 0.1684  data: 0.0007  max mem: 10802
Test:  [20/97]  eta: 0:00:13  model_time: 0.1643 (0.1666)  evaluator_time: 0.0018 (0.0019)  time: 0.1693  data: 0.0006  max mem: 10802
Test:  [40/97]  eta: 0:00:09  model_time: 0.1660 (0.1658)  evaluator_time: 0.0019 (0.0031)  time: 0.1702  data: 0.0006  max mem: 10802
Test:  [60/97]  eta: 0:00:06  model_time: 0.1721 (0.1661)  evaluator_time: 0.0019 (0.0027)  time: 0.1693  data: 0.0006  max mem: 10802
Test:  [80/97]  eta: 0:00:02  model_time: 0.1692 (0.1661)  evaluator_time: 0.0020 (0.0025)  time: 0.1687  data: 0.0006  max mem: 10802
Test:  [96/97]  eta: 0:00:00  model_time: 0.1691 (0.1655)  evaluator_time: 0.0018 (0.0024)  time: 0.1657  data: 0.0006  max mem: 10802
Test: Total time: 0:00:16 (0.1687 s / it)
Averaged stats: model_time: 0.1691 (0.1672)  evaluator_time: 0.0018 (0.0024)
:::MLLOG {"namespace": "", "time_ms": 1684347232090, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 161, "epoch_num": 3}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [3]  [   0/4571]  eta: 0:09:58    time: 0.1310  data: 0.0009  max mem: 10802
Epoch: [3]  [  20/4571]  eta: 0:09:59    time: 0.1318  data: 0.1210  max mem: 10802
:::MLLOG {"namespace": "", "time_ms": 1684347237214, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.33341076326913427, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 432, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1684347237214, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 433, "epoch_num": 3}}
Epoch: [3]  [  40/4571]  eta: 0:09:57    time: 0.1320  data: 0.1168  max mem: 10802
Epoch: [3]  [  60/4571]  eta: 0:09:54    time: 0.1319  data: 0.1182  max mem: 10802
Epoch: [3]  [  80/4571]  eta: 0:09:52    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [ 100/4571]  eta: 0:09:49    time: 0.1319  data: 0.1210  max mem: 10802
Epoch: [3]  [ 120/4571]  eta: 0:09:47    time: 0.1326  data: 0.1218  max mem: 10802
Epoch: [3]  [ 140/4571]  eta: 0:09:45    time: 0.1320  data: 0.1183  max mem: 10802
Epoch: [3]  [ 160/4571]  eta: 0:09:42    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [3]  [ 180/4571]  eta: 0:09:40    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [3]  [ 200/4571]  eta: 0:09:37    time: 0.1321  data: 0.1230  max mem: 10802
Epoch: [3]  [ 220/4571]  eta: 0:09:34    time: 0.1321  data: 0.1182  max mem: 10802
Epoch: [3]  [ 240/4571]  eta: 0:09:32    time: 0.1320  data: 0.1180  max mem: 10802
Epoch: [3]  [ 260/4571]  eta: 0:09:29    time: 0.1320  data: 0.1178  max mem: 10802
Epoch: [3]  [ 280/4571]  eta: 0:09:26    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [3]  [ 300/4571]  eta: 0:09:24    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [ 320/4571]  eta: 0:09:21    time: 0.1320  data: 0.1212  max mem: 10802
Epoch: [3]  [ 340/4571]  eta: 0:09:18    time: 0.1320  data: 0.1211  max mem: 10802
Epoch: [3]  [ 360/4571]  eta: 0:09:16    time: 0.1321  data: 0.1182  max mem: 10802
Epoch: [3]  [ 380/4571]  eta: 0:09:13    time: 0.1320  data: 0.1179  max mem: 10802
Epoch: [3]  [ 400/4571]  eta: 0:09:10    time: 0.1320  data: 0.1213  max mem: 10802
Epoch: [3]  [ 420/4571]  eta: 0:09:08    time: 0.1323  data: 0.1213  max mem: 10802
Epoch: [3]  [ 440/4571]  eta: 0:09:05    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [ 460/4571]  eta: 0:09:03    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [ 480/4571]  eta: 0:09:00    time: 0.1341  data: 0.1201  max mem: 10802
Epoch: [3]  [ 500/4571]  eta: 0:08:58    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [ 520/4571]  eta: 0:08:55    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [3]  [ 540/4571]  eta: 0:08:52    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [3]  [ 560/4571]  eta: 0:08:50    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [3]  [ 580/4571]  eta: 0:08:47    time: 0.1326  data: 0.1185  max mem: 10802
Epoch: [3]  [ 600/4571]  eta: 0:08:44    time: 0.1324  data: 0.1233  max mem: 10802
Epoch: [3]  [ 620/4571]  eta: 0:08:42    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [3]  [ 640/4571]  eta: 0:08:39    time: 0.1324  data: 0.1215  max mem: 10802
Epoch: [3]  [ 660/4571]  eta: 0:08:37    time: 0.1325  data: 0.1185  max mem: 10802
Epoch: [3]  [ 680/4571]  eta: 0:08:34    time: 0.1321  data: 0.1213  max mem: 10802
Epoch: [3]  [ 700/4571]  eta: 0:08:31    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [3]  [ 720/4571]  eta: 0:08:29    time: 0.1323  data: 0.1190  max mem: 10802
Epoch: [3]  [ 740/4571]  eta: 0:08:26    time: 0.1323  data: 0.1185  max mem: 10802
Epoch: [3]  [ 760/4571]  eta: 0:08:23    time: 0.1320  data: 0.1211  max mem: 10802
Epoch: [3]  [ 780/4571]  eta: 0:08:21    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [3]  [ 800/4571]  eta: 0:08:18    time: 0.1320  data: 0.1183  max mem: 10802
Epoch: [3]  [ 820/4571]  eta: 0:08:15    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [3]  [ 840/4571]  eta: 0:08:13    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [ 860/4571]  eta: 0:08:10    time: 0.1323  data: 0.1215  max mem: 10802
Epoch: [3]  [ 880/4571]  eta: 0:08:08    time: 0.1324  data: 0.1183  max mem: 10802
Epoch: [3]  [ 900/4571]  eta: 0:08:05    time: 0.1320  data: 0.1184  max mem: 10802
Epoch: [3]  [ 920/4571]  eta: 0:08:02    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [ 940/4571]  eta: 0:08:00    time: 0.1321  data: 0.1213  max mem: 10802
Epoch: [3]  [ 960/4571]  eta: 0:07:57    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [3]  [ 980/4571]  eta: 0:07:54    time: 0.1320  data: 0.1213  max mem: 10802
Epoch: [3]  [1000/4571]  eta: 0:07:52    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [1020/4571]  eta: 0:07:49    time: 0.1321  data: 0.1183  max mem: 10802
Epoch: [3]  [1040/4571]  eta: 0:07:46    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [1060/4571]  eta: 0:07:44    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [1080/4571]  eta: 0:07:41    time: 0.1339  data: 0.1252  max mem: 10802
Epoch: [3]  [1100/4571]  eta: 0:07:38    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [3]  [1120/4571]  eta: 0:07:36    time: 0.1320  data: 0.1233  max mem: 10802
Epoch: [3]  [1140/4571]  eta: 0:07:33    time: 0.1322  data: 0.1231  max mem: 10802
Epoch: [3]  [1160/4571]  eta: 0:07:31    time: 0.1321  data: 0.1182  max mem: 10802
Epoch: [3]  [1180/4571]  eta: 0:07:28    time: 0.1322  data: 0.1214  max mem: 10802
Epoch: [3]  [1200/4571]  eta: 0:07:25    time: 0.1320  data: 0.1183  max mem: 10802
Epoch: [3]  [1220/4571]  eta: 0:07:23    time: 0.1322  data: 0.1235  max mem: 10802
Epoch: [3]  [1240/4571]  eta: 0:07:20    time: 0.1322  data: 0.1182  max mem: 10802
Epoch: [3]  [1260/4571]  eta: 0:07:17    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [3]  [1280/4571]  eta: 0:07:15    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [1300/4571]  eta: 0:07:12    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [3]  [1320/4571]  eta: 0:07:09    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [3]  [1340/4571]  eta: 0:07:07    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [1360/4571]  eta: 0:07:04    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [1380/4571]  eta: 0:07:01    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [3]  [1400/4571]  eta: 0:06:59    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [3]  [1420/4571]  eta: 0:06:56    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [3]  [1440/4571]  eta: 0:06:53    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [1460/4571]  eta: 0:06:51    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [1480/4571]  eta: 0:06:48    time: 0.1325  data: 0.1184  max mem: 10802
Epoch: [3]  [1500/4571]  eta: 0:06:46    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [1520/4571]  eta: 0:06:43    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [1540/4571]  eta: 0:06:40    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [1560/4571]  eta: 0:06:38    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [3]  [1580/4571]  eta: 0:06:35    time: 0.1321  data: 0.1213  max mem: 10802
Epoch: [3]  [1600/4571]  eta: 0:06:32    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [3]  [1620/4571]  eta: 0:06:30    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [3]  [1640/4571]  eta: 0:06:27    time: 0.1323  data: 0.1180  max mem: 10802
Epoch: [3]  [1660/4571]  eta: 0:06:24    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [3]  [1680/4571]  eta: 0:06:22    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [1700/4571]  eta: 0:06:19    time: 0.1322  data: 0.1183  max mem: 10802
Epoch: [3]  [1720/4571]  eta: 0:06:16    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [3]  [1740/4571]  eta: 0:06:14    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [3]  [1760/4571]  eta: 0:06:11    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [3]  [1780/4571]  eta: 0:06:08    time: 0.1320  data: 0.1185  max mem: 10802
Epoch: [3]  [1800/4571]  eta: 0:06:06    time: 0.1320  data: 0.1232  max mem: 10802
Epoch: [3]  [1820/4571]  eta: 0:06:03    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [1840/4571]  eta: 0:06:01    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [3]  [1860/4571]  eta: 0:05:58    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [3]  [1880/4571]  eta: 0:05:55    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [1900/4571]  eta: 0:05:53    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [1920/4571]  eta: 0:05:50    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [1940/4571]  eta: 0:05:47    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [1960/4571]  eta: 0:05:45    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [1980/4571]  eta: 0:05:42    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [2000/4571]  eta: 0:05:39    time: 0.1322  data: 0.1184  max mem: 10802
Epoch: [3]  [2020/4571]  eta: 0:05:37    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [2040/4571]  eta: 0:05:34    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [2060/4571]  eta: 0:05:31    time: 0.1322  data: 0.1182  max mem: 10802
Epoch: [3]  [2080/4571]  eta: 0:05:29    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [2100/4571]  eta: 0:05:26    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [3]  [2120/4571]  eta: 0:05:24    time: 0.1323  data: 0.1188  max mem: 10802
Epoch: [3]  [2140/4571]  eta: 0:05:21    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [3]  [2160/4571]  eta: 0:05:18    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [3]  [2180/4571]  eta: 0:05:16    time: 0.1321  data: 0.1213  max mem: 10802
Epoch: [3]  [2200/4571]  eta: 0:05:13    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [2220/4571]  eta: 0:05:10    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [3]  [2240/4571]  eta: 0:05:08    time: 0.1322  data: 0.1184  max mem: 10802
Epoch: [3]  [2260/4571]  eta: 0:05:05    time: 0.1321  data: 0.1214  max mem: 10802
Epoch: [3]  [2280/4571]  eta: 0:05:02    time: 0.1321  data: 0.1234  max mem: 10802
Epoch: [3]  [2300/4571]  eta: 0:05:00    time: 0.1323  data: 0.1215  max mem: 10802
Epoch: [3]  [2320/4571]  eta: 0:04:57    time: 0.1323  data: 0.1183  max mem: 10802
Epoch: [3]  [2340/4571]  eta: 0:04:54    time: 0.1321  data: 0.1213  max mem: 10802
Epoch: [3]  [2360/4571]  eta: 0:04:52    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [3]  [2380/4571]  eta: 0:04:49    time: 0.1320  data: 0.1179  max mem: 10802
Epoch: [3]  [2400/4571]  eta: 0:04:46    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [2420/4571]  eta: 0:04:44    time: 0.1323  data: 0.1215  max mem: 10802
Epoch: [3]  [2440/4571]  eta: 0:04:41    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [3]  [2460/4571]  eta: 0:04:39    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [2480/4571]  eta: 0:04:36    time: 0.1320  data: 0.1184  max mem: 10802
Epoch: [3]  [2500/4571]  eta: 0:04:33    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [3]  [2520/4571]  eta: 0:04:31    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [3]  [2540/4571]  eta: 0:04:28    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [3]  [2560/4571]  eta: 0:04:25    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [2580/4571]  eta: 0:04:23    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [2600/4571]  eta: 0:04:20    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [2620/4571]  eta: 0:04:17    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [3]  [2640/4571]  eta: 0:04:15    time: 0.1323  data: 0.1181  max mem: 10802
Epoch: [3]  [2660/4571]  eta: 0:04:12    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [3]  [2680/4571]  eta: 0:04:09    time: 0.1322  data: 0.1214  max mem: 10802
Epoch: [3]  [2700/4571]  eta: 0:04:07    time: 0.1320  data: 0.1179  max mem: 10802
Epoch: [3]  [2720/4571]  eta: 0:04:04    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [3]  [2740/4571]  eta: 0:04:02    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [3]  [2760/4571]  eta: 0:03:59    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [3]  [2780/4571]  eta: 0:03:56    time: 0.1322  data: 0.1212  max mem: 10802
Epoch: [3]  [2800/4571]  eta: 0:03:54    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [2820/4571]  eta: 0:03:51    time: 0.1320  data: 0.1183  max mem: 10802
Epoch: [3]  [2840/4571]  eta: 0:03:48    time: 0.1322  data: 0.1234  max mem: 10802
Epoch: [3]  [2860/4571]  eta: 0:03:46    time: 0.1327  data: 0.1186  max mem: 10802
Epoch: [3]  [2880/4571]  eta: 0:03:43    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [3]  [2900/4571]  eta: 0:03:40    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [2920/4571]  eta: 0:03:38    time: 0.1321  data: 0.1187  max mem: 10802
Epoch: [3]  [2940/4571]  eta: 0:03:35    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [3]  [2960/4571]  eta: 0:03:32    time: 0.1320  data: 0.1179  max mem: 10802
Epoch: [3]  [2980/4571]  eta: 0:03:30    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [3]  [3000/4571]  eta: 0:03:27    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [3020/4571]  eta: 0:03:25    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [3]  [3040/4571]  eta: 0:03:22    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [3]  [3060/4571]  eta: 0:03:19    time: 0.1319  data: 0.1179  max mem: 10802
Epoch: [3]  [3080/4571]  eta: 0:03:17    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [3]  [3100/4571]  eta: 0:03:14    time: 0.1320  data: 0.1180  max mem: 10802
Epoch: [3]  [3120/4571]  eta: 0:03:11    time: 0.1318  data: 0.1233  max mem: 10802
Epoch: [3]  [3140/4571]  eta: 0:03:09    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [3160/4571]  eta: 0:03:06    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [3180/4571]  eta: 0:03:03    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [3200/4571]  eta: 0:03:01    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [3220/4571]  eta: 0:02:58    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [3240/4571]  eta: 0:02:55    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [3260/4571]  eta: 0:02:53    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [3]  [3280/4571]  eta: 0:02:50    time: 0.1321  data: 0.1213  max mem: 10802
Epoch: [3]  [3300/4571]  eta: 0:02:48    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [3320/4571]  eta: 0:02:45    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [3]  [3340/4571]  eta: 0:02:42    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [3360/4571]  eta: 0:02:40    time: 0.1322  data: 0.1214  max mem: 10802
Epoch: [3]  [3380/4571]  eta: 0:02:37    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [3]  [3400/4571]  eta: 0:02:34    time: 0.1320  data: 0.1211  max mem: 10802
Epoch: [3]  [3420/4571]  eta: 0:02:32    time: 0.1322  data: 0.1185  max mem: 10802
Epoch: [3]  [3440/4571]  eta: 0:02:29    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [3]  [3460/4571]  eta: 0:02:26    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [3]  [3480/4571]  eta: 0:02:24    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [3500/4571]  eta: 0:02:21    time: 0.1321  data: 0.1233  max mem: 10802
Epoch: [3]  [3520/4571]  eta: 0:02:18    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [3]  [3540/4571]  eta: 0:02:16    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [3560/4571]  eta: 0:02:13    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [3]  [3580/4571]  eta: 0:02:10    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [3600/4571]  eta: 0:02:08    time: 0.1320  data: 0.1233  max mem: 10802
Epoch: [3]  [3620/4571]  eta: 0:02:05    time: 0.1325  data: 0.1188  max mem: 10802
Epoch: [3]  [3640/4571]  eta: 0:02:03    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [3]  [3660/4571]  eta: 0:02:00    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [3]  [3680/4571]  eta: 0:01:57    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [3700/4571]  eta: 0:01:55    time: 0.1321  data: 0.1213  max mem: 10802
Epoch: [3]  [3720/4571]  eta: 0:01:52    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [3]  [3740/4571]  eta: 0:01:49    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [3760/4571]  eta: 0:01:47    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [3]  [3780/4571]  eta: 0:01:44    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [3]  [3800/4571]  eta: 0:01:41    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [3]  [3820/4571]  eta: 0:01:39    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [3]  [3840/4571]  eta: 0:01:36    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [3860/4571]  eta: 0:01:33    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [3]  [3880/4571]  eta: 0:01:31    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [3900/4571]  eta: 0:01:28    time: 0.1322  data: 0.1214  max mem: 10802
Epoch: [3]  [3920/4571]  eta: 0:01:26    time: 0.1321  data: 0.1181  max mem: 10802
Epoch: [3]  [3940/4571]  eta: 0:01:23    time: 0.1320  data: 0.1179  max mem: 10802
Epoch: [3]  [3960/4571]  eta: 0:01:20    time: 0.1322  data: 0.1230  max mem: 10802
Epoch: [3]  [3980/4571]  eta: 0:01:18    time: 0.1321  data: 0.1184  max mem: 10802
Epoch: [3]  [4000/4571]  eta: 0:01:15    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [4020/4571]  eta: 0:01:12    time: 0.1321  data: 0.1183  max mem: 10802
Epoch: [3]  [4040/4571]  eta: 0:01:10    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [3]  [4060/4571]  eta: 0:01:07    time: 0.1323  data: 0.1186  max mem: 10802
Epoch: [3]  [4080/4571]  eta: 0:01:04    time: 0.1322  data: 0.1214  max mem: 10802
Epoch: [3]  [4100/4571]  eta: 0:01:02    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [3]  [4120/4571]  eta: 0:00:59    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [3]  [4140/4571]  eta: 0:00:56    time: 0.1322  data: 0.1186  max mem: 10802
Epoch: [3]  [4160/4571]  eta: 0:00:54    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [3]  [4180/4571]  eta: 0:00:51    time: 0.1323  data: 0.1214  max mem: 10802
Epoch: [3]  [4200/4571]  eta: 0:00:49    time: 0.1321  data: 0.1212  max mem: 10802
Epoch: [3]  [4220/4571]  eta: 0:00:46    time: 0.1321  data: 0.1179  max mem: 10802
Epoch: [3]  [4240/4571]  eta: 0:00:43    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [3]  [4260/4571]  eta: 0:00:41    time: 0.1324  data: 0.1214  max mem: 10802
Epoch: [3]  [4280/4571]  eta: 0:00:38    time: 0.1321  data: 0.1234  max mem: 10802
Epoch: [3]  [4300/4571]  eta: 0:00:35    time: 0.1321  data: 0.1186  max mem: 10802
Epoch: [3]  [4320/4571]  eta: 0:00:33    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [4340/4571]  eta: 0:00:30    time: 0.1322  data: 0.1181  max mem: 10802
Epoch: [3]  [4360/4571]  eta: 0:00:27    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [4380/4571]  eta: 0:00:25    time: 0.1323  data: 0.1187  max mem: 10802
Epoch: [3]  [4400/4571]  eta: 0:00:22    time: 0.1322  data: 0.1187  max mem: 10802
Epoch: [3]  [4420/4571]  eta: 0:00:19    time: 0.1322  data: 0.1180  max mem: 10802
Epoch: [3]  [4440/4571]  eta: 0:00:17    time: 0.1321  data: 0.1235  max mem: 10802
Epoch: [3]  [4460/4571]  eta: 0:00:14    time: 0.1322  data: 0.1213  max mem: 10802
Epoch: [3]  [4480/4571]  eta: 0:00:12    time: 0.1320  data: 0.1184  max mem: 10802
Epoch: [3]  [4500/4571]  eta: 0:00:09    time: 0.1323  data: 0.1182  max mem: 10802
Epoch: [3]  [4520/4571]  eta: 0:00:06    time: 0.1321  data: 0.1185  max mem: 10802
Epoch: [3]  [4540/4571]  eta: 0:00:04    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [4560/4571]  eta: 0:00:01    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3]  [4570/4571]  eta: 0:00:00    time: 0.1321  data: 0.1180  max mem: 10802
Epoch: [3] Total time: 0:10:04 (0.1321 s / it)
:::MLLOG {"namespace": "", "time_ms": 1684347836393, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 332, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1684347836393, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 121.07785026677514}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 336, "step": 4}}
:::MLLOG {"namespace": "", "time_ms": 1684347836393, "event_type": "INTERVAL_START", "key": "eval_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 346, "epoch_num": 4}}
Test:  [ 0/97]  eta: 0:00:15  model_time: 0.1566 (0.1566)  evaluator_time: 0.0016 (0.0016)  time: 0.1590  data: 0.0007  max mem: 10802
Test:  [20/97]  eta: 0:00:12  model_time: 0.1566 (0.1596)  evaluator_time: 0.0017 (0.0017)  time: 0.1622  data: 0.0006  max mem: 10802
Test:  [40/97]  eta: 0:00:09  model_time: 0.1649 (0.1617)  evaluator_time: 0.0018 (0.0018)  time: 0.1664  data: 0.0006  max mem: 10802
Test:  [60/97]  eta: 0:00:06  model_time: 0.1617 (0.1617)  evaluator_time: 0.0016 (0.0018)  time: 0.1642  data: 0.0006  max mem: 10802
Test:  [80/97]  eta: 0:00:02  model_time: 0.1623 (0.1620)  evaluator_time: 0.0018 (0.0018)  time: 0.1655  data: 0.0006  max mem: 10802
Test:  [96/97]  eta: 0:00:00  model_time: 0.1611 (0.1616)  evaluator_time: 0.0017 (0.0017)  time: 0.1626  data: 0.0006  max mem: 10802
Test: Total time: 0:00:15 (0.1641 s / it)
Averaged stats: model_time: 0.1611 (0.1637)  evaluator_time: 0.0017 (0.0021)
:::MLLOG {"namespace": "", "time_ms": 1684347853040, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 161, "epoch_num": 4}}
Epoch: [4]  [   0/4572]  eta: 0:09:59    time: 0.1311  data: 0.0008  max mem: 10802
Epoch: [4]  [  20/4572]  eta: 0:10:00    time: 0.1320  data: 0.1210  max mem: 10802
:::MLLOG {"namespace": "", "time_ms": 1684347857637, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.34832865533296387, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 432, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1684347857638, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 433, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1684347858454, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 332, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1684347858454, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 124.86944563102817}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 336, "step": 5}}
:::MLLOG {"namespace": "", "time_ms": 1684347858455, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "train.py", "lineno": 698, "status": "success"}}
Training time 0:41:37
:::MLLOG {"namespace": "", "time_ms": 1684347858455, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684347858455, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684347858455, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684347858455, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684347858454, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684347858455, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684347858454, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684347858454, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684347858456, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684347858456, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684347858456, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684347858456, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684347858457, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684347858456, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684347858457, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
:::MLLOG {"namespace": "", "time_ms": 1684347858466, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "train.py", "lineno": 702}}
Loading annotations into memory...
Done (t=0.69s)
Creating index...
Done (t=0.96s)
Loading and preparing results...
DONE (t=2.84s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.26s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.24442
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.37574
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.26047
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00682
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.05835
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.26991
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.35938
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.51357
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.53720
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.02558
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.20624
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.58565
Loading and preparing results...
DONE (t=2.78s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.41s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.30169
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.44338
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.32438
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00725
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.08286
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.33396
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.38880
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.55615
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.58310
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03380
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23818
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.63412
Loading and preparing results...
DONE (t=2.42s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.31s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33341
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.47957
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.36009
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00941
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.09409
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.36807
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.39764
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.57137
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.59985
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03396
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.25314
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.65164
Loading and preparing results...
DONE (t=2.26s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.11s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34833
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.49119
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.37531
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.01062
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.09274
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.38582
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.41214
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.58592
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.61340
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03781
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.26535
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.66496
/usr/local/lib/python3.8/dist-packages/torch/jit/annotations.py:310: UserWarning: TorchScript will treat type annotations of Tensor dtype-specific subtypes as if they are normal Tensors. dtype constraints are not enforced in compilation either.
  warnings.warn("TorchScript will treat type annotations of Tensor "
/usr/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 5 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
ENDING TIMING RUN AT 2023-05-17 06:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,2599,nvidia,2023-05-17 05:41:04 PM
ENDING TIMING RUN AT 2023-05-17 06:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,2599,nvidia,2023-05-17 05:41:04 PM
ENDING TIMING RUN AT 2023-05-17 06:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,2597,nvidia,2023-05-17 05:41:06 PM
ENDING TIMING RUN AT 2023-05-17 06:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,2598,nvidia,2023-05-17 05:41:05 PM
ENDING TIMING RUN AT 2023-05-17 06:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,2598,nvidia,2023-05-17 05:41:05 PM
ENDING TIMING RUN AT 2023-05-17 06:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,2598,nvidia,2023-05-17 05:41:05 PM
ENDING TIMING RUN AT 2023-05-17 06:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,2598,nvidia,2023-05-17 05:41:05 PM
ENDING TIMING RUN AT 2023-05-17 06:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,2598,nvidia,2023-05-17 05:41:05 PM
ENDING TIMING RUN AT 2023-05-17 06:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,2599,nvidia,2023-05-17 05:41:04 PM
ENDING TIMING RUN AT 2023-05-17 06:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,2599,nvidia,2023-05-17 05:41:04 PM
ENDING TIMING RUN AT 2023-05-17 06:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,2598,nvidia,2023-05-17 05:41:05 PM
ENDING TIMING RUN AT 2023-05-17 06:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,2598,nvidia,2023-05-17 05:41:05 PM
ENDING TIMING RUN AT 2023-05-17 06:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,2598,nvidia,2023-05-17 05:41:05 PM
ENDING TIMING RUN AT 2023-05-17 06:24:23 PM
RESULT,SINGLE_STAGE_DETECTOR,,2597,nvidia,2023-05-17 05:41:06 PM
ENDING TIMING RUN AT 2023-05-17 06:24:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,2599,nvidia,2023-05-17 05:41:05 PM
ENDING TIMING RUN AT 2023-05-17 06:24:24 PM
RESULT,SINGLE_STAGE_DETECTOR,,2599,nvidia,2023-05-17 05:41:05 PM
