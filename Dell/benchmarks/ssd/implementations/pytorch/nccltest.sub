#!/bin/bash

# Copyright (c) 2021-2022, NVIDIA CORPORATION. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Script for separately running NCCL allreduce test with the total size of the RetinaNet parameters.

# Example:
# unset DGXNNODES DGXNGPU && export DGXNNODES=8 DGXNGPU=8 && SBATCH_NETWORK=sharp \
# CONT=gitlab-master.nvidia.com/dl/dgx/pytorch:master-py3-devel sbatch --nodes ${DGXNNODES} \
# -J mlperft-ssd.retinanet_devel_nccltest_sharp --ntasks-per-node=${DGXNGPU} -p viking-hbm3 \
# --account mlperft --output=retinanet_devel_nccltest_sharp.run.000 -t 10 nccltest.sub

set -euxo pipefail

: "${CONT:?CONT not set}"
: "${CONT_NAME:=single_stage_detector}"

# Setup container
echo MELLANOX_VISIBLE_DEVICES="${MELLANOX_VISIBLE_DEVICES:-}"
srun \
    --ntasks="${SLURM_JOB_NUM_NODES}" \
    --container-image="${CONT}" \
    --container-name="${CONT_NAME}" \
    true
srun -N1 -n1 --container-name="${CONT_NAME}" ibv_devinfo --list
srun -N1 -n1 --container-name="${CONT_NAME}" nvidia-smi topo -m

srun --mpi=pmix --ntasks="$(( SLURM_JOB_NUM_NODES * DGXNGPU ))" --ntasks-per-node="${DGXNGPU}" \
     --container-name="${CONT_NAME}" all_reduce_perf_mpi -b 73698008 -e 73698008 -d half -G 1
