+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ docker exec -it object_detection python -c '
from maskrcnn_benchmark.utils.mlperf_logger import mllogger
mllogger.mlperf_submission_log(mllogger.constants.MASKRCNN)'
:::MLLOG {"namespace": "", "time_ms": 1684167326300, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "maskrcnn", "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1684167326339, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "SUBMISSION_ORG_PLACEHOLDER", "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1684167326340, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1684167326341, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1684167326342, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "1xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "<string>", "lineno": 3}}
+ '[' 1 -eq 1 ']'
+ sync
+ sudo /sbin/sysctl vm.drop_caches=3
vm.drop_caches = 3
+ docker exec -it object_detection python -c '
from maskrcnn_benchmark.utils.mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True, stack_offset=0)'
:::MLLOG {"namespace": "", "time_ms": 1684167336314, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "/usr/local/lib/python3.8/dist-packages/mlperf_logging/mllog/mllog.py", "lineno": 259}}
+ docker exec -it --env=BATCHSIZE --env=DGXHT --env=DGXNGPU --env=DGXNNODES --env=DGXNSOCKET --env=DGXSOCKETCORES --env=DGXSYSTEM --env=EXTRA_CONFIG --env=EXTRA_PARAMS --env=WALLTIME --env=MLPERF_HOST_OS object_detection python -m torch.distributed.run --standalone --no_python --nproc_per_node=8 ./run_and_time.sh
master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
STARTING TIMING RUN AT 2023-05-15 04:15:37 PM
+ echo 'running benchmark'
STARTING TIMING RUN AT 2023-05-15 04:15:37 PM
running benchmark
+ DATASET_DIR=/data
+ echo 'running benchmark'
running benchmark
+ DATASET_DIR=/data
+ ln -sTf /data/coco2017 /coco
+ ln -sTf /data/coco2017 /coco
++ ls /data
++ ls /data
STARTING TIMING RUN AT 2023-05-15 04:15:37 PM
+ echo 'running benchmark'
running benchmark
+ DATASET_DIR=/data
+ ln -sTf /data/coco2017 /coco
+ echo coco2017 pkl_coco
coco2017 pkl_coco
+ echo coco2017 pkl_coco
coco2017 pkl_coco
++ ls /coco
++ ls /coco
++ ls /data
+ echo annotations models train2017 val2017
annotations models train2017 val2017
+ echo annotations models train2017 val2017
annotations models train2017 val2017
++ ls /pkl_coco
++ ls /pkl_coco
STARTING TIMING RUN AT 2023-05-15 04:15:37 PM
+ echo 'running benchmark'
running benchmark
+ DATASET_DIR=/data
+ ln -sTf /data/coco2017 /coco
+ echo coco2017 pkl_coco
coco2017 pkl_coco
++ ls /coco
+ echo
+ echo


+ TIME_TAGS=0
+ NVTX_FLAG=0
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ NCCL_TEST=0
+ EPOCH_PROF=0
+ NCCL_TEST=0
+ SYNTH_DATA=0
+ EPOCH_PROF=0
+ DISABLE_CG=0
+ SYNTH_DATA=0
+ USE_TORCHRUN=0
+ DISABLE_CG=0
+ USE_TORCHRUN=0
+ '[' 0 -gt 0 ']'
+ NSYSCMD=
+ '[' 0 -gt 0 ']'
+ declare -a CMD
+ '[' 0 -gt 0 ']'
+ NSYSCMD=
+ [[ -n '' ]]
+ CMD=(${NSYSCMD} 'python' '-u')
+ '[' 0 -gt 0 ']'
+ declare -a CMD
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ '[' '' = apiLog.sh ']'
+ [[ -n '' ]]
+ CMD=(${NSYSCMD} 'python' '-u')
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ python -u maskrcnn/tools/train_mlperf.py --config-file maskrcnn/configs/e2e_mask_rcnn_R_50_FPN_1x_pyt.yaml DTYPE float16 PATHS_CATALOG maskrcnn/maskrcnn_benchmark/config/paths_catalog_dbcluster.py MODEL.WEIGHT /coco/models/R-50.pkl DISABLE_REDUCED_LOGGING True SOLVER.BASE_LR 0.12 SOLVER.WARMUP_FACTOR 0.000192 SOLVER.WARMUP_ITERS 625 SOLVER.WARMUP_METHOD mlperf_linear SOLVER.STEPS '(12000,16000)' SOLVER.IMS_PER_BATCH 96 TEST.IMS_PER_BATCH 96 MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN 12000 MODEL.RPN.FPN_POST_NMS_TOP_N_PER_IMAGE False NHWC True SOLVER.MAX_ITER 40000 DATALOADER.DALI False DATALOADER.DALI_ON_GPU False DATALOADER.CACHE_EVAL_IMAGES True EVAL_SEGM_NUMPROCS 10 USE_CUDA_GRAPH True EVAL_MASK_VIRTUAL_PASTE True MODEL.BACKBONE.INCLUDE_RPN_HEAD True DATALOADER.NUM_WORKERS 1 PRECOMPUTE_RPN_CONSTANT_TENSORS True DATALOADER.HYBRID True MODEL.RESNETS.FIRST_TRANS_FUNC SpatialBottleneckWithFixedBatchNorm MODEL.RESNETS.TRANS_FUNC SpatialBottleneckWithFixedBatchNorm MODEL.BACKBONE.DONT_RECOMPUTE_SCALE_AND_BIAS True
++ ls /data
+ '[' '' = apiLog.sh ']'
+ echo annotations models train2017 val2017
annotations models train2017 val2017
+ python -u maskrcnn/tools/train_mlperf.py --config-file maskrcnn/configs/e2e_mask_rcnn_R_50_FPN_1x_pyt.yaml DTYPE float16 PATHS_CATALOG maskrcnn/maskrcnn_benchmark/config/paths_catalog_dbcluster.py MODEL.WEIGHT /coco/models/R-50.pkl DISABLE_REDUCED_LOGGING True SOLVER.BASE_LR 0.12 SOLVER.WARMUP_FACTOR 0.000192 SOLVER.WARMUP_ITERS 625 SOLVER.WARMUP_METHOD mlperf_linear SOLVER.STEPS '(12000,16000)' SOLVER.IMS_PER_BATCH 96 TEST.IMS_PER_BATCH 96 MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN 12000 MODEL.RPN.FPN_POST_NMS_TOP_N_PER_IMAGE False NHWC True SOLVER.MAX_ITER 40000 DATALOADER.DALI False DATALOADER.DALI_ON_GPU False DATALOADER.CACHE_EVAL_IMAGES True EVAL_SEGM_NUMPROCS 10 USE_CUDA_GRAPH True EVAL_MASK_VIRTUAL_PASTE True MODEL.BACKBONE.INCLUDE_RPN_HEAD True DATALOADER.NUM_WORKERS 1 PRECOMPUTE_RPN_CONSTANT_TENSORS True DATALOADER.HYBRID True MODEL.RESNETS.FIRST_TRANS_FUNC SpatialBottleneckWithFixedBatchNorm MODEL.RESNETS.TRANS_FUNC SpatialBottleneckWithFixedBatchNorm MODEL.BACKBONE.DONT_RECOMPUTE_SCALE_AND_BIAS True
++ ls /pkl_coco
+ echo coco2017 pkl_coco
coco2017 pkl_coco
++ ls /coco
STARTING TIMING RUN AT 2023-05-15 04:15:37 PM
+ echo 'running benchmark'
running benchmark
+ DATASET_DIR=/data
+ ln -sTf /data/coco2017 /coco
+ echo

+ TIME_TAGS=0
+ NVTX_FLAG=0
+ NCCL_TEST=0
+ EPOCH_PROF=0
+ SYNTH_DATA=0
+ DISABLE_CG=0
+ USE_TORCHRUN=0
+ '[' 0 -gt 0 ']'
+ NSYSCMD=
+ '[' 0 -gt 0 ']'
+ declare -a CMD
+ [[ -n '' ]]
+ CMD=(${NSYSCMD} 'python' '-u')
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ '[' '' = apiLog.sh ']'
+ python -u maskrcnn/tools/train_mlperf.py --config-file maskrcnn/configs/e2e_mask_rcnn_R_50_FPN_1x_pyt.yaml DTYPE float16 PATHS_CATALOG maskrcnn/maskrcnn_benchmark/config/paths_catalog_dbcluster.py MODEL.WEIGHT /coco/models/R-50.pkl DISABLE_REDUCED_LOGGING True SOLVER.BASE_LR 0.12 SOLVER.WARMUP_FACTOR 0.000192 SOLVER.WARMUP_ITERS 625 SOLVER.WARMUP_METHOD mlperf_linear SOLVER.STEPS '(12000,16000)' SOLVER.IMS_PER_BATCH 96 TEST.IMS_PER_BATCH 96 MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN 12000 MODEL.RPN.FPN_POST_NMS_TOP_N_PER_IMAGE False NHWC True SOLVER.MAX_ITER 40000 DATALOADER.DALI False DATALOADER.DALI_ON_GPU False DATALOADER.CACHE_EVAL_IMAGES True EVAL_SEGM_NUMPROCS 10 USE_CUDA_GRAPH True EVAL_MASK_VIRTUAL_PASTE True MODEL.BACKBONE.INCLUDE_RPN_HEAD True DATALOADER.NUM_WORKERS 1 PRECOMPUTE_RPN_CONSTANT_TENSORS True DATALOADER.HYBRID True MODEL.RESNETS.FIRST_TRANS_FUNC SpatialBottleneckWithFixedBatchNorm MODEL.RESNETS.TRANS_FUNC SpatialBottleneckWithFixedBatchNorm MODEL.BACKBONE.DONT_RECOMPUTE_SCALE_AND_BIAS True
+ echo annotations models train2017 val2017
annotations models train2017 val2017
++ ls /pkl_coco
++ ls /data
+ echo

+ TIME_TAGS=0
+ NVTX_FLAG=0
+ NCCL_TEST=0
+ EPOCH_PROF=0
+ SYNTH_DATA=0
+ DISABLE_CG=0
+ USE_TORCHRUN=0
+ '[' 0 -gt 0 ']'
+ NSYSCMD=
+ '[' 0 -gt 0 ']'
+ declare -a CMD
+ [[ -n '' ]]
+ CMD=(${NSYSCMD} 'python' '-u')
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ '[' '' = apiLog.sh ']'
+ python -u maskrcnn/tools/train_mlperf.py --config-file maskrcnn/configs/e2e_mask_rcnn_R_50_FPN_1x_pyt.yaml DTYPE float16 PATHS_CATALOG maskrcnn/maskrcnn_benchmark/config/paths_catalog_dbcluster.py MODEL.WEIGHT /coco/models/R-50.pkl DISABLE_REDUCED_LOGGING True SOLVER.BASE_LR 0.12 SOLVER.WARMUP_FACTOR 0.000192 SOLVER.WARMUP_ITERS 625 SOLVER.WARMUP_METHOD mlperf_linear SOLVER.STEPS '(12000,16000)' SOLVER.IMS_PER_BATCH 96 TEST.IMS_PER_BATCH 96 MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN 12000 MODEL.RPN.FPN_POST_NMS_TOP_N_PER_IMAGE False NHWC True SOLVER.MAX_ITER 40000 DATALOADER.DALI False DATALOADER.DALI_ON_GPU False DATALOADER.CACHE_EVAL_IMAGES True EVAL_SEGM_NUMPROCS 10 USE_CUDA_GRAPH True EVAL_MASK_VIRTUAL_PASTE True MODEL.BACKBONE.INCLUDE_RPN_HEAD True DATALOADER.NUM_WORKERS 1 PRECOMPUTE_RPN_CONSTANT_TENSORS True DATALOADER.HYBRID True MODEL.RESNETS.FIRST_TRANS_FUNC SpatialBottleneckWithFixedBatchNorm MODEL.RESNETS.TRANS_FUNC SpatialBottleneckWithFixedBatchNorm MODEL.BACKBONE.DONT_RECOMPUTE_SCALE_AND_BIAS True
+ echo coco2017 pkl_coco
coco2017 pkl_coco
++ ls /coco
STARTING TIMING RUN AT 2023-05-15 04:15:37 PM
+ echo 'running benchmark'
running benchmark
+ DATASET_DIR=/data
+ ln -sTf /data/coco2017 /coco
+ echo annotations models train2017 val2017
annotations models train2017 val2017
++ ls /pkl_coco
++ ls /data
+ echo

+ TIME_TAGS=0
+ NVTX_FLAG=0
+ NCCL_TEST=0
+ EPOCH_PROF=0
+ SYNTH_DATA=0
+ DISABLE_CG=0
+ USE_TORCHRUN=0
+ '[' 0 -gt 0 ']'
+ NSYSCMD=
+ '[' 0 -gt 0 ']'
+ declare -a CMD
+ [[ -n '' ]]
+ CMD=(${NSYSCMD} 'python' '-u')
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ '[' '' = apiLog.sh ']'
+ python -u maskrcnn/tools/train_mlperf.py --config-file maskrcnn/configs/e2e_mask_rcnn_R_50_FPN_1x_pyt.yaml DTYPE float16 PATHS_CATALOG maskrcnn/maskrcnn_benchmark/config/paths_catalog_dbcluster.py MODEL.WEIGHT /coco/models/R-50.pkl DISABLE_REDUCED_LOGGING True SOLVER.BASE_LR 0.12 SOLVER.WARMUP_FACTOR 0.000192 SOLVER.WARMUP_ITERS 625 SOLVER.WARMUP_METHOD mlperf_linear SOLVER.STEPS '(12000,16000)' SOLVER.IMS_PER_BATCH 96 TEST.IMS_PER_BATCH 96 MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN 12000 MODEL.RPN.FPN_POST_NMS_TOP_N_PER_IMAGE False NHWC True SOLVER.MAX_ITER 40000 DATALOADER.DALI False DATALOADER.DALI_ON_GPU False DATALOADER.CACHE_EVAL_IMAGES True EVAL_SEGM_NUMPROCS 10 USE_CUDA_GRAPH True EVAL_MASK_VIRTUAL_PASTE True MODEL.BACKBONE.INCLUDE_RPN_HEAD True DATALOADER.NUM_WORKERS 1 PRECOMPUTE_RPN_CONSTANT_TENSORS True DATALOADER.HYBRID True MODEL.RESNETS.FIRST_TRANS_FUNC SpatialBottleneckWithFixedBatchNorm MODEL.RESNETS.TRANS_FUNC SpatialBottleneckWithFixedBatchNorm MODEL.BACKBONE.DONT_RECOMPUTE_SCALE_AND_BIAS True
+ echo coco2017 pkl_coco
coco2017 pkl_coco
++ ls /coco
+ echo annotations models train2017 val2017
annotations models train2017 val2017
++ ls /pkl_coco
STARTING TIMING RUN AT 2023-05-15 04:15:37 PM
+ echo 'running benchmark'
running benchmark
+ DATASET_DIR=/data
+ ln -sTf /data/coco2017 /coco
+ echo

+ TIME_TAGS=0
+ NVTX_FLAG=0
+ NCCL_TEST=0
+ EPOCH_PROF=0
+ SYNTH_DATA=0
+ DISABLE_CG=0
+ USE_TORCHRUN=0
+ '[' 0 -gt 0 ']'
+ NSYSCMD=
+ '[' 0 -gt 0 ']'
+ declare -a CMD
+ [[ -n '' ]]
+ CMD=(${NSYSCMD} 'python' '-u')
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ '[' '' = apiLog.sh ']'
+ python -u maskrcnn/tools/train_mlperf.py --config-file maskrcnn/configs/e2e_mask_rcnn_R_50_FPN_1x_pyt.yaml DTYPE float16 PATHS_CATALOG maskrcnn/maskrcnn_benchmark/config/paths_catalog_dbcluster.py MODEL.WEIGHT /coco/models/R-50.pkl DISABLE_REDUCED_LOGGING True SOLVER.BASE_LR 0.12 SOLVER.WARMUP_FACTOR 0.000192 SOLVER.WARMUP_ITERS 625 SOLVER.WARMUP_METHOD mlperf_linear SOLVER.STEPS '(12000,16000)' SOLVER.IMS_PER_BATCH 96 TEST.IMS_PER_BATCH 96 MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN 12000 MODEL.RPN.FPN_POST_NMS_TOP_N_PER_IMAGE False NHWC True SOLVER.MAX_ITER 40000 DATALOADER.DALI False DATALOADER.DALI_ON_GPU False DATALOADER.CACHE_EVAL_IMAGES True EVAL_SEGM_NUMPROCS 10 USE_CUDA_GRAPH True EVAL_MASK_VIRTUAL_PASTE True MODEL.BACKBONE.INCLUDE_RPN_HEAD True DATALOADER.NUM_WORKERS 1 PRECOMPUTE_RPN_CONSTANT_TENSORS True DATALOADER.HYBRID True MODEL.RESNETS.FIRST_TRANS_FUNC SpatialBottleneckWithFixedBatchNorm MODEL.RESNETS.TRANS_FUNC SpatialBottleneckWithFixedBatchNorm MODEL.BACKBONE.DONT_RECOMPUTE_SCALE_AND_BIAS True
STARTING TIMING RUN AT 2023-05-15 04:15:37 PM
+ echo 'running benchmark'
running benchmark
+ DATASET_DIR=/data
+ ln -sTf /data/coco2017 /coco
++ ls /data
++ ls /data
+ echo coco2017 pkl_coco
coco2017 pkl_coco
++ ls /coco
+ echo coco2017 pkl_coco
coco2017 pkl_coco
++ ls /coco
+ echo annotations models train2017 val2017
annotations models train2017 val2017
++ ls /pkl_coco
+ echo annotations models train2017 val2017
annotations models train2017 val2017
+ echo

+ TIME_TAGS=0
+ NVTX_FLAG=0
+ NCCL_TEST=0
+ EPOCH_PROF=0
+ SYNTH_DATA=0
+ DISABLE_CG=0
+ USE_TORCHRUN=0
+ '[' 0 -gt 0 ']'
+ NSYSCMD=
+ '[' 0 -gt 0 ']'
+ declare -a CMD
+ [[ -n '' ]]
+ CMD=(${NSYSCMD} 'python' '-u')
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ '[' '' = apiLog.sh ']'
+ python -u maskrcnn/tools/train_mlperf.py --config-file maskrcnn/configs/e2e_mask_rcnn_R_50_FPN_1x_pyt.yaml DTYPE float16 PATHS_CATALOG maskrcnn/maskrcnn_benchmark/config/paths_catalog_dbcluster.py MODEL.WEIGHT /coco/models/R-50.pkl DISABLE_REDUCED_LOGGING True SOLVER.BASE_LR 0.12 SOLVER.WARMUP_FACTOR 0.000192 SOLVER.WARMUP_ITERS 625 SOLVER.WARMUP_METHOD mlperf_linear SOLVER.STEPS '(12000,16000)' SOLVER.IMS_PER_BATCH 96 TEST.IMS_PER_BATCH 96 MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN 12000 MODEL.RPN.FPN_POST_NMS_TOP_N_PER_IMAGE False NHWC True SOLVER.MAX_ITER 40000 DATALOADER.DALI False DATALOADER.DALI_ON_GPU False DATALOADER.CACHE_EVAL_IMAGES True EVAL_SEGM_NUMPROCS 10 USE_CUDA_GRAPH True EVAL_MASK_VIRTUAL_PASTE True MODEL.BACKBONE.INCLUDE_RPN_HEAD True DATALOADER.NUM_WORKERS 1 PRECOMPUTE_RPN_CONSTANT_TENSORS True DATALOADER.HYBRID True MODEL.RESNETS.FIRST_TRANS_FUNC SpatialBottleneckWithFixedBatchNorm MODEL.RESNETS.TRANS_FUNC SpatialBottleneckWithFixedBatchNorm MODEL.BACKBONE.DONT_RECOMPUTE_SCALE_AND_BIAS True
++ ls /pkl_coco
+ echo

+ TIME_TAGS=0
+ NVTX_FLAG=0
+ NCCL_TEST=0
+ EPOCH_PROF=0
+ SYNTH_DATA=0
+ DISABLE_CG=0
+ USE_TORCHRUN=0
+ '[' 0 -gt 0 ']'
+ NSYSCMD=
+ '[' 0 -gt 0 ']'
+ declare -a CMD
+ [[ -n '' ]]
+ CMD=(${NSYSCMD} 'python' '-u')
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ '[' '' = apiLog.sh ']'
+ python -u maskrcnn/tools/train_mlperf.py --config-file maskrcnn/configs/e2e_mask_rcnn_R_50_FPN_1x_pyt.yaml DTYPE float16 PATHS_CATALOG maskrcnn/maskrcnn_benchmark/config/paths_catalog_dbcluster.py MODEL.WEIGHT /coco/models/R-50.pkl DISABLE_REDUCED_LOGGING True SOLVER.BASE_LR 0.12 SOLVER.WARMUP_FACTOR 0.000192 SOLVER.WARMUP_ITERS 625 SOLVER.WARMUP_METHOD mlperf_linear SOLVER.STEPS '(12000,16000)' SOLVER.IMS_PER_BATCH 96 TEST.IMS_PER_BATCH 96 MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN 12000 MODEL.RPN.FPN_POST_NMS_TOP_N_PER_IMAGE False NHWC True SOLVER.MAX_ITER 40000 DATALOADER.DALI False DATALOADER.DALI_ON_GPU False DATALOADER.CACHE_EVAL_IMAGES True EVAL_SEGM_NUMPROCS 10 USE_CUDA_GRAPH True EVAL_MASK_VIRTUAL_PASTE True MODEL.BACKBONE.INCLUDE_RPN_HEAD True DATALOADER.NUM_WORKERS 1 PRECOMPUTE_RPN_CONSTANT_TENSORS True DATALOADER.HYBRID True MODEL.RESNETS.FIRST_TRANS_FUNC SpatialBottleneckWithFixedBatchNorm MODEL.RESNETS.TRANS_FUNC SpatialBottleneckWithFixedBatchNorm MODEL.BACKBONE.DONT_RECOMPUTE_SCALE_AND_BIAS True
/usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
  warnings.warn(msg, DeprecatedFeatureWarning)
/usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
  warnings.warn(msg, DeprecatedFeatureWarning)
/usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
  warnings.warn(msg, DeprecatedFeatureWarning)
/usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
  warnings.warn(msg, DeprecatedFeatureWarning)
/usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
  warnings.warn(msg, DeprecatedFeatureWarning)
/usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
  warnings.warn(msg, DeprecatedFeatureWarning)
/usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
  warnings.warn(msg, DeprecatedFeatureWarning)
/usr/local/lib/python3.8/dist-packages/apex/__init__.py:68: DeprecatedFeatureWarning: apex.amp is deprecated and will be removed by the end of February 2023. Use [PyTorch AMP](https://pytorch.org/docs/stable/amp.html)
  warnings.warn(msg, DeprecatedFeatureWarning)
:::MLLOG {"namespace": "", "time_ms": 1684167345304, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 1011}}
:::MLLOG {"namespace": "", "time_ms": 1684167345329, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 1011}}
:::MLLOG {"namespace": "", "time_ms": 1684167345334, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 1011}}
:::MLLOG {"namespace": "", "time_ms": 1684167345332, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 1011}}
:::MLLOG {"namespace": "", "time_ms": 1684167345342, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 1011}}
:::MLLOG {"namespace": "", "time_ms": 1684167345379, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 1011}}
:::MLLOG {"namespace": "", "time_ms": 1684167345361, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 1011}}
:::MLLOG {"namespace": "", "time_ms": 1684167345566, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 1011}}
:::MLLOG {"namespace": "", "time_ms": 1684167365054, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1983712128, "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 1081}}
2023-05-15 16:16:05,055 maskrcnn_benchmark INFO: Using 8 GPUs
2023-05-15 16:16:05,055 maskrcnn_benchmark INFO: Namespace(config_file='maskrcnn/configs/e2e_mask_rcnn_R_50_FPN_1x_pyt.yaml', distributed=True, local_rank=0, opts=['DTYPE', 'float16', 'PATHS_CATALOG', 'maskrcnn/maskrcnn_benchmark/config/paths_catalog_dbcluster.py', 'MODEL.WEIGHT', '/coco/models/R-50.pkl', 'DISABLE_REDUCED_LOGGING', 'True', 'SOLVER.BASE_LR', '0.12', 'SOLVER.WARMUP_FACTOR', '0.000192', 'SOLVER.WARMUP_ITERS', '625', 'SOLVER.WARMUP_METHOD', 'mlperf_linear', 'SOLVER.STEPS', '(12000,16000)', 'SOLVER.IMS_PER_BATCH', '96', 'TEST.IMS_PER_BATCH', '96', 'MODEL.RPN.FPN_POST_NMS_TOP_N_TRAIN', '12000', 'MODEL.RPN.FPN_POST_NMS_TOP_N_PER_IMAGE', 'False', 'NHWC', 'True', 'SOLVER.MAX_ITER', '40000', 'DATALOADER.DALI', 'False', 'DATALOADER.DALI_ON_GPU', 'False', 'DATALOADER.CACHE_EVAL_IMAGES', 'True', 'EVAL_SEGM_NUMPROCS', '10', 'USE_CUDA_GRAPH', 'True', 'EVAL_MASK_VIRTUAL_PASTE', 'True', 'MODEL.BACKBONE.INCLUDE_RPN_HEAD', 'True', 'DATALOADER.NUM_WORKERS', '1', 'PRECOMPUTE_RPN_CONSTANT_TENSORS', 'True', 'DATALOADER.HYBRID', 'True', 'MODEL.RESNETS.FIRST_TRANS_FUNC', 'SpatialBottleneckWithFixedBatchNorm', 'MODEL.RESNETS.TRANS_FUNC', 'SpatialBottleneckWithFixedBatchNorm', 'MODEL.BACKBONE.DONT_RECOMPUTE_SCALE_AND_BIAS', 'True'], seed=1983712128)
2023-05-15 16:16:05,056 maskrcnn_benchmark INFO: Worker 0: Setting seed 2440760793
2023-05-15 16:16:05,057 maskrcnn_benchmark INFO: Collecting env info (might take some time)
3 :: dedicated_evaluation_ranks = 0, num_training_ranks = 8, images_per_batch_train = 96, images_per_gpu_train = 12, rank_train = 3, rank_in_group_train = 0, spatial_group_size_train = 1, num_evaluation_ranks = 8, images_per_batch_test = 96, images_per_gpu_test = 12, rank_test = 3, rank_in_group_test = 0, spatial_group_size_test = 1
3 :: is_training_rank = True, is_evaluation_rank = True
5 :: dedicated_evaluation_ranks = 0, num_training_ranks = 8, images_per_batch_train = 96, images_per_gpu_train = 12, rank_train = 5, rank_in_group_train = 0, spatial_group_size_train = 1, num_evaluation_ranks = 8, images_per_batch_test = 96, images_per_gpu_test = 12, rank_test = 5, rank_in_group_test = 0, spatial_group_size_test = 1
5 :: is_training_rank = True, is_evaluation_rank = True
6 :: dedicated_evaluation_ranks = 0, num_training_ranks = 8, images_per_batch_train = 96, images_per_gpu_train = 12, rank_train = 6, rank_in_group_train = 0, spatial_group_size_train = 1, num_evaluation_ranks = 8, images_per_batch_test = 96, images_per_gpu_test = 12, rank_test = 6, rank_in_group_test = 0, spatial_group_size_test = 14 :: dedicated_evaluation_ranks = 0, num_training_ranks = 8, images_per_batch_train = 96, images_per_gpu_train = 12, rank_train = 4, rank_in_group_train = 0, spatial_group_size_train = 1, num_evaluation_ranks = 8, images_per_batch_test = 96, images_per_gpu_test = 12, rank_test = 4, rank_in_group_test = 0, spatial_group_size_test = 1

6 :: is_training_rank = True, is_evaluation_rank = True
1 :: dedicated_evaluation_ranks = 0, num_training_ranks = 8, images_per_batch_train = 96, images_per_gpu_train = 12, rank_train = 1, rank_in_group_train = 0, spatial_group_size_train = 1, num_evaluation_ranks = 8, images_per_batch_test = 96, images_per_gpu_test = 12, rank_test = 1, rank_in_group_test = 0, spatial_group_size_test = 14 :: is_training_rank = True, is_evaluation_rank = True

1 :: is_training_rank = True, is_evaluation_rank = True
2 :: dedicated_evaluation_ranks = 0, num_training_ranks = 8, images_per_batch_train = 96, images_per_gpu_train = 12, rank_train = 2, rank_in_group_train = 0, spatial_group_size_train = 1, num_evaluation_ranks = 8, images_per_batch_test = 96, images_per_gpu_test = 12, rank_test = 2, rank_in_group_test = 0, spatial_group_size_test = 1
2 :: is_training_rank = True, is_evaluation_rank = True
7 :: dedicated_evaluation_ranks = 0, num_training_ranks = 8, images_per_batch_train = 96, images_per_gpu_train = 12, rank_train = 7, rank_in_group_train = 0, spatial_group_size_train = 1, num_evaluation_ranks = 8, images_per_batch_test = 96, images_per_gpu_test = 12, rank_test = 7, rank_in_group_test = 0, spatial_group_size_test = 1
7 :: is_training_rank = True, is_evaluation_rank = True
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:1130: UserWarning: _ConvTransposeMixin is a deprecated internal class. Please consider using public APIs.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:1130: UserWarning: _ConvTransposeMixin is a deprecated internal class. Please consider using public APIs.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:1130: UserWarning: _ConvTransposeMixin is a deprecated internal class. Please consider using public APIs.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:1130: UserWarning: _ConvTransposeMixin is a deprecated internal class. Please consider using public APIs.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:1130: UserWarning: _ConvTransposeMixin is a deprecated internal class. Please consider using public APIs.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:1130: UserWarning: _ConvTransposeMixin is a deprecated internal class. Please consider using public APIs.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:1130: UserWarning: _ConvTransposeMixin is a deprecated internal class. Please consider using public APIs.
  warnings.warn(
USE_CUDA_GRAPH :: per_gpu_batch_sizes = [(True, 12), (False, 12)]
USE_CUDA_GRAPH :: per_gpu_batch_sizes = [(True, 12), (False, 12)]
USE_CUDA_GRAPH :: per_gpu_batch_sizes = [(True, 12), (False, 12)]
USE_CUDA_GRAPH :: per_gpu_batch_sizes = [(True, 12), (False, 12)]
USE_CUDA_GRAPH :: per_gpu_batch_sizes = [(True, 12), (False, 12)]
USE_CUDA_GRAPH :: per_gpu_batch_sizes = [(True, 12), (False, 12)]
USE_CUDA_GRAPH :: per_gpu_batch_sizes = [(True, 12), (False, 12)]
2023-05-15 16:16:07,948 maskrcnn_benchmark INFO: 
PyTorch version: 2.1.0a0+fe05266
Is debug build: False
CUDA used to build PyTorch: 12.1
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.5 LTS (x86_64)
GCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
Clang version: Could not collect
CMake version: version 3.24.1
Libc version: glibc-2.31

Python version: 3.8.10 (default, Mar 13 2023, 10:26:41)  [GCC 9.4.0] (64-bit runtime)
Python platform: Linux-5.15.0-1035-azure-x86_64-with-glibc2.29
Is CUDA available: True
CUDA runtime version: 12.1.66
CUDA_MODULE_LOADING set to: EAGER
GPU models and configuration: 
GPU 0: NVIDIA H100 80GB HBM3
GPU 1: NVIDIA H100 80GB HBM3
GPU 2: NVIDIA H100 80GB HBM3
GPU 3: NVIDIA H100 80GB HBM3
GPU 4: NVIDIA H100 80GB HBM3
GPU 5: NVIDIA H100 80GB HBM3
GPU 6: NVIDIA H100 80GB HBM3
GPU 7: NVIDIA H100 80GB HBM3

Nvidia driver version: 525.85.12
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.0
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.0
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                    x86_64
CPU op-mode(s):                  32-bit, 64-bit
Byte Order:                      Little Endian
Address sizes:                   46 bits physical, 57 bits virtual
CPU(s):                          96
On-line CPU(s) list:             0-95
Thread(s) per core:              1
Core(s) per socket:              48
Socket(s):                       2
NUMA node(s):                    2
Vendor ID:                       GenuineIntel
CPU family:                      6
Model:                           143
Model name:                      Intel(R) Xeon(R) Platinum 8480C
Stepping:                        8
CPU MHz:                         3760.178
BogoMIPS:                        4000.00
Hypervisor vendor:               Microsoft
Virtualization type:             full
L1d cache:                       4.5 MiB
L1i cache:                       3 MiB
L2 cache:                        192 MiB
L3 cache:                        210 MiB
NUMA node0 CPU(s):               0-47
NUMA node1 CPU(s):               48-95
Vulnerability Itlb multihit:     Not affected
Vulnerability L1tf:              Not affected
Vulnerability Mds:               Not affected
Vulnerability Meltdown:          Not affected
Vulnerability Mmio stale data:   Unknown: No mitigations
Vulnerability Retbleed:          Vulnerable
Vulnerability Spec store bypass: Vulnerable
Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:        Mitigation; Retpolines, STIBP disabled, RSB filling, PBRSB-eIBRS Not affected
Vulnerability Srbds:             Not affected
Vulnerability Tsx async abort:   Not affected
Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid aperfmperf pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm avx512f avx512dq rdseed adx smap avx512ifma clflushopt clwb avx512cd sha_ni avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves avx_vnni avx512_bf16 avx512vbmi umip waitpkg avx512_vbmi2 gfni vaes vpclmulqdq avx512_vnni avx512_bitalg avx512_vpopcntdq la57 rdpid cldemote movdiri movdir64b fsrm serialize amx_bf16 avx512_fp16 amx_tile amx_int8 arch_capabilities

Versions of relevant libraries:
[pip3] numpy==1.22.2
[pip3] pytorch-quantization==2.1.2
[pip3] torch==2.1.0a0+fe05266
[pip3] torch-tensorrt==1.4.0.dev0
[pip3] torchtext==0.13.0a0+fae8e8c
[pip3] torchvision==0.15.0a0
[conda] Could not collect
        Pillow (9.2.0)
2023-05-15 16:16:07,949 maskrcnn_benchmark INFO: Loaded configuration file maskrcnn/configs/e2e_mask_rcnn_R_50_FPN_1x_pyt.yaml
2023-05-15 16:16:07,949 maskrcnn_benchmark INFO: 
MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/MSRA/R-50"
  BACKBONE:
    CONV_BODY: "R-50-FPN"
    OUT_CHANNELS: 256
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    PRE_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
  ROI_BOX_HEAD:
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
  ROI_MASK_HEAD:
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    FEATURE_EXTRACTOR: "MaskRCNNFPNFeatureExtractor"
    PREDICTOR: "MaskRCNNC4Predictor"
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
  MASK_ON: True
DATASETS:
  TRAIN: ("pyt_coco_2017_train",)
  TEST: ("coco_2017_val",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  BASE_LR: 0.02
  WEIGHT_DECAY: 0.0001
  STEPS: (60000, 80000)
  MAX_ITER: 90000

2023-05-15 16:16:07,949 maskrcnn_benchmark INFO: Running with config:
ADDITIONAL_METERS: False
ALLOW_BATCH_SIZE_ONE_GRAPHING: True
AMP_VERBOSE: False
CUDA_GRAPH_NUM_SHAPES_PER_ORIENTATION: 1
CUDA_GRAPH_NUM_SHAPES_PER_ORIENTATION_TEST: 1
CUDA_PROFILER_API_PROFILING: (0, 0)
DATALOADER:
  ALWAYS_PAD_TO_MAX: True
  ASPECT_RATIO_GROUPING: True
  CACHE_EVAL_IMAGES: True
  DALI: False
  DALI_ON_GPU: False
  GLOBAL_TRANSFORMS: True
  HYBRID: True
  MAX_ANNOTATIONS_PER_IMAGE: 0
  NUM_WORKERS: 1
  SIZE_DIVISIBILITY: 32
  USE_SYNTHETIC_INPUT: False
DATASETS:
  TEST: ('coco_2017_val',)
  TRAIN: ('pyt_coco_2017_train',)
DEBUG_DETERMINISTIC: False
DEBUG_SAVE_GRADIENTS: False
DEDICATED_EVALUATION_RANKS: 0
DEDICATED_EVALUATION_WAIT_FOR_RESULT_ITERATIONS: (0, 13, 400)
DISABLE_LOSS_LOGGING: False
DISABLE_REDUCED_LOGGING: True
DTYPE: float16
DYNAMIC_LOSS_SCALE_WINDOW: 1000
ENABLE_COMPLIANCE_LOG: True
ENABLE_NSYS_PROFILING: False
EVAL_MASK_VIRTUAL_PASTE: True
EVAL_SEGM_NUMPROCS: 10
INPUT:
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  TO_BGR255: True
MLPERF:
  MIN_BBOX_MAP: 0.377
  MIN_SEGM_MAP: 0.339
MODEL:
  BACKBONE:
    CONV_BODY: R-50-FPN
    DONT_RECOMPUTE_SCALE_AND_BIAS: True
    FREEZE_CONV_BODY_AT: 2
    HALO_EXCHANGER: HaloExchangerPeer
    INCLUDE_RPN_HEAD: True
    OUT_CHANNELS: 256
    SPATIAL_H_SPLIT: True
    SPATIAL_METHOD: 1
    USE_DELAY_KERNEL: False
    USE_GN: False
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FPN:
    USE_FUSION: True
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: True
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    FIRST_TRANS_FUNC: SpatialBottleneckWithFixedBatchNorm
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: SpatialBottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: FPN2MLPFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 81
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 100
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.05
    USE_FPN: True
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: MaskRCNNFPNFeatureExtractor
    FEATURE_EXTRACTOR_FUSION: False
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_TOP_N_PER_IMAGE: False
    FPN_POST_NMS_TOP_N_TEST: 1000
    FPN_POST_NMS_TOP_N_TRAIN: 12000
    FUSION: True
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 1000
    POST_NMS_TOP_N_TRAIN: 2000
    PRE_NMS_TOP_N_TEST: 1000
    PRE_NMS_TOP_N_TRAIN: 2000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: True
    USE_SPLIT_TOPK: False
  RPN_ONLY: False
  WEIGHT: /coco/models/R-50.pkl
NHWC: True
NUM_ITERATION_TO_RUN_EVAL: -1
OUTPUT_DIR: .
PATHS_CATALOG: maskrcnn/maskrcnn_benchmark/config/paths_catalog_dbcluster.py
PER_EPOCH_EVAL: True
PRECOMPUTE_RPN_CONSTANT_TENSORS: True
SAVE_CHECKPOINTS: False
SOLVER:
  BASE_LR: 0.12
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 2500
  GAMMA: 0.1
  IMS_PER_BATCH: 96
  MAX_ITER: 40000
  MOMENTUM: 0.9
  STEPS: (12000, 16000)
  WARMUP_FACTOR: 0.000192
  WARMUP_ITERS: 625
  WARMUP_METHOD: mlperf_linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
SYNCFREE_ROI: True
TEST:
  DETECTIONS_PER_IMG: 100
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 96
USE_CUDA_GRAPH: True
:::MLLOG {"namespace": "", "time_ms": 1684167367951, "event_type": "POINT_IN_TIME", "key": "d_batch_size", "value": 12.0, "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 1126}}
:::MLLOG {"namespace": "", "time_ms": 1684167367951, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 96, "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 535}}
:::MLLOG {"namespace": "", "time_ms": 1684167367951, "event_type": "POINT_IN_TIME", "key": "num_image_candidates", "value": 12000, "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 536}}
:::MLLOG {"namespace": "", "time_ms": 1684167367951, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 537}}
0 :: dedicated_evaluation_ranks = 0, num_training_ranks = 8, images_per_batch_train = 96, images_per_gpu_train = 12, rank_train = 0, rank_in_group_train = 0, spatial_group_size_train = 1, num_evaluation_ranks = 8, images_per_batch_test = 96, images_per_gpu_test = 12, rank_test = 0, rank_in_group_test = 0, spatial_group_size_test = 1
0 :: is_training_rank = True, is_evaluation_rank = True
0 :: batch_size_one=False, images_per_gpu_train=12, images_per_gpu_test=12
:::MLLOG {"namespace": "", "time_ms": 1684167368234, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 60, "tensor": "FPN_inner_block1"}}
:::MLLOG {"namespace": "", "time_ms": 1684167368241, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 64, "tensor": "FPN_layer_block1"}}
:::MLLOG {"namespace": "", "time_ms": 1684167368243, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 60, "tensor": "FPN_inner_block2"}}
:::MLLOG {"namespace": "", "time_ms": 1684167368250, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 64, "tensor": "FPN_layer_block2"}}
:::MLLOG {"namespace": "", "time_ms": 1684167368252, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 60, "tensor": "FPN_inner_block3"}}
:::MLLOG {"namespace": "", "time_ms": 1684167368258, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 64, "tensor": "FPN_layer_block3"}}
:::MLLOG {"namespace": "", "time_ms": 1684167368261, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 60, "tensor": "FPN_inner_block4"}}
:::MLLOG {"namespace": "", "time_ms": 1684167368267, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py", "lineno": 64, "tensor": "FPN_layer_block4"}}
:::MLLOG {"namespace": "", "time_ms": 1684167368288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/modeling/rpn/rpn.py", "lineno": 51, "tensor": "RPNHead_conv"}}
:::MLLOG {"namespace": "", "time_ms": 1684167368288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/modeling/rpn/rpn.py", "lineno": 52, "tensor": "RPNHead_cls"}}
:::MLLOG {"namespace": "", "time_ms": 1684167368288, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/modeling/rpn/rpn.py", "lineno": 53, "tensor": "RPNHead_bbox"}}
:::MLLOG {"namespace": "", "time_ms": 1684167368381, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_feature_extractors.py", "lineno": 95, "tensor": "ROI_BOX_FEATURE_EXTRACTOR_fc6"}}
:::MLLOG {"namespace": "", "time_ms": 1684167368390, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_feature_extractors.py", "lineno": 99, "tensor": "ROI_BOX_FEATURE_EXTRACTOR_fc7"}}
:::MLLOG {"namespace": "", "time_ms": 1684167368392, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py", "lineno": 50, "tensor": "ROI_BOX_PREDICTOR_cls"}}
:::MLLOG {"namespace": "", "time_ms": 1684167368394, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py", "lineno": 53, "tensor": "ROI_BOX_PREDICTOR_bbox"}}
:::MLLOG {"namespace": "", "time_ms": 1684167368402, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py", "lineno": 80, "tensor": "ROI_MASK_FEATURE_EXTRACTOR_fcn1"}}
:::MLLOG {"namespace": "", "time_ms": 1684167368408, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py", "lineno": 80, "tensor": "ROI_MASK_FEATURE_EXTRACTOR_fcn2"}}
:::MLLOG {"namespace": "", "time_ms": 1684167368415, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py", "lineno": 80, "tensor": "ROI_MASK_FEATURE_EXTRACTOR_fcn3"}}
:::MLLOG {"namespace": "", "time_ms": 1684167368421, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py", "lineno": 80, "tensor": "ROI_MASK_FEATURE_EXTRACTOR_fcn4"}}
/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:1130: UserWarning: _ConvTransposeMixin is a deprecated internal class. Please consider using public APIs.
  warnings.warn(
:::MLLOG {"namespace": "", "time_ms": 1684167368425, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_predictors.py", "lineno": 54, "tensor": "ROI_MASK_PREDICTOR_fcn5"}}
:::MLLOG {"namespace": "", "time_ms": 1684167368425, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_predictors.py", "lineno": 55, "tensor": "ROI_MASK_PREDICTOR_fcn_logits"}}
2023-05-15 16:16:08,427 maskrcnn_benchmark.trainer INFO: Changed spatial parallel args for 16 SpatialBottleneck modules.
2023-05-15 16:16:08,427 maskrcnn_benchmark.trainer INFO: Reconfigured 1 GatherTensors modules.
2023-05-15 16:16:08,427 maskrcnn_benchmark.trainer INFO: Reconfigured 1 BaseStem modules.
2023-05-15 16:16:08,870 maskrcnn_benchmark.trainer INFO: Changed spatial parallel args for 16 SpatialBottleneck modules.
2023-05-15 16:16:08,870 maskrcnn_benchmark.trainer INFO: Reconfigured 1 GatherTensors modules.
2023-05-15 16:16:08,870 maskrcnn_benchmark.trainer INFO: Reconfigured 1 BaseStem modules.
2023-05-15 16:16:08,959 maskrcnn_benchmark.trainer INFO: Training shapes are [(1344, 800), (800, 1344)]
2023-05-15 16:16:08,959 maskrcnn_benchmark.trainer INFO: testing shapes are [(1344, 800), (800, 1344)]
USE_CUDA_GRAPH :: per_gpu_batch_sizes = [(True, 12), (False, 12)]
2023-05-15 16:16:08,967 maskrcnn_benchmark.trainer INFO: Changed spatial parallel args for 16 SpatialBottleneck modules.
2023-05-15 16:16:08,967 maskrcnn_benchmark.trainer INFO: Reconfigured 1 GatherTensors modules.
2023-05-15 16:16:08,967 maskrcnn_benchmark.trainer INFO: Reconfigured 1 BaseStem modules.
0 :: Gatherered torch.Size([12, 336, 200, 256]) -> [12, 336, 200, 256]
0 :: Gatherered torch.Size([12, 168, 100, 512]) -> [12, 168, 100, 512]
0 :: Gatherered torch.Size([12, 84, 50, 1024]) -> [12, 84, 50, 1024]
0 :: Gatherered torch.Size([12, 42, 25, 2048]) -> [12, 42, 25, 2048]
Graphing

Graphing

Graphing

Graphing

Graphing

Graphing

Graphing

0 :: Gatherered torch.Size([12, 336, 200, 256]) -> [12, 336, 200, 256]
0 :: Gatherered torch.Size([12, 168, 100, 512]) -> [12, 168, 100, 512]
0 :: Gatherered torch.Size([12, 84, 50, 1024]) -> [12, 84, 50, 1024]
0 :: Gatherered torch.Size([12, 42, 25, 2048]) -> [12, 42, 25, 2048]
0 :: Gatherered torch.Size([12, 336, 200, 256]) -> [12, 336, 200, 256]
0 :: Gatherered torch.Size([12, 168, 100, 512]) -> [12, 168, 100, 512]
0 :: Gatherered torch.Size([12, 84, 50, 1024]) -> [12, 84, 50, 1024]
0 :: Gatherered torch.Size([12, 42, 25, 2048]) -> [12, 42, 25, 2048]
0 :: Gatherered torch.Size([12, 336, 200, 256]) -> [12, 336, 200, 256]
0 :: Gatherered torch.Size([12, 168, 100, 512]) -> [12, 168, 100, 512]
0 :: Gatherered torch.Size([12, 84, 50, 1024]) -> [12, 84, 50, 1024]
0 :: Gatherered torch.Size([12, 42, 25, 2048]) -> [12, 42, 25, 2048]
Graphing

0 :: Gatherered torch.Size([12, 336, 200, 256]) -> [12, 336, 200, 256]
0 :: Gatherered torch.Size([12, 168, 100, 512]) -> [12, 168, 100, 512]
0 :: Gatherered torch.Size([12, 84, 50, 1024]) -> [12, 84, 50, 1024]
0 :: Gatherered torch.Size([12, 42, 25, 2048]) -> [12, 42, 25, 2048]
0 :: Gatherered torch.Size([12, 200, 336, 256]) -> [12, 200, 336, 256]
0 :: Gatherered torch.Size([12, 100, 168, 512]) -> [12, 100, 168, 512]
0 :: Gatherered torch.Size([12, 50, 84, 1024]) -> [12, 50, 84, 1024]
0 :: Gatherered torch.Size([12, 25, 42, 2048]) -> [12, 25, 42, 2048]
Graphing

Graphing

Graphing

Graphing

Graphing

Graphing

Graphing

Graphing

Graphing

Graphing

Graphing

Graphing

Graphing

Graphing

Graphing

Graphing

Graphing

Graphing

Graphing

Graphing

Graphing

0 :: Gatherered torch.Size([12, 200, 336, 256]) -> [12, 200, 336, 256]
0 :: Gatherered torch.Size([12, 100, 168, 512]) -> [12, 100, 168, 512]
0 :: Gatherered torch.Size([12, 50, 84, 1024]) -> [12, 50, 84, 1024]
0 :: Gatherered torch.Size([12, 25, 42, 2048]) -> [12, 25, 42, 2048]
Graphing

0 :: Gatherered torch.Size([12, 200, 336, 256]) -> [12, 200, 336, 256]
0 :: Gatherered torch.Size([12, 100, 168, 512]) -> [12, 100, 168, 512]
0 :: Gatherered torch.Size([12, 50, 84, 1024]) -> [12, 50, 84, 1024]
0 :: Gatherered torch.Size([12, 25, 42, 2048]) -> [12, 25, 42, 2048]
2023-05-15 16:17:41,440 maskrcnn_benchmark.trainer INFO: Changed spatial parallel args for 16 SpatialBottleneck modules.
2023-05-15 16:17:41,440 maskrcnn_benchmark.trainer INFO: Reconfigured 1 GatherTensors modules.
2023-05-15 16:17:41,440 maskrcnn_benchmark.trainer INFO: Reconfigured 1 BaseStem modules.
0 :: Gatherered torch.Size([12, 336, 200, 256]) -> [12, 336, 200, 256]
0 :: Gatherered torch.Size([12, 168, 100, 512]) -> [12, 168, 100, 512]
0 :: Gatherered torch.Size([12, 84, 50, 1024]) -> [12, 84, 50, 1024]
0 :: Gatherered torch.Size([12, 42, 25, 2048]) -> [12, 42, 25, 2048]
0 :: Gatherered torch.Size([12, 336, 200, 256]) -> [12, 336, 200, 256]
0 :: Gatherered torch.Size([12, 168, 100, 512]) -> [12, 168, 100, 512]
0 :: Gatherered torch.Size([12, 84, 50, 1024]) -> [12, 84, 50, 1024]
0 :: Gatherered torch.Size([12, 42, 25, 2048]) -> [12, 42, 25, 2048]
0 :: Gatherered torch.Size([12, 336, 200, 256]) -> [12, 336, 200, 256]
0 :: Gatherered torch.Size([12, 168, 100, 512]) -> [12, 168, 100, 512]
0 :: Gatherered torch.Size([12, 84, 50, 1024]) -> [12, 84, 50, 1024]
0 :: Gatherered torch.Size([12, 42, 25, 2048]) -> [12, 42, 25, 2048]
0 :: Gatherered torch.Size([12, 336, 200, 256]) -> [12, 336, 200, 256]
0 :: Gatherered torch.Size([12, 168, 100, 512]) -> [12, 168, 100, 512]
0 :: Gatherered torch.Size([12, 84, 50, 1024]) -> [12, 84, 50, 1024]
0 :: Gatherered torch.Size([12, 42, 25, 2048]) -> [12, 42, 25, 2048]
Graphing

0 :: Gatherered torch.Size([12, 336, 200, 256]) -> [12, 336, 200, 256]
0 :: Gatherered torch.Size([12, 168, 100, 512]) -> [12, 168, 100, 512]
0 :: Gatherered torch.Size([12, 84, 50, 1024]) -> [12, 84, 50, 1024]
0 :: Gatherered torch.Size([12, 42, 25, 2048]) -> [12, 42, 25, 2048]
0 :: Gatherered torch.Size([12, 200, 336, 256]) -> [12, 200, 336, 256]
0 :: Gatherered torch.Size([12, 100, 168, 512]) -> [12, 100, 168, 512]
0 :: Gatherered torch.Size([12, 50, 84, 1024]) -> [12, 50, 84, 1024]
0 :: Gatherered torch.Size([12, 25, 42, 2048]) -> [12, 25, 42, 2048]
0 :: Gatherered torch.Size([12, 200, 336, 256]) -> [12, 200, 336, 256]
0 :: Gatherered torch.Size([12, 100, 168, 512]) -> [12, 100, 168, 512]
0 :: Gatherered torch.Size([12, 50, 84, 1024]) -> [12, 50, 84, 1024]
0 :: Gatherered torch.Size([12, 25, 42, 2048]) -> [12, 25, 42, 2048]
Graphing

0 :: Gatherered torch.Size([12, 200, 336, 256]) -> [12, 200, 336, 256]
0 :: Gatherered torch.Size([12, 100, 168, 512]) -> [12, 100, 168, 512]
0 :: Gatherered torch.Size([12, 50, 84, 1024]) -> [12, 50, 84, 1024]
0 :: Gatherered torch.Size([12, 25, 42, 2048]) -> [12, 25, 42, 2048]
0 :: self.fp16_group_index=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0',
       dtype=torch.int32)
:::MLLOG {"namespace": "", "time_ms": 1684167461851, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "sgd_with_momentum", "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 779}}
:::MLLOG {"namespace": "", "time_ms": 1684167461851, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.12, "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 780}}
:::MLLOG {"namespace": "", "time_ms": 1684167461851, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_steps", "value": 625, "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 781}}
:::MLLOG {"namespace": "", "time_ms": 1684167461851, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0.000192, "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 782}}
:::MLLOG {"namespace": "", "time_ms": 1684167461851, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_factor", "value": 0.1, "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 783}}
:::MLLOG {"namespace": "", "time_ms": 1684167461851, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_steps", "value": [12000, 16000], "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 784}}
:::MLLOG {"namespace": "", "time_ms": 1684167461851, "event_type": "POINT_IN_TIME", "key": "min_image_size", "value": 800, "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 785}}
:::MLLOG {"namespace": "", "time_ms": 1684167461851, "event_type": "POINT_IN_TIME", "key": "max_image_size", "value": 1333, "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 786}}
2023-05-15 16:17:41,855 maskrcnn_benchmark.utils.checkpoint INFO: Loading checkpoint from /coco/models/R-50.pkl
2023-05-15 16:17:41,920 maskrcnn_benchmark.utils.c2_model_loading INFO: Remapping C2 weights
2023-05-15 16:17:41,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: conv1_b              mapped name: conv1.bias
2023-05-15 16:17:41,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: conv1_w              mapped name: conv1.weight
2023-05-15 16:17:41,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fc1000_b             mapped name: fc1000.bias
2023-05-15 16:17:41,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: fc1000_w             mapped name: fc1000.weight
2023-05-15 16:17:41,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_b     mapped name: layer1.0.downsample.0.bias
2023-05-15 16:17:41,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_b  mapped name: layer1.0.downsample.1.bias
2023-05-15 16:17:41,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_s  mapped name: layer1.0.downsample.1.weight
2023-05-15 16:17:41,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch1_w     mapped name: layer1.0.downsample.0.weight
2023-05-15 16:17:41,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_b    mapped name: layer1.0.conv1.bias
2023-05-15 16:17:41,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_b mapped name: layer1.0.bn1.bias
2023-05-15 16:17:41,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_s mapped name: layer1.0.bn1.weight
2023-05-15 16:17:41,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_w    mapped name: layer1.0.conv1.weight
2023-05-15 16:17:41,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_b    mapped name: layer1.0.conv2.bias
2023-05-15 16:17:41,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_b mapped name: layer1.0.bn2.bias
2023-05-15 16:17:41,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_s mapped name: layer1.0.bn2.weight
2023-05-15 16:17:41,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_w    mapped name: layer1.0.conv2.weight
2023-05-15 16:17:41,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_b    mapped name: layer1.0.conv3.bias
2023-05-15 16:17:41,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_b mapped name: layer1.0.bn3.bias
2023-05-15 16:17:41,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_s mapped name: layer1.0.bn3.weight
2023-05-15 16:17:41,920 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_w    mapped name: layer1.0.conv3.weight
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_b    mapped name: layer1.1.conv1.bias
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_b mapped name: layer1.1.bn1.bias
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_s mapped name: layer1.1.bn1.weight
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_w    mapped name: layer1.1.conv1.weight
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_b    mapped name: layer1.1.conv2.bias
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_b mapped name: layer1.1.bn2.bias
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_s mapped name: layer1.1.bn2.weight
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_w    mapped name: layer1.1.conv2.weight
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_b    mapped name: layer1.1.conv3.bias
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_b mapped name: layer1.1.bn3.bias
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_s mapped name: layer1.1.bn3.weight
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_w    mapped name: layer1.1.conv3.weight
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_b    mapped name: layer1.2.conv1.bias
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_b mapped name: layer1.2.bn1.bias
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_s mapped name: layer1.2.bn1.weight
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_w    mapped name: layer1.2.conv1.weight
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_b    mapped name: layer1.2.conv2.bias
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_b mapped name: layer1.2.bn2.bias
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_s mapped name: layer1.2.bn2.weight
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_w    mapped name: layer1.2.conv2.weight
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_b    mapped name: layer1.2.conv3.bias
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_b mapped name: layer1.2.bn3.bias
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_s mapped name: layer1.2.bn3.weight
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_w    mapped name: layer1.2.conv3.weight
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_b     mapped name: layer2.0.downsample.0.bias
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_b  mapped name: layer2.0.downsample.1.bias
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_s  mapped name: layer2.0.downsample.1.weight
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch1_w     mapped name: layer2.0.downsample.0.weight
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_b    mapped name: layer2.0.conv1.bias
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_b mapped name: layer2.0.bn1.bias
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_s mapped name: layer2.0.bn1.weight
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_w    mapped name: layer2.0.conv1.weight
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_b    mapped name: layer2.0.conv2.bias
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_b mapped name: layer2.0.bn2.bias
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_s mapped name: layer2.0.bn2.weight
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_w    mapped name: layer2.0.conv2.weight
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_b    mapped name: layer2.0.conv3.bias
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_b mapped name: layer2.0.bn3.bias
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_s mapped name: layer2.0.bn3.weight
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_w    mapped name: layer2.0.conv3.weight
2023-05-15 16:17:41,921 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_b    mapped name: layer2.1.conv1.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_b mapped name: layer2.1.bn1.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_s mapped name: layer2.1.bn1.weight
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_w    mapped name: layer2.1.conv1.weight
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_b    mapped name: layer2.1.conv2.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_b mapped name: layer2.1.bn2.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_s mapped name: layer2.1.bn2.weight
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_w    mapped name: layer2.1.conv2.weight
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_b    mapped name: layer2.1.conv3.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_b mapped name: layer2.1.bn3.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_s mapped name: layer2.1.bn3.weight
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_w    mapped name: layer2.1.conv3.weight
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_b    mapped name: layer2.2.conv1.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_b mapped name: layer2.2.bn1.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_s mapped name: layer2.2.bn1.weight
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_w    mapped name: layer2.2.conv1.weight
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_b    mapped name: layer2.2.conv2.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_b mapped name: layer2.2.bn2.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_s mapped name: layer2.2.bn2.weight
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_w    mapped name: layer2.2.conv2.weight
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_b    mapped name: layer2.2.conv3.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_b mapped name: layer2.2.bn3.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_s mapped name: layer2.2.bn3.weight
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_w    mapped name: layer2.2.conv3.weight
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_b    mapped name: layer2.3.conv1.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_b mapped name: layer2.3.bn1.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_s mapped name: layer2.3.bn1.weight
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_w    mapped name: layer2.3.conv1.weight
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_b    mapped name: layer2.3.conv2.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_b mapped name: layer2.3.bn2.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_s mapped name: layer2.3.bn2.weight
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_w    mapped name: layer2.3.conv2.weight
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_b    mapped name: layer2.3.conv3.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_b mapped name: layer2.3.bn3.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_s mapped name: layer2.3.bn3.weight
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_w    mapped name: layer2.3.conv3.weight
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_b     mapped name: layer3.0.downsample.0.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_b  mapped name: layer3.0.downsample.1.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_s  mapped name: layer3.0.downsample.1.weight
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch1_w     mapped name: layer3.0.downsample.0.weight
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_b    mapped name: layer3.0.conv1.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_b mapped name: layer3.0.bn1.bias
2023-05-15 16:17:41,922 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_s mapped name: layer3.0.bn1.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_w    mapped name: layer3.0.conv1.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_b    mapped name: layer3.0.conv2.bias
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_b mapped name: layer3.0.bn2.bias
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_s mapped name: layer3.0.bn2.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_w    mapped name: layer3.0.conv2.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_b    mapped name: layer3.0.conv3.bias
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_b mapped name: layer3.0.bn3.bias
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_s mapped name: layer3.0.bn3.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_w    mapped name: layer3.0.conv3.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_b    mapped name: layer3.1.conv1.bias
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_b mapped name: layer3.1.bn1.bias
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_s mapped name: layer3.1.bn1.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_w    mapped name: layer3.1.conv1.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_b    mapped name: layer3.1.conv2.bias
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_b mapped name: layer3.1.bn2.bias
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_s mapped name: layer3.1.bn2.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_w    mapped name: layer3.1.conv2.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_b    mapped name: layer3.1.conv3.bias
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_b mapped name: layer3.1.bn3.bias
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_s mapped name: layer3.1.bn3.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_w    mapped name: layer3.1.conv3.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_b    mapped name: layer3.2.conv1.bias
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_b mapped name: layer3.2.bn1.bias
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_s mapped name: layer3.2.bn1.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_w    mapped name: layer3.2.conv1.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_b    mapped name: layer3.2.conv2.bias
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_b mapped name: layer3.2.bn2.bias
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_s mapped name: layer3.2.bn2.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_w    mapped name: layer3.2.conv2.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_b    mapped name: layer3.2.conv3.bias
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_b mapped name: layer3.2.bn3.bias
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_s mapped name: layer3.2.bn3.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_w    mapped name: layer3.2.conv3.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_b    mapped name: layer3.3.conv1.bias
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_b mapped name: layer3.3.bn1.bias
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_s mapped name: layer3.3.bn1.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_w    mapped name: layer3.3.conv1.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_b    mapped name: layer3.3.conv2.bias
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_b mapped name: layer3.3.bn2.bias
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_s mapped name: layer3.3.bn2.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_w    mapped name: layer3.3.conv2.weight
2023-05-15 16:17:41,923 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_b    mapped name: layer3.3.conv3.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_b mapped name: layer3.3.bn3.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_s mapped name: layer3.3.bn3.weight
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_w    mapped name: layer3.3.conv3.weight
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_b    mapped name: layer3.4.conv1.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_b mapped name: layer3.4.bn1.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_s mapped name: layer3.4.bn1.weight
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_w    mapped name: layer3.4.conv1.weight
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_b    mapped name: layer3.4.conv2.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_b mapped name: layer3.4.bn2.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_s mapped name: layer3.4.bn2.weight
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_w    mapped name: layer3.4.conv2.weight
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_b    mapped name: layer3.4.conv3.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_b mapped name: layer3.4.bn3.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_s mapped name: layer3.4.bn3.weight
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_w    mapped name: layer3.4.conv3.weight
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_b    mapped name: layer3.5.conv1.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_b mapped name: layer3.5.bn1.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_s mapped name: layer3.5.bn1.weight
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_w    mapped name: layer3.5.conv1.weight
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_b    mapped name: layer3.5.conv2.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_b mapped name: layer3.5.bn2.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_s mapped name: layer3.5.bn2.weight
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_w    mapped name: layer3.5.conv2.weight
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_b    mapped name: layer3.5.conv3.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_b mapped name: layer3.5.bn3.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_s mapped name: layer3.5.bn3.weight
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_w    mapped name: layer3.5.conv3.weight
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_b     mapped name: layer4.0.downsample.0.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_b  mapped name: layer4.0.downsample.1.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_s  mapped name: layer4.0.downsample.1.weight
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch1_w     mapped name: layer4.0.downsample.0.weight
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_b    mapped name: layer4.0.conv1.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_b mapped name: layer4.0.bn1.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_s mapped name: layer4.0.bn1.weight
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_w    mapped name: layer4.0.conv1.weight
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_b    mapped name: layer4.0.conv2.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_b mapped name: layer4.0.bn2.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_s mapped name: layer4.0.bn2.weight
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_w    mapped name: layer4.0.conv2.weight
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_b    mapped name: layer4.0.conv3.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_b mapped name: layer4.0.bn3.bias
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_s mapped name: layer4.0.bn3.weight
2023-05-15 16:17:41,924 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_w    mapped name: layer4.0.conv3.weight
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_b    mapped name: layer4.1.conv1.bias
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_b mapped name: layer4.1.bn1.bias
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_s mapped name: layer4.1.bn1.weight
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_w    mapped name: layer4.1.conv1.weight
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_b    mapped name: layer4.1.conv2.bias
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_b mapped name: layer4.1.bn2.bias
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_s mapped name: layer4.1.bn2.weight
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_w    mapped name: layer4.1.conv2.weight
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_b    mapped name: layer4.1.conv3.bias
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_b mapped name: layer4.1.bn3.bias
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_s mapped name: layer4.1.bn3.weight
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_w    mapped name: layer4.1.conv3.weight
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_b    mapped name: layer4.2.conv1.bias
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_b mapped name: layer4.2.bn1.bias
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_s mapped name: layer4.2.bn1.weight
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_w    mapped name: layer4.2.conv1.weight
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_b    mapped name: layer4.2.conv2.bias
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_b mapped name: layer4.2.bn2.bias
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_s mapped name: layer4.2.bn2.weight
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_w    mapped name: layer4.2.conv2.weight
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_b    mapped name: layer4.2.conv3.bias
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_b mapped name: layer4.2.bn3.bias
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_s mapped name: layer4.2.bn3.weight
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_w    mapped name: layer4.2.conv3.weight
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res_conv1_bn_b       mapped name: bn1.bias
2023-05-15 16:17:41,925 maskrcnn_benchmark.utils.c2_model_loading INFO: C2 name: res_conv1_bn_s       mapped name: bn1.weight
2023-05-15 16:17:41,935 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.0.bn1.bias                     loaded from layer1.0.bn1.bias            of shape (64,)
2023-05-15 16:17:41,935 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.0.bn1.weight                   loaded from layer1.0.bn1.weight          of shape (64,)
2023-05-15 16:17:41,935 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.0.bn2.bias                     loaded from layer1.0.bn2.bias            of shape (64,)
2023-05-15 16:17:41,935 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.0.bn2.weight                   loaded from layer1.0.bn2.weight          of shape (64,)
2023-05-15 16:17:41,935 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.0.bn3.bias                     loaded from layer1.0.bn3.bias            of shape (256,)
2023-05-15 16:17:41,935 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.0.bn3.weight                   loaded from layer1.0.bn3.weight          of shape (256,)
2023-05-15 16:17:41,935 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.0.conv1.weight                 loaded from layer1.0.conv1.weight        of shape (64, 64, 1, 1)
2023-05-15 16:17:41,935 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.0.conv2.weight                 loaded from layer1.0.conv2.weight        of shape (64, 64, 3, 3)
2023-05-15 16:17:41,935 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.0.conv3.weight                 loaded from layer1.0.conv3.weight        of shape (256, 64, 1, 1)
2023-05-15 16:17:41,935 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.0.downsample.0.weight          loaded from layer1.0.downsample.0.weight of shape (256, 64, 1, 1)
2023-05-15 16:17:41,935 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.0.downsample.1.bias            loaded from layer1.0.downsample.1.bias   of shape (256,)
2023-05-15 16:17:41,935 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.0.downsample.1.weight          loaded from layer1.0.downsample.1.weight of shape (256,)
2023-05-15 16:17:41,935 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.1.bn1.bias                     loaded from layer1.1.bn1.bias            of shape (64,)
2023-05-15 16:17:41,935 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.1.bn1.weight                   loaded from layer1.1.bn1.weight          of shape (64,)
2023-05-15 16:17:41,935 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.1.bn2.bias                     loaded from layer1.1.bn2.bias            of shape (64,)
2023-05-15 16:17:41,935 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.1.bn2.weight                   loaded from layer1.1.bn2.weight          of shape (64,)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.1.bn3.bias                     loaded from layer1.1.bn3.bias            of shape (256,)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.1.bn3.weight                   loaded from layer1.1.bn3.weight          of shape (256,)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.1.conv1.weight                 loaded from layer1.1.conv1.weight        of shape (64, 256, 1, 1)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.1.conv2.weight                 loaded from layer1.1.conv2.weight        of shape (64, 64, 3, 3)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.1.conv3.weight                 loaded from layer1.1.conv3.weight        of shape (256, 64, 1, 1)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.2.bn1.bias                     loaded from layer1.2.bn1.bias            of shape (64,)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.2.bn1.weight                   loaded from layer1.2.bn1.weight          of shape (64,)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.2.bn2.bias                     loaded from layer1.2.bn2.bias            of shape (64,)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.2.bn2.weight                   loaded from layer1.2.bn2.weight          of shape (64,)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.2.bn3.bias                     loaded from layer1.2.bn3.bias            of shape (256,)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.2.bn3.weight                   loaded from layer1.2.bn3.weight          of shape (256,)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.2.conv1.weight                 loaded from layer1.2.conv1.weight        of shape (64, 256, 1, 1)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.2.conv2.weight                 loaded from layer1.2.conv2.weight        of shape (64, 64, 3, 3)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer1.2.conv3.weight                 loaded from layer1.2.conv3.weight        of shape (256, 64, 1, 1)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.0.bn1.bias                     loaded from layer2.0.bn1.bias            of shape (128,)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.0.bn1.weight                   loaded from layer2.0.bn1.weight          of shape (128,)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.0.bn2.bias                     loaded from layer2.0.bn2.bias            of shape (128,)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.0.bn2.weight                   loaded from layer2.0.bn2.weight          of shape (128,)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.0.bn3.bias                     loaded from layer2.0.bn3.bias            of shape (512,)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.0.bn3.weight                   loaded from layer2.0.bn3.weight          of shape (512,)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.0.conv1.weight                 loaded from layer2.0.conv1.weight        of shape (128, 256, 1, 1)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.0.conv2.weight                 loaded from layer2.0.conv2.weight        of shape (128, 128, 3, 3)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.0.conv3.weight                 loaded from layer2.0.conv3.weight        of shape (512, 128, 1, 1)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.0.downsample.0.weight          loaded from layer2.0.downsample.0.weight of shape (512, 256, 1, 1)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.0.downsample.1.bias            loaded from layer2.0.downsample.1.bias   of shape (512,)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.0.downsample.1.weight          loaded from layer2.0.downsample.1.weight of shape (512,)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.1.bn1.bias                     loaded from layer2.1.bn1.bias            of shape (128,)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.1.bn1.weight                   loaded from layer2.1.bn1.weight          of shape (128,)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.1.bn2.bias                     loaded from layer2.1.bn2.bias            of shape (128,)
2023-05-15 16:17:41,936 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.1.bn2.weight                   loaded from layer2.1.bn2.weight          of shape (128,)
2023-05-15 16:17:41,937 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.1.bn3.bias                     loaded from layer2.1.bn3.bias            of shape (512,)
2023-05-15 16:17:41,937 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.1.bn3.weight                   loaded from layer2.1.bn3.weight          of shape (512,)
2023-05-15 16:17:41,937 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.1.conv1.weight                 loaded from layer2.1.conv1.weight        of shape (128, 512, 1, 1)
2023-05-15 16:17:41,937 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.1.conv2.weight                 loaded from layer2.1.conv2.weight        of shape (128, 128, 3, 3)
2023-05-15 16:17:41,937 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.1.conv3.weight                 loaded from layer2.1.conv3.weight        of shape (512, 128, 1, 1)
2023-05-15 16:17:41,937 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.2.bn1.bias                     loaded from layer2.2.bn1.bias            of shape (128,)
2023-05-15 16:17:41,937 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.2.bn1.weight                   loaded from layer2.2.bn1.weight          of shape (128,)
2023-05-15 16:17:41,937 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.2.bn2.bias                     loaded from layer2.2.bn2.bias            of shape (128,)
2023-05-15 16:17:41,937 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.2.bn2.weight                   loaded from layer2.2.bn2.weight          of shape (128,)
2023-05-15 16:17:41,937 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.2.bn3.bias                     loaded from layer2.2.bn3.bias            of shape (512,)
2023-05-15 16:17:41,937 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.2.bn3.weight                   loaded from layer2.2.bn3.weight          of shape (512,)
2023-05-15 16:17:41,937 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.2.conv1.weight                 loaded from layer2.2.conv1.weight        of shape (128, 512, 1, 1)
2023-05-15 16:17:41,937 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.2.conv2.weight                 loaded from layer2.2.conv2.weight        of shape (128, 128, 3, 3)
2023-05-15 16:17:41,937 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.2.conv3.weight                 loaded from layer2.2.conv3.weight        of shape (512, 128, 1, 1)
2023-05-15 16:17:41,937 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.3.bn1.bias                     loaded from layer2.3.bn1.bias            of shape (128,)
2023-05-15 16:17:41,937 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.3.bn1.weight                   loaded from layer2.3.bn1.weight          of shape (128,)
2023-05-15 16:17:41,937 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.3.bn2.bias                     loaded from layer2.3.bn2.bias            of shape (128,)
2023-05-15 16:17:41,937 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.3.bn2.weight                   loaded from layer2.3.bn2.weight          of shape (128,)
2023-05-15 16:17:41,937 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.3.bn3.bias                     loaded from layer2.3.bn3.bias            of shape (512,)
2023-05-15 16:17:41,937 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.3.bn3.weight                   loaded from layer2.3.bn3.weight          of shape (512,)
2023-05-15 16:17:41,937 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.3.conv1.weight                 loaded from layer2.3.conv1.weight        of shape (128, 512, 1, 1)
2023-05-15 16:17:41,938 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.3.conv2.weight                 loaded from layer2.3.conv2.weight        of shape (128, 128, 3, 3)
2023-05-15 16:17:41,938 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer2.3.conv3.weight                 loaded from layer2.3.conv3.weight        of shape (512, 128, 1, 1)
2023-05-15 16:17:41,938 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.0.bn1.bias                     loaded from layer3.0.bn1.bias            of shape (256,)
2023-05-15 16:17:41,938 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.0.bn1.weight                   loaded from layer3.0.bn1.weight          of shape (256,)
2023-05-15 16:17:41,938 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.0.bn2.bias                     loaded from layer3.0.bn2.bias            of shape (256,)
2023-05-15 16:17:41,938 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.0.bn2.weight                   loaded from layer3.0.bn2.weight          of shape (256,)
2023-05-15 16:17:41,938 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.0.bn3.bias                     loaded from layer3.0.bn3.bias            of shape (1024,)
2023-05-15 16:17:41,938 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.0.bn3.weight                   loaded from layer3.0.bn3.weight          of shape (1024,)
2023-05-15 16:17:41,938 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.0.conv1.weight                 loaded from layer3.0.conv1.weight        of shape (256, 512, 1, 1)
2023-05-15 16:17:41,938 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.0.conv2.weight                 loaded from layer3.0.conv2.weight        of shape (256, 256, 3, 3)
2023-05-15 16:17:41,938 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.0.conv3.weight                 loaded from layer3.0.conv3.weight        of shape (1024, 256, 1, 1)
2023-05-15 16:17:41,939 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.0.downsample.0.weight          loaded from layer3.0.downsample.0.weight of shape (1024, 512, 1, 1)
2023-05-15 16:17:41,939 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.0.downsample.1.bias            loaded from layer3.0.downsample.1.bias   of shape (1024,)
2023-05-15 16:17:41,939 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.0.downsample.1.weight          loaded from layer3.0.downsample.1.weight of shape (1024,)
2023-05-15 16:17:41,939 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.1.bn1.bias                     loaded from layer3.1.bn1.bias            of shape (256,)
2023-05-15 16:17:41,939 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.1.bn1.weight                   loaded from layer3.1.bn1.weight          of shape (256,)
2023-05-15 16:17:41,939 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.1.bn2.bias                     loaded from layer3.1.bn2.bias            of shape (256,)
2023-05-15 16:17:41,939 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.1.bn2.weight                   loaded from layer3.1.bn2.weight          of shape (256,)
2023-05-15 16:17:41,939 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.1.bn3.bias                     loaded from layer3.1.bn3.bias            of shape (1024,)
2023-05-15 16:17:41,939 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.1.bn3.weight                   loaded from layer3.1.bn3.weight          of shape (1024,)
2023-05-15 16:17:41,939 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.1.conv1.weight                 loaded from layer3.1.conv1.weight        of shape (256, 1024, 1, 1)
2023-05-15 16:17:41,940 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.1.conv2.weight                 loaded from layer3.1.conv2.weight        of shape (256, 256, 3, 3)
2023-05-15 16:17:41,940 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.1.conv3.weight                 loaded from layer3.1.conv3.weight        of shape (1024, 256, 1, 1)
2023-05-15 16:17:41,940 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.2.bn1.bias                     loaded from layer3.2.bn1.bias            of shape (256,)
2023-05-15 16:17:41,940 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.2.bn1.weight                   loaded from layer3.2.bn1.weight          of shape (256,)
2023-05-15 16:17:41,940 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.2.bn2.bias                     loaded from layer3.2.bn2.bias            of shape (256,)
2023-05-15 16:17:41,940 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.2.bn2.weight                   loaded from layer3.2.bn2.weight          of shape (256,)
2023-05-15 16:17:41,940 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.2.bn3.bias                     loaded from layer3.2.bn3.bias            of shape (1024,)
2023-05-15 16:17:41,940 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.2.bn3.weight                   loaded from layer3.2.bn3.weight          of shape (1024,)
2023-05-15 16:17:41,940 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.2.conv1.weight                 loaded from layer3.2.conv1.weight        of shape (256, 1024, 1, 1)
2023-05-15 16:17:41,941 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.2.conv2.weight                 loaded from layer3.2.conv2.weight        of shape (256, 256, 3, 3)
2023-05-15 16:17:41,941 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.2.conv3.weight                 loaded from layer3.2.conv3.weight        of shape (1024, 256, 1, 1)
2023-05-15 16:17:41,941 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.3.bn1.bias                     loaded from layer3.3.bn1.bias            of shape (256,)
2023-05-15 16:17:41,941 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.3.bn1.weight                   loaded from layer3.3.bn1.weight          of shape (256,)
2023-05-15 16:17:41,941 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.3.bn2.bias                     loaded from layer3.3.bn2.bias            of shape (256,)
2023-05-15 16:17:41,941 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.3.bn2.weight                   loaded from layer3.3.bn2.weight          of shape (256,)
2023-05-15 16:17:41,941 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.3.bn3.bias                     loaded from layer3.3.bn3.bias            of shape (1024,)
2023-05-15 16:17:41,941 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.3.bn3.weight                   loaded from layer3.3.bn3.weight          of shape (1024,)
2023-05-15 16:17:41,941 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.3.conv1.weight                 loaded from layer3.3.conv1.weight        of shape (256, 1024, 1, 1)
2023-05-15 16:17:41,942 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.3.conv2.weight                 loaded from layer3.3.conv2.weight        of shape (256, 256, 3, 3)
2023-05-15 16:17:41,942 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.3.conv3.weight                 loaded from layer3.3.conv3.weight        of shape (1024, 256, 1, 1)
2023-05-15 16:17:41,942 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.4.bn1.bias                     loaded from layer3.4.bn1.bias            of shape (256,)
2023-05-15 16:17:41,942 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.4.bn1.weight                   loaded from layer3.4.bn1.weight          of shape (256,)
2023-05-15 16:17:41,942 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.4.bn2.bias                     loaded from layer3.4.bn2.bias            of shape (256,)
2023-05-15 16:17:41,943 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.4.bn2.weight                   loaded from layer3.4.bn2.weight          of shape (256,)
2023-05-15 16:17:41,943 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.4.bn3.bias                     loaded from layer3.4.bn3.bias            of shape (1024,)
2023-05-15 16:17:41,943 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.4.bn3.weight                   loaded from layer3.4.bn3.weight          of shape (1024,)
2023-05-15 16:17:41,943 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.4.conv1.weight                 loaded from layer3.4.conv1.weight        of shape (256, 1024, 1, 1)
2023-05-15 16:17:41,944 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.4.conv2.weight                 loaded from layer3.4.conv2.weight        of shape (256, 256, 3, 3)
2023-05-15 16:17:41,944 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.4.conv3.weight                 loaded from layer3.4.conv3.weight        of shape (1024, 256, 1, 1)
2023-05-15 16:17:41,944 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.5.bn1.bias                     loaded from layer3.5.bn1.bias            of shape (256,)
2023-05-15 16:17:41,944 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.5.bn1.weight                   loaded from layer3.5.bn1.weight          of shape (256,)
2023-05-15 16:17:41,944 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.5.bn2.bias                     loaded from layer3.5.bn2.bias            of shape (256,)
2023-05-15 16:17:41,944 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.5.bn2.weight                   loaded from layer3.5.bn2.weight          of shape (256,)
2023-05-15 16:17:41,944 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.5.bn3.bias                     loaded from layer3.5.bn3.bias            of shape (1024,)
2023-05-15 16:17:41,944 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.5.bn3.weight                   loaded from layer3.5.bn3.weight          of shape (1024,)
2023-05-15 16:17:41,944 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.5.conv1.weight                 loaded from layer3.5.conv1.weight        of shape (256, 1024, 1, 1)
2023-05-15 16:17:41,945 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.5.conv2.weight                 loaded from layer3.5.conv2.weight        of shape (256, 256, 3, 3)
2023-05-15 16:17:41,945 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer3.5.conv3.weight                 loaded from layer3.5.conv3.weight        of shape (1024, 256, 1, 1)
2023-05-15 16:17:41,945 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.0.bn1.bias                     loaded from layer4.0.bn1.bias            of shape (512,)
2023-05-15 16:17:41,945 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.0.bn1.weight                   loaded from layer4.0.bn1.weight          of shape (512,)
2023-05-15 16:17:41,945 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.0.bn2.bias                     loaded from layer4.0.bn2.bias            of shape (512,)
2023-05-15 16:17:41,945 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.0.bn2.weight                   loaded from layer4.0.bn2.weight          of shape (512,)
2023-05-15 16:17:41,945 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.0.bn3.bias                     loaded from layer4.0.bn3.bias            of shape (2048,)
2023-05-15 16:17:41,945 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.0.bn3.weight                   loaded from layer4.0.bn3.weight          of shape (2048,)
2023-05-15 16:17:41,945 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.0.conv1.weight                 loaded from layer4.0.conv1.weight        of shape (512, 1024, 1, 1)
2023-05-15 16:17:41,949 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.0.conv2.weight                 loaded from layer4.0.conv2.weight        of shape (512, 512, 3, 3)
2023-05-15 16:17:41,949 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.0.conv3.weight                 loaded from layer4.0.conv3.weight        of shape (2048, 512, 1, 1)
2023-05-15 16:17:41,949 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.0.downsample.0.weight          loaded from layer4.0.downsample.0.weight of shape (2048, 1024, 1, 1)
2023-05-15 16:17:41,949 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.0.downsample.1.bias            loaded from layer4.0.downsample.1.bias   of shape (2048,)
2023-05-15 16:17:41,949 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.0.downsample.1.weight          loaded from layer4.0.downsample.1.weight of shape (2048,)
2023-05-15 16:17:41,949 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.1.bn1.bias                     loaded from layer4.1.bn1.bias            of shape (512,)
2023-05-15 16:17:41,949 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.1.bn1.weight                   loaded from layer4.1.bn1.weight          of shape (512,)
2023-05-15 16:17:41,949 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.1.bn2.bias                     loaded from layer4.1.bn2.bias            of shape (512,)
2023-05-15 16:17:41,949 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.1.bn2.weight                   loaded from layer4.1.bn2.weight          of shape (512,)
2023-05-15 16:17:41,949 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.1.bn3.bias                     loaded from layer4.1.bn3.bias            of shape (2048,)
2023-05-15 16:17:41,949 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.1.bn3.weight                   loaded from layer4.1.bn3.weight          of shape (2048,)
2023-05-15 16:17:41,949 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.1.conv1.weight                 loaded from layer4.1.conv1.weight        of shape (512, 2048, 1, 1)
2023-05-15 16:17:41,952 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.1.conv2.weight                 loaded from layer4.1.conv2.weight        of shape (512, 512, 3, 3)
2023-05-15 16:17:41,952 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.1.conv3.weight                 loaded from layer4.1.conv3.weight        of shape (2048, 512, 1, 1)
2023-05-15 16:17:41,953 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.2.bn1.bias                     loaded from layer4.2.bn1.bias            of shape (512,)
2023-05-15 16:17:41,953 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.2.bn1.weight                   loaded from layer4.2.bn1.weight          of shape (512,)
2023-05-15 16:17:41,953 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.2.bn2.bias                     loaded from layer4.2.bn2.bias            of shape (512,)
2023-05-15 16:17:41,953 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.2.bn2.weight                   loaded from layer4.2.bn2.weight          of shape (512,)
2023-05-15 16:17:41,953 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.2.bn3.bias                     loaded from layer4.2.bn3.bias            of shape (2048,)
2023-05-15 16:17:41,953 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.2.bn3.weight                   loaded from layer4.2.bn3.weight          of shape (2048,)
2023-05-15 16:17:41,953 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.2.conv1.weight                 loaded from layer4.2.conv1.weight        of shape (512, 2048, 1, 1)
2023-05-15 16:17:41,956 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.2.conv2.weight                 loaded from layer4.2.conv2.weight        of shape (512, 512, 3, 3)
2023-05-15 16:17:41,956 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.layer4.2.conv3.weight                 loaded from layer4.2.conv3.weight        of shape (2048, 512, 1, 1)
2023-05-15 16:17:41,956 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.stem._base_stem.bn1.bias              loaded from bn1.bias                     of shape (64,)
2023-05-15 16:17:41,956 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.stem._base_stem.bn1.weight            loaded from bn1.weight                   of shape (64,)
2023-05-15 16:17:41,956 maskrcnn_benchmark.utils.model_serialization INFO: graphable.model_segment.backbone.body.stem._base_stem.conv1.weight          loaded from conv1.weight                 of shape (64, 3, 7, 7)
2023-05-15 16:17:42,399 maskrcnn_benchmark.trainer INFO: Running dummy shapes through finished training model to trigger cudnn rt fusion
:::MLLOG {"namespace": "", "time_ms": 1684167468496, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 878}}
:::MLLOG {"namespace": "", "time_ms": 1684167468497, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "maskrcnn/tools/train_mlperf.py", "lineno": 878}}
2023-05-15 16:17:48,498 maskrcnn_benchmark.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Traceback (most recent call last):
  File "maskrcnn/tools/train_mlperf.py", line 1139, in <module>
Traceback (most recent call last):
Traceback (most recent call last):
  File "maskrcnn/tools/train_mlperf.py", line 1139, in <module>
  File "maskrcnn/tools/train_mlperf.py", line 1139, in <module>
Traceback (most recent call last):
  File "maskrcnn/tools/train_mlperf.py", line 1139, in <module>
Traceback (most recent call last):
  File "maskrcnn/tools/train_mlperf.py", line 1139, in <module>
    main()
  File "maskrcnn/tools/train_mlperf.py", line 1128, in main
    main()
  File "maskrcnn/tools/train_mlperf.py", line 1128, in main
    main()
  File "maskrcnn/tools/train_mlperf.py", line 1128, in main
    model, success, throughput = train(cfg, rank, world_size, args.distributed, training_comm, evaluation_comm, random_number_generator, seed=worker_seeds[seed_rank])
  File "maskrcnn/tools/train_mlperf.py", line 885, in train
    main()
  File "maskrcnn/tools/train_mlperf.py", line 1128, in main
    model, success, throughput = train(cfg, rank, world_size, args.distributed, training_comm, evaluation_comm, random_number_generator, seed=worker_seeds[seed_rank])
      File "maskrcnn/tools/train_mlperf.py", line 885, in train
model, success, throughput = train(cfg, rank, world_size, args.distributed, training_comm, evaluation_comm, random_number_generator, seed=worker_seeds[seed_rank])
  File "maskrcnn/tools/train_mlperf.py", line 885, in train
    data_loader, iters_per_epoch = make_data_loader(
  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/build.py", line 198, in make_data_loader
    main()
  File "maskrcnn/tools/train_mlperf.py", line 1128, in main
        datasets, epoch_size = build_dataset(dataset_list, None if is_hybrid_loader else transforms, DatasetCatalog, is_train, cfg.DATALOADER.GLOBAL_TRANSFORMS, transforms_properties, comm, master_rank)model, success, throughput = train(cfg, rank, world_size, args.distributed, training_comm, evaluation_comm, random_number_generator, seed=worker_seeds[seed_rank])

  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/build.py", line 66, in build_dataset
  File "maskrcnn/tools/train_mlperf.py", line 885, in train
        data_loader, iters_per_epoch = make_data_loader(data_loader, iters_per_epoch = make_data_loader(

loading annotations into memory...  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/build.py", line 198, in make_data_loader
  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/build.py", line 198, in make_data_loader
    
dataset = factory(**args)
  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/datasets/coco.py", line 61, in __init__
Traceback (most recent call last):
  File "maskrcnn/tools/train_mlperf.py", line 1139, in <module>
        datasets, epoch_size = build_dataset(dataset_list, None if is_hybrid_loader else transforms, DatasetCatalog, is_train, cfg.DATALOADER.GLOBAL_TRANSFORMS, transforms_properties, comm, master_rank)datasets, epoch_size = build_dataset(dataset_list, None if is_hybrid_loader else transforms, DatasetCatalog, is_train, cfg.DATALOADER.GLOBAL_TRANSFORMS, transforms_properties, comm, master_rank)
      File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/build.py", line 66, in build_dataset
        self.img_infos = torch.load("%simg_info.pyt" % (base_file_name)).reshape([-1,4])
model, success, throughput = train(cfg, rank, world_size, args.distributed, training_comm, evaluation_comm, random_number_generator, seed=worker_seeds[seed_rank])Traceback (most recent call last):
data_loader, iters_per_epoch = make_data_loader(
  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/build.py", line 66, in build_dataset

    
  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 793, in load
  File "maskrcnn/tools/train_mlperf.py", line 1139, in <module>
dataset = factory(**args)  File "maskrcnn/tools/train_mlperf.py", line 885, in train
  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/build.py", line 198, in make_data_loader
    
dataset = factory(**args)  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/datasets/coco.py", line 61, in __init__

  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/datasets/coco.py", line 61, in __init__
    datasets, epoch_size = build_dataset(dataset_list, None if is_hybrid_loader else transforms, DatasetCatalog, is_train, cfg.DATALOADER.GLOBAL_TRANSFORMS, transforms_properties, comm, master_rank)
  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/build.py", line 66, in build_dataset
    self.img_infos = torch.load("%simg_info.pyt" % (base_file_name)).reshape([-1,4])
  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 793, in load
    self.img_infos = torch.load("%simg_info.pyt" % (base_file_name)).reshape([-1,4])
  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 793, in load
    dataset = factory(**args)
  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/datasets/coco.py", line 61, in __init__
    data_loader, iters_per_epoch = make_data_loader(
  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/build.py", line 198, in make_data_loader
    self.img_infos = torch.load("%simg_info.pyt" % (base_file_name)).reshape([-1,4])
  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 793, in load
    datasets, epoch_size = build_dataset(dataset_list, None if is_hybrid_loader else transforms, DatasetCatalog, is_train, cfg.DATALOADER.GLOBAL_TRANSFORMS, transforms_properties, comm, master_rank)
  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/build.py", line 66, in build_dataset
    dataset = factory(**args)
  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/datasets/coco.py", line 61, in __init__
    self.img_infos = torch.load("%simg_info.pyt" % (base_file_name)).reshape([-1,4])
  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 793, in load
    main()
  File "maskrcnn/tools/train_mlperf.py", line 1128, in main
    main()
  File "maskrcnn/tools/train_mlperf.py", line 1128, in main
    model, success, throughput = train(cfg, rank, world_size, args.distributed, training_comm, evaluation_comm, random_number_generator, seed=worker_seeds[seed_rank])
  File "maskrcnn/tools/train_mlperf.py", line 885, in train
    model, success, throughput = train(cfg, rank, world_size, args.distributed, training_comm, evaluation_comm, random_number_generator, seed=worker_seeds[seed_rank])
      File "maskrcnn/tools/train_mlperf.py", line 885, in train
data_loader, iters_per_epoch = make_data_loader(
  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/build.py", line 198, in make_data_loader
    datasets, epoch_size = build_dataset(dataset_list, None if is_hybrid_loader else transforms, DatasetCatalog, is_train, cfg.DATALOADER.GLOBAL_TRANSFORMS, transforms_properties, comm, master_rank)
  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/build.py", line 66, in build_dataset
    dataset = factory(**args)
      File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/datasets/coco.py", line 61, in __init__
data_loader, iters_per_epoch = make_data_loader(
  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/build.py", line 198, in make_data_loader
        self.img_infos = torch.load("%simg_info.pyt" % (base_file_name)).reshape([-1,4])datasets, epoch_size = build_dataset(dataset_list, None if is_hybrid_loader else transforms, DatasetCatalog, is_train, cfg.DATALOADER.GLOBAL_TRANSFORMS, transforms_properties, comm, master_rank)

  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 793, in load
  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/build.py", line 66, in build_dataset
    dataset = factory(**args)
  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/datasets/coco.py", line 61, in __init__
    self.img_infos = torch.load("%simg_info.pyt" % (base_file_name)).reshape([-1,4])
  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 793, in load
Traceback (most recent call last):
  File "maskrcnn/tools/train_mlperf.py", line 1139, in <module>
    main()
  File "maskrcnn/tools/train_mlperf.py", line 1128, in main
    model, success, throughput = train(cfg, rank, world_size, args.distributed, training_comm, evaluation_comm, random_number_generator, seed=worker_seeds[seed_rank])
  File "maskrcnn/tools/train_mlperf.py", line 885, in train
    data_loader, iters_per_epoch = make_data_loader(
  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/build.py", line 198, in make_data_loader
    datasets, epoch_size = build_dataset(dataset_list, None if is_hybrid_loader else transforms, DatasetCatalog, is_train, cfg.DATALOADER.GLOBAL_TRANSFORMS, transforms_properties, comm, master_rank)
  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/build.py", line 66, in build_dataset
    dataset = factory(**args)
  File "/workspace/object_detection/maskrcnn/maskrcnn_benchmark/data/datasets/coco.py", line 61, in __init__
    self.img_infos = torch.load("%simg_info.pyt" % (base_file_name)).reshape([-1,4])
  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 793, in load
                    with _open_file_like(f, 'rb') as opened_file:        with _open_file_like(f, 'rb') as opened_file:with _open_file_like(f, 'rb') as opened_file:    with _open_file_like(f, 'rb') as opened_file:with _open_file_like(f, 'rb') as opened_file:
with _open_file_like(f, 'rb') as opened_file:with _open_file_like(f, 'rb') as opened_file:

with _open_file_like(f, 'rb') as opened_file:  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 273, in _open_file_like


  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 273, in _open_file_like


  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 273, in _open_file_like

  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 273, in _open_file_like
  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 273, in _open_file_like
  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 273, in _open_file_like
  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 273, in _open_file_like
  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 273, in _open_file_like
        return _open_file(name_or_buffer, mode)return _open_file(name_or_buffer, mode)

      File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 254, in __init__
  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 254, in __init__
return _open_file(name_or_buffer, mode)    
return _open_file(name_or_buffer, mode)  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 254, in __init__
    
            return _open_file(name_or_buffer, mode)  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 254, in __init__
return _open_file(name_or_buffer, mode)return _open_file(name_or_buffer, mode)    return _open_file(name_or_buffer, mode)
        

super().__init__(open(name, mode))
  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 254, in __init__
super().__init__(open(name, mode))super().__init__(open(name, mode))  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 254, in __init__
  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 254, in __init__

  File "/usr/local/lib/python3.8/dist-packages/torch/serialization.py", line 254, in __init__


        super().__init__(open(name, mode))super().__init__(open(name, mode))
FileNotFoundError    FileNotFoundErrorsuper().__init__(open(name, mode))
    FileNotFoundError:     : 
super().__init__(open(name, mode))[Errno 2] No such file or directory: '/coco_train2017_pyt/coco_train2017_img_info.pyt': FileNotFoundError[Errno 2] No such file or directory: '/coco_train2017_pyt/coco_train2017_img_info.pyt'super().__init__(open(name, mode))FileNotFoundError

[Errno 2] No such file or directory: '/coco_train2017_pyt/coco_train2017_img_info.pyt'
: 
FileNotFoundError: 
[Errno 2] No such file or directory: '/coco_train2017_pyt/coco_train2017_img_info.pyt'[Errno 2] No such file or directory: '/coco_train2017_pyt/coco_train2017_img_info.pyt': 
FileNotFoundError
[Errno 2] No such file or directory: '/coco_train2017_pyt/coco_train2017_img_info.pyt'FileNotFoundError: 
[Errno 2] No such file or directory: '/coco_train2017_pyt/coco_train2017_img_info.pyt': 
[Errno 2] No such file or directory: '/coco_train2017_pyt/coco_train2017_img_info.pyt'
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 144) of binary: ./run_and_time.sh
Traceback (most recent call last):
  File "/usr/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/usr/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 798, in <module>
    main()
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 794, in main
    run(args)
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py", line 785, in run
    elastic_launch(
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 134, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py", line 250, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
./run_and_time.sh FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-05-15_16:17:53
  host      : headnode.internal.cloudapp.net
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 148)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-05-15_16:17:53
  host      : headnode.internal.cloudapp.net
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 153)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[3]:
  time      : 2023-05-15_16:17:53
  host      : headnode.internal.cloudapp.net
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 161)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[4]:
  time      : 2023-05-15_16:17:53
  host      : headnode.internal.cloudapp.net
  rank      : 4 (local_rank: 4)
  exitcode  : 1 (pid: 170)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[5]:
  time      : 2023-05-15_16:17:53
  host      : headnode.internal.cloudapp.net
  rank      : 5 (local_rank: 5)
  exitcode  : 1 (pid: 179)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[6]:
  time      : 2023-05-15_16:17:53
  host      : headnode.internal.cloudapp.net
  rank      : 6 (local_rank: 6)
  exitcode  : 1 (pid: 193)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[7]:
  time      : 2023-05-15_16:17:53
  host      : headnode.internal.cloudapp.net
  rank      : 7 (local_rank: 7)
  exitcode  : 1 (pid: 211)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-05-15_16:17:53
  host      : headnode.internal.cloudapp.net
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 144)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
